{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[google scholar]\n",
    "- url : https://scholar.google.co.kr\n",
    "- beautifulsoup, selenium을 이용해서 데이터 수집하는 코드 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BS4 Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36',\n",
    "    'referer' : 'http://www.naver.com'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'reinforcement learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://scholar.google.co.kr/scholar?start='\n",
    "url2 = '&q=reinforcement+learning&hl=ko&as_sdt=0,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchPages = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetUrl = []\n",
    "for i in range(0,searchPages):\n",
    "    tmpUrl = url1+str(i*10)+url2\n",
    "    TargetUrl.append(tmpUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://scholar.google.co.kr/scholar?start=0&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=10&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=20&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=30&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=40&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=50&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=60&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=70&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=80&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=90&q=reinforcement+learning&hl=ko&as_sdt=0,5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TargetUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(TargetUrl[0], headers=headers)\n",
    "soup = BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html><head><title>Google 학술 검색</title><meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\"/><meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/><meta content=\"origin-when-cross-origin\" name=\"referrer\"/><meta content=\"width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=2\" name=\"viewport\"/><meta content=\"telephone=no\" name=\"format-detection\"/><link href=\"/favicon.ico\" rel=\"shortcut icon\"/><style>html,body,form,table,div,h1,h2,h3,h4,h5,h6,img,ol,ul,li,button{margin:0;padding:0;border:0;}table{border-collapse:collapse;border-width:0;empty-cells:show;}html,body{height:100%}#gs_top{position:relative;box-sizing:border-box;min-height:100%;min-width:964px;-webkit-tap-highlight-color:rgba(0,0,0,0);}#gs_top>*:not(#x){-webkit-tap-highlight-color:rgba(204,204,204,.5);}.gs_el_ph #gs_top,.gs_el_ta #gs_top{min-width:320px;}#gs_top.gs_nscl{position:fixed;width:100%;}body,td,input,button{font-size:13px;font-family:Arial,sans-serif;line-height:1.24;}body{background:#fff;color:#222;-webkit-text-size-adjust:100%;-moz-text-size-adjust:none;}.gs_gray{color:#777777}.gs_red{color:#dd4b39}.gs_grn{color:#006621}.gs_lil{font-size:11px}.gs_med{font-size:16px}.gs_hlt{font-weight:bold;}a:link{color:#1a0dab;text-decoration:none}a:visited{color:#660099;text-decoration:none}a:hover,a:hover .gs_lbl{text-decoration:underline}a:active,a:active .gs_lbl,a .gs_lbl:active{color:#d14836}.gs_el_tc a:hover,.gs_el_tc a:hover .gs_lbl{text-decoration:none}.gs_pfcs a:focus,.gs_pfcs button:focus,.gs_pfcs input:focus,.gs_pfcs label:focus{outline:none}.gs_a,.gs_a a:link,.gs_a a:visited{color:#006621}.gs_a a:active{color:#d14836}a.gs_fl:link,.gs_fl a:link{color:#1a0dab}a.gs_fl:visited,.gs_fl a:visited{color:#660099}a.gs_fl:active,.gs_fl a:active{color:#d14836}.gs_fl{color:#777777}.gs_ctc,.gs_ctu{vertical-align:middle;font-size:13px;font-weight:normal}.gs_ctc{color:#1a0dab}.gs_ctg,.gs_ctg2{font-size:13px;font-weight:bold}.gs_ctg{color:#1a0dab}a.gs_pda,.gs_pda a{padding:7px 0 5px 0}.gs_alrt{background:#f9edbe;border:1px solid #f0c36d;padding:0 16px;text-align:center;box-shadow:0 2px 4px rgba(0,0,0,.2);border-radius:2px;}.gs_spc{display:inline-block;width:12px}.gs_br{width:0;font-size:0}.gs_ibl{display:inline-block;}.gs_scl:after{content:\"\";display:table;clear:both;}.gs_ind{padding-left:8px;text-indent:-8px}.gs_ico,.gs_icm{display:inline-block;background:no-repeat url(/intl/ko/scholar/images/1x/sprite_20161020.png);background-position:-23px -161px;background-size:169px;width:21px;height:21px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_ico,.gs_icm{background-image:url(/intl/ko/scholar/images/2x/sprite_20161020.png);}}.gs_el_ta .gs_nta,.gs_ota,.gs_el_ph .gs_nph,.gs_oph{display:none}.gs_el_ta .gs_ota,.gs_el_ph .gs_oph{display:inline}.gs_el_ta div.gs_ota,.gs_el_ph div.gs_oph{display:block}.gs_sth_g{visibility:hidden;max-height:0;}.gs_sth_vis .gs_sth_g{max-height:1000px;}.gs_sth_vis .gs_sth_b{position:fixed;top:0;}@keyframes gs_anm_spin{0%{transform:rotate(0deg);}100%{transform:rotate(360deg);}}.gs_rimg{display:block;background-color:#e5e5e5;border-radius:50%;overflow:hidden;position:relative;z-index:1;}.gs_rimg>img{position:absolute;margin:auto;left:0;top:0;bottom:0;right:0;}.gs_in_txtw{display:inline-block;vertical-align:middle;}.gs_in_txtb{display:block;}.gs_in_txt{color:#000;background-color:#fff;font-size:16px;box-sizing:border-box;height:29px;line-height:23px;border:1px solid #d9d9d9;border-top-color:#c0c0c0;padding:3px 6px 1px 8px;border-radius:1px;outline:none;-webkit-appearance:none;-moz-appearance:none;}.gs_el_tc .gs_in_txt{font-size:18px;}.gs_in_txtb .gs_in_txt{width:100%;}.gs_in_txt:hover{border-color:#b9b9b9;border-top-color:#a0a0a0;box-shadow:inset 0 1px 2px rgba(0,0,0,.1);}.gs_in_txte .gs_in_txt{border-color:#dd4b39;}.gs_in_txt:focus{border-color:#4d90fe;box-shadow:inset 0 1px 2px rgba(0,0,0,.3);}.gs_in_txt:disabled{color:#b8b8b8;border-color:#f1f1f1;box-shadow:none;}.gs_in_txtm .gs_in_txt{font-size:13px;height:24px;line-height:16px;padding:3px 6px;}.gs_el_tc .gs_in_txtm .gs_in_txt{height:29px;line-height:21px;}.gs_in_txts{font-size:13px;line-height:18px;color:#666;}.gs_in_txte .gs_in_txts{color:#dd4b39;}button{position:relative;z-index:1;box-sizing:border-box;font-size:13px;cursor:pointer;height:29px;line-height:normal;min-width:72px;padding:0 8px;color:#444;border:1px solid rgba(0,0,0,.1);border-radius:3px;text-align:center;background-color:#f5f5f5;-webkit-user-select:none;user-select:none;}button.gs_btn_rnd{border-radius:14px;padding:0 12px;}button.gs_btn_rnd.gs_btn_rndci{padding-left:4px;}button.gs_btn_lrge{height:41px;min-width:82px;padding:0 9px;}button.gs_btn_lrge.gs_btn_rnd{border-radius:20px;padding:0 16px;}button.gs_btn_lrge.gs_btn_rnd.gs_btn_rndci{padding-left:10px;}button.gs_btn_mini{padding:0;border:0;}.gs_el_ph button.gs_btn_mph,.gs_el_ta button.gs_btn_mta{height:41px;}button .gs_wr{position:relative;display:inline-block;width:100%;height:100%;}button .gs_wr:before{content:\"\";width:0;height:100%;}button .gs_wr:before,button .gs_ico,button .gs_rdt,button .gs_lbl,button .gs_icm{display:inline-block;vertical-align:middle;}button .gs_wr{font-size:13px;text-transform:none;}.gs_btn_lrge .gs_wr{font-size:15px;}.gs_btn_half,.gs_el_ta .gs_btn_hta,.gs_el_ph .gs_btn_hph{min-width:36px;}.gs_btn_lrge.gs_btn_half,.gs_el_ta .gs_btn_lrge.gs_btn_hta,.gs_el_ph .gs_btn_lrge.gs_btn_hph,.gs_el_ta .gs_btn_mta,.gs_el_ph .gs_btn_mph{min-width:41px;}.gs_btn_slt{border-radius:3px 0 0 3px;}.gs_btn_srt{margin-left:-1px;border-radius:0 3px 3px 0;}.gs_btn_smd{margin-left:-1px;border-radius:0;}button:hover{z-index:2;color:#222;border-color:rgba(0,0,0,.2);background-color:#f8f8f8;}button.gs_sel{background-color:#dcdcdc;}button:active{z-index:2;background-color:#f1f1f1;}button:focus{z-index:2;}button::-moz-focus-inner{padding:0;border:0}button:-moz-focusring{outline:1px dotted ButtonText}.gs_pfcs button:-moz-focusring{outline:none}a.gs_in_ib{position:relative;display:inline-block;line-height:16px;padding:6px 0 7px 0;-webkit-user-select:none;user-select:none;}a.gs_btn_lrge{height:40px;padding:0;}a.gs_in_ib .gs_lbl{display:inline-block;padding-left:21px;color:#222;}a.gs_in_ib .gs_lbl:not(:empty){padding-left:29px;}button.gs_in_ib .gs_lbl:not(:empty){padding-left:4px;}a.gs_in_ib:active .gs_lbl,a.gs_in_ib .gs_lbl:active,a.gs_in_ib :active~.gs_lbl{color:#d14836;}.gs_el_ta .gs_btn_hta .gs_lbl,.gs_el_ph .gs_btn_hph .gs_lbl,.gs_el_ta .gs_btn_mta .gs_lbl,.gs_el_ph .gs_btn_mph .gs_lbl,.gs_el_ta .gs_btn_cta .gs_lbl,.gs_el_ph .gs_btn_cph .gs_lbl{display:none;}a.gs_in_ib .gs_ico{position:absolute;top:3px;left:0;}.gs_in_ib.gs_md_li .gs_ico{left:14px;}.gs_el_tc .gs_in_ib.gs_md_li .gs_ico{top:11px;}.gs_in_ib.gs_md_li.gs_md_lix .gs_ico{top:10px;left:16px;}a.gs_btn_lrge .gs_ico{top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}.gs_in_ib .gs_ico{opacity:.55;}.gs_in_ib:hover .gs_ico{opacity:.72;}.gs_in_ib:active .gs_ico,.gs_in_ib .gs_ico:active,.gs_in_ib :active~.gs_ico{opacity:1;}.gs_in_ib:disabled .gs_ico,.gs_in_ib.gs_dis .gs_ico{opacity:.28;}.gs_in_ib.gs_btn_act .gs_ico,.gs_in_ib.gs_btn_cre .gs_ico{opacity:1;}.gs_btn_act:disabled .gs_ico,.gs_btn_cre:disabled .gs_ico{opacity:.72;}.gs_rdt{position:relative;width:0;height:21px;}.gs_rdt:before{content:\"\";position:absolute;top:2px;right:1px;width:5px;height:5px;border-radius:50%;background-color:#dd4b39;}button.gs_btn_flat{border-color:transparent;background-color:transparent;}button.gs_btn_flat:hover{background-color:rgba(0,0,0,.05);}button.gs_btn_flat:active{background-color:rgba(0,0,0,.1);}button.gs_btn_flat.gs_btn_flact{color:#1a0dab;}button.gs_btn_act{color:#fff;-webkit-font-smoothing:antialiased;background-color:#4d90fe;}button.gs_btn_act:hover{color:#fff;background-color:#3983fe;}button.gs_btn_act.gs_sel{background-color:#2f6bcc;}button.gs_btn_act:active{background-color:#357ae8;}button.gs_btn_cre{color:#fff;-webkit-font-smoothing:antialiased;background-color:#d14836;}button.gs_btn_cre:hover{color:#fff;background-color:#c53727;}button.gs_btn_cre.gs_sel{background-color:#992b1e;}html:not(.gs_pfcs) .gs_btn_act:focus:not(:active){box-shadow:inset 0 0 0 1px rgba(255,255,255,.5);}button.gs_btn_cre:active{background-color:#b0281a;}button:disabled,button:disabled:hover,button:disabled:active{cursor:default;color:#b8b8b8;border-color:rgba(0,0,0,.05);background-color:transparent;z-index:0;}button.gs_btn_flat:disabled{color:#b8b8b8;border-color:transparent;}button.gs_btn_act:disabled{color:#fff;background-color:#a6c8ff;}button.gs_btn_cre:disabled{color:#fff;background-color:#e8a49b;}a.gs_in_ib.gs_dis{cursor:default;pointer-events:none}a.gs_in_ib.gs_dis .gs_lbl{color:#b8b8b8;text-decoration:none}.gs_ttp{position:absolute;top:100%;right:50%;z-index:10;pointer-events:none;visibility:hidden;opacity:0;transition:visibility 0s .13s,opacity .13s ease-out;}button:hover .gs_ttp,button:focus .gs_ttp,a:hover .gs_ttp,a:focus .gs_ttp{transition:visibility 0s .3s,opacity .13s ease-in .3s;visibility:visible;opacity:1;}.gs_md_tb.gs_sel .gs_ttp{transition:none;visibility:hidden;}.gs_ttp .gs_aro,.gs_ttp .gs_aru{position:absolute;top:-2px;right:-5px;width:0;height:0;line-height:0;font-size:0;border:5px solid transparent;border-top:none;border-bottom-color:#2a2a2a;z-index:1;}.gs_ttp .gs_aro{top:-3px;right:-6px;border-width:6px;border-top:none;border-bottom-color:white;}.gs_ttp .gs_txt{display:block;position:relative;top:2px;right:-50%;padding:7px 9px;background:#2a2a2a;color:white;font-size:13px;font-weight:normal;line-height:normal;white-space:nowrap;border:1px solid white;box-shadow:inset 0 1px 4px rgba(0,0,0,.2);}.gs_press,.gs_in_se,.gs_tan{touch-action:none;}.gs_in_se .gs_lbl:not(:empty){padding-right:14px;}.gs_in_se .gs_icm{position:absolute;top:50%;margin-top:-5.5px;right:0;width:7px;height:11px;background-position:-21px -88px;opacity:.55;}.gs_in_se:hover .gs_icm{opacity:.72;}.gs_in_se:active .gs_icm{opacity:1;}.gs_in_se:disabled .gs_icm{opacity:.28;}.gs_el_ta .gs_btn_hta .gs_icm,.gs_el_ph .gs_btn_hph .gs_icm,.gs_el_ta .gs_btn_mta .gs_icm,.gs_el_ph .gs_btn_mph .gs_icm,.gs_el_ta .gs_btn_cta .gs_icm,.gs_el_ph .gs_btn_cph .gs_icm{display:none;}.gs_btn_mnu .gs_icm{margin-top:-3.5px;height:7px;background-position:0 -110px;}.gs_in_se.gs_btn_act .gs_icm,.gs_in_se.gs_btn_cre .gs_icm{margin-top:-3.5px;height:7px;background-position:-42px -44px;opacity:1;}.gs_btn_act:disabled .gs_icm,.gs_btn_cre:disabled .gs_icm{opacity:.72;}button.gs_btnG .gs_ico{width:21px;height:21px;background-position:-92px -253px;}.gs_md_d{text-transform:none;white-space:nowrap;position:absolute;top:0;left:0;border:1px solid #ccc;border-color:rgba(0,0,0,.2);background:#fff;box-shadow:0 2px 4px rgba(0,0,0,.2);z-index:1100;text-align:left;visibility:hidden;max-height:0;margin-top:-1000px;opacity:0;transition:opacity .13s,visibility 0s .13s,max-height 0s .13s,margin-top 0s .13s;}.gs_md_d.gs_vis{visibility:visible;max-height:10000px;margin-top:0;opacity:1;transition:all 0s;}.gs_el_tc .gs_md_d{transform-origin:100% 0;transform:scale(1,0);transition:opacity .218s ease-out,transform 0s .218s,visibility 0s .218s,max-height 0s .218s,margin-top 0s .218s;}.gs_el_ios .gs_md_d{-webkit-backface-visibility:hidden;}.gs_el_tc .gs_md_d.gs_ttzi{transform-origin:50% 50%;transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_ttzr{transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_vis{transform:scale(1,1);transition:transform .218s ease-out;}.gs_md_r{position:relative;display:inline-block;}.gs_md_rmb>.gs_md_d{top:29px}.gs_md_rmbl>.gs_md_d{top:41px}.gs_md_ul{list-style-type:none;word-wrap:break-word;display:inline-block;vertical-align:top;}.gs_md_ul.gs_md_ul_tb{display:block;}.gs_md_li,.gs_in_cb.gs_md_li,.gs_md_li:link,.gs_md_li:visited{display:block;padding:6px 44px 6px 16px;font-size:13px;line-height:16px;color:#222;cursor:pointer;text-decoration:none;position:relative;z-index:0;}a.gs_md_li:hover .gs_lbl,a.gs_md_li:active .gs_lbl{text-decoration:none}.gs_el_tc .gs_md_li{padding-top:14px;padding-bottom:10px;}.gs_md_li.gs_md_lix{font-size:16px;line-height:20px;padding:12px 16px 8px 16px;}.gs_md_li:before{content:\"\";background-color:#f1f1f1;position:absolute;left:0;right:0;top:0;bottom:0;opacity:0;transition:opacity .13s;z-index:-1;}.gs_md_li:hover:before,.gs_md_li:focus:before{opacity:1;transition:all 0s;}a.gs_in_ib.gs_md_li .gs_lbl{color:#222}a.gs_in_ib.gs_md_li.gs_in_gray .gs_lbl{color:#444}.gs_md_li:active:before{background-color:#ddd}.gs_md_li.gs_sel,a.gs_in_ib.gs_md_li.gs_sel .gs_lbl{color:#d14836}.gs_md_d:focus,.gs_md_li:focus{outline:none}a.gs_md_lix .gs_lbl,a.gs_md_lix .gs_lbl:not(:empty){padding:0 0 0 40px;}a.gs_in_cb:link,a.gs_in_cb:visited,a.gs_in_cb:active,a.gs_in_cb:hover{cursor:pointer;color:#222;text-decoration:none;}.gs_in_cb,.gs_in_ra{position:relative;line-height:16px;display:inline-block;-webkit-user-select:none;user-select:none;}.gs_in_cb.gs_md_li{padding:6px 44px 6px 16px;}.gs_in_cb input,.gs_in_ra input{position:absolute;top:1px;left:1px;width:15px;height:15px;margin:0;padding:0;opacity:0;z-index:2;}.gs_in_ra input{top:0;left:0}.gs_el_tc .gs_in_cb input{top:9px}.gs_el_tc .gs_in_ra input{top:8px}.gs_in_cb.gs_in_cbj input{top:15px;left:15px}.gs_in_cb label,.gs_in_cb .gs_lbl,.gs_in_ra label{display:inline-block;padding-left:21px;min-height:16px;}.gs_in_cb label:empty:before,.gs_in_cb .gs_lbl:empty:before,.gs_in_ra label:empty:before{content:\"\\200b\";}.gs_el_tc .gs_in_cb label,.gs_el_tc .gs_in_cb .gs_lbl,.gs_el_tc .gs_in_ra label{padding-top:8px;padding-bottom:5px;}.gs_in_cb.gs_in_cbj label,.gs_in_cb.gs_in_cbj .gs_lbl{padding:13px 0 12px 41px;}.gs_in_cbb,.gs_in_cbb label,.gs_in_cbb .gs_lbl{display:block;}.gs_in_cb .gs_cbx,.gs_in_ra .gs_cbx{position:absolute}.gs_in_cb .gs_cbx{top:2px;left:2px;width:11px;height:11px;border:1px solid #c6c6c6;border-radius:1px;}.gs_md_li .gs_cbx{top:8px;left:18px}.gs_el_tc .gs_in_cb .gs_cbx{top:10px}.gs_el_tc .gs_md_li .gs_cbx{top:16px}.gs_in_cb.gs_in_cbj .gs_cbx{top:15px;left:15px}.gs_el_tc .gs_in_ra .gs_cbx{top:8px}.gs_in_ra .gs_cbx{top:0;left:0;border:1px solid #c6c6c6;width:13px;height:13px;border-radius:7px;}.gs_in_cb:hover .gs_cbx,.gs_in_ra:hover .gs_cbx{border-color:#666;box-shadow:inset 0 1px 1px rgba(0,0,0,.1);}button.gs_in_cb:hover .gs_cbx{border-color:#c6c6c6;}.gs_in_cb :focus~label,.gs_in_ra :focus~label{outline:1px dotted #222;outline:auto -webkit-focus-ring-color;}.gs_pfcs .gs_in_cb :focus~label,.gs_pfcs .gs_in_ra :focus~label{outline:none;}.gs_in_cb:active .gs_cbx,.gs_in_ra:active .gs_cbx,.gs_in_cb .gs_cbx:active,.gs_in_ra .gs_cbx:active,.gs_in_cb :active~.gs_cbx,.gs_in_ra :active~.gs_cbx{border-color:#666;background-color:#ebebeb;}button.gs_in_cb:active .gs_cbx{border-color:#a6a6a6;}.gs_in_cb :disabled~.gs_cbx,.gs_in_ra :disabled~.gs_cbx,button.gs_in_cb:disabled .gs_cbx{border-color:#f1f1f1;box-shadow:none;}.gs_in_cb :disabled~label,.gs_in_ra :disabled~label{color:#b8b8b8;}.gs_in_cb.gs_err .gs_cbx{border-color:#eda29b;}.gs_in_cb .gs_chk,.gs_in_ra .gs_chk{position:absolute;z-index:1;top:-3px;left:-2px;width:21px;height:21px;}.gs_md_li .gs_chk{top:3px;left:14px}.gs_el_tc .gs_in_cb .gs_chk{top:5px}.gs_el_tc .gs_md_li .gs_chk{top:11px}.gs_in_cb.gs_in_cbj .gs_chk{top:10px;left:11px}.gs_in_ra .gs_chk{top:4px;left:4px;width:7px;height:7px;border-radius:4px;}.gs_el_tc .gs_in_ra .gs_chk{top:12px}.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk{background:no-repeat url(/intl/ko/scholar/images/1x/sprite_20161020.png) -69px -67px;opacity:.62;}.gs_in_ra input:checked~.gs_chk{background-color:#666}.gs_in_cb.gs_par .gs_chk{background:no-repeat url(/intl/ko/scholar/images/1x/sprite_20161020.png) -21px -44px;opacity:.55;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk,.gs_in_cb.gs_par .gs_chk{background-image:url(/intl/ko/scholar/images/2x/sprite_20161020.png);background-size:169px;}}.gs_in_cb input:checked:disabled~.gs_chk{opacity:.22}.gs_in_ra input:checked:disabled~.gs_chk{background-color:#f1f1f1}.gs_md_ac{position:absolute;top:28px;left:0;right:0;z-index:1100;white-space:normal;display:none;pointer-events:none;}.gs_md_ac[dir=\"ltr\"]{text-align:left;}.gs_md_ac[dir=\"rtl\"]{text-align:right;}.gs_md_ac ul{list-style-type:none;word-wrap:break-word;line-height:1.24;border:1px solid #e5e5e5;border-color:rgba(0,0,0,.2);background:#fff;box-shadow:0px 2px 4px rgba(0,0,0,.2);touch-action:manipulation;cursor:pointer;-webkit-user-select:none;user-select:none;pointer-events:auto;}.gs_md_acp{display:flex;line-height:0;}.gs_md_acp .gs_md_acs,.gs_md_acp ul{max-width:100%;box-sizing:border-box;display:inline-block;vertical-align:top;}.gs_md_acs{visibility:hidden;white-space:pre;height:0;min-width:0%;flex:0 1 auto;font-size:16px;}.gs_el_tc .gs_md_acs{font-size:18px;}.gs_md_acp ul{white-space:nowrap;flex:0 0 auto;}.gs_md_ac li{position:relative;padding:2px 8px;font-size:16px;line-height:20px;color:#222;background-color:#fff;overflow:hidden;text-overflow:ellipsis;}.gs_md_ac li.gs_sel{color:#000;background-color:#c6dafc;}.gs_md_ac li:active{background-color:#e8f0fe;}.gs_el_ios .gs_md_ac li:active{background-color:#fff;}.gs_md_ac li.gs_md_ac_lh,.gs_md_ac li.gs_md_ac_lh b{color:#660099;}.gs_el_tc .gs_md_ac li{padding:11px 8px 9px 8px;font-size:18px;border-top:1px solid #e5e5e5;}.gs_el_tc .gs_md_ac li:first-child{border-top:none;}.gs_md_ac[dir=\"ltr\"] li.gs_md_ac_lh{padding-right:29px;}.gs_md_ac[dir=\"rtl\"] li.gs_md_ac_lh{padding-left:29px;}.gs_el_tc .gs_md_ac[dir=\"ltr\"] li.gs_md_ac_lh{padding-right:49px;}.gs_el_tc .gs_md_ac[dir=\"rtl\"] li.gs_md_ac_lh{padding-left:49px;}.gs_md_ac_lh .gs_ico_X{position:absolute;top:0;}.gs_md_ac[dir=\"ltr\"] .gs_md_ac_lh .gs_ico_X{right:0;}.gs_md_ac[dir=\"rtl\"] .gs_md_ac_lh .gs_ico_X{left:0;}.gs_el_tc #gs_top .gs_md_ac .gs_md_ac_lh .gs_ico_Xt{padding:10px;}.gs_md_ac_lh .gs_ico_X:hover{background-color:#eee;}.gs_ico_x{background-position:-113px -22px;opacity:.55;}.gs_ico_x:hover{opacity:.72;}.gs_ico_x:active{opacity:1;}.gs_ico_X{background-position:-71px 0;opacity:.55;}.gs_ico_X:hover{opacity:.72;}.gs_ico_X:active{opacity:1;}.gs_el_tc .gs_ico_Xt{background-origin:content-box;background-clip:content-box;padding:10px 6px 10px 14px;}.gs_ico_P{background-position:0 0;opacity:.55;}.gs_ico_P:hover{opacity:.72;}.gs_ico_P:active{opacity:1;}.gs_btnP .gs_ico{background-position:-21px 0;}.gs_btnC .gs_ico{background-position:0 -66px;}.gs_btnL .gs_ico{background-position:-92px -44px;}.gs_ico_LB{background-position:-50px -44px;height:16px;}.gs_btnJ .gs_ico{background-position:-92px -22px;}.gs_btnM .gs_ico{background-position:-92px 0;}.gs_btnMW .gs_ico{background-position:-21px -22px;}.gs_btnSB .gs_ico{background-position:0 -44px;}.gs_btnTSB .gs_ico{background-position:-115px -253px;}.gs_btnPL .gs_ico{background-position:-148px -66px;}.gs_btnPR .gs_ico{background-position:-21px -66px;}.gs_btnPLW .gs_ico{background-position:-0 -230px;}.gs_btnPRW .gs_ico{background-position:-23px -230px;}.gs_btnZI .gs_ico{background-position:-148px -22px;}.gs_btnZO .gs_ico{background-position:-127px -44px;}.gs_btnDE .gs_ico{background-position:-134px 0;}.gs_btnFI .gs_ico{background-position:-50px -66px;}.gs_btnAD .gs_ico{background-position:-141px -88px;opacity:.55;}.gs_btnAD:hover .gs_ico{opacity:.72;}.gs_btnAD:active .gs_ico,.gs_btnAD .gs_ico:active,.gs_btnAD :active~.gs_ico{opacity:1;}.gs_btnBA .gs_ico{background-position:-50px -22px;}.gs_btnBL .gs_ico{background-position:0 -22px;}.gs_btnBLD .gs_ico{background-position:-23px -184px;}.gs_btnADD .gs_ico{background-position:-92px -66px;}.gs_btnMRG .gs_ico{background-position:-113px 0;}.gs_btnLBL .gs_ico{background-position:0 -161px;}.gs_btnCNCL .gs_ico{background-position:-71px 0;}.gs_btnDWL .gs_ico{background-position:-28px -88px;}.gs_btnMNU .gs_ico{background-position:0 -88px;}.gs_btnMNT .gs_ico{background-position:-46px -161px;}.gs_btnALT .gs_ico{background-position:-92px -161px;}.gs_btnART .gs_ico{background-position:-115px -161px;}.gs_btnGSL .gs_ico{background-position:-69px -161px;}.gs_btnCLS .gs_ico{background-position:-138px -161px;}.gs_btnXBLU .gs_ico{background-position:-138px -253px;}.gs_btnSSB .gs_ico{background-position:0 -276px;}.gs_btnSSW .gs_ico{background-position:-23px -276px;}.gs_btnFLT .gs_ico{background-position:0 -184px;}.gs_btnXT .gs_ico{background-position:-46px -184px;}.gs_btnPD .gs_ico{background-position:-69px -184px;}.gs_btnPU .gs_ico {background-position:-92px -276px;}.gs_btnCP .gs_ico{background-position:-92px -184px;}.gs_btnTP .gs_ico{background-position:-138px -184px;}.gs_btnML .gs_ico{background-position:-115px -276px;}.gs_btnCHK .gs_ico{background-position:-71px -66px;}.gs_btnDNB .gs_ico{background-position:-115px -230px;}.gs_btnDNW .gs_ico{background-position:0 -207px;}.gs_btnACA .gs_ico{background-position:-23px -207px;}.gs_btnAPT .gs_ico{background-position:-46px -207px;}.gs_btnAPTW .gs_ico{background-position:-92px -230px;}.gs_btnAFL .gs_ico{background-position:-69px -207px;}.gs_btnAN .gs_ico{background-position:-46px -276px;}.gs_btnAI .gs_ico{background-position:-69px -276px;}.gs_btnPBL .gs_ico{background-position:-92px -207px;}.gs_btnUCT .gs_ico{background-position:-115px -207px;}.gs_btnVRF .gs_ico{background-position:-138px -207px;}.gs_btnLSI .gs_ico{background-position:-46px -230px;}.gs_btnLSG .gs_ico{background-position:-69px -230px;}.gs_btnMOR .gs_ico{background-position:-23px -253px;}.gs_btnADV .gs_ico{background-position:-46px -253px;}.gs_btnPRO .gs_ico{background-position:-69px -253px;}.gs_ico_nav_previous{background-position:0 -119px;width:53px;height:40px;}.gs_ico_nav_first{background-position:-25px -119px;width:28px;height:40px;}.gs_ico_nav_current{background-position:-53px -119px;width:20px;height:40px;}.gs_ico_nav_page{background-position:-73px -119px;width:20px;height:40px;}.gs_ico_nav_next{background-position:-93px -119px;width:71px;height:40px;}.gs_ico_nav_last{background-position:-93px -119px;width:45px;height:40px;}.gs_ico_star{background-position:-71px -44px;width:13px;height:13px;}.gs_btnPLSW .gs_ico{background-position:-138px -230px;}.gs_btnPDF .gs_ico{background-position:0 -253px;}#gs_hdr_drs,#gs_hdr_drw{position:fixed;top:0;left:0;width:100%;height:100%;z-index:1200;visibility:hidden;}#gs_hdr_drs{opacity:0;background-color:#fff;transition:opacity .15s,visibility 0s .15s;}.gs_el_ta #gs_hdr_drs,.gs_el_ph #gs_hdr_drs{background-color:#666;}#gs_hdr_drs.gs_vis{visibility:visible;opacity:.5;transition:opacity .15s,visibility 0s;}.gs_el_tc #gs_hdr_drs{transition:opacity .218s,visibility 0s .218s;}.gs_el_tc #gs_hdr_drs.gs_vis{transition:opacity .218s,visibility 0s;}#gs_hdr_drw{overflow:auto;width:230px;background-color:#fff;box-shadow:2px 2px 4px rgba(0,0,0,.15);outline:none;transform:translate(-100%,0);transition:transform .15s ease-in-out,visibility 0s .15s;}.gs_el_sm #gs_hdr_drw{width:300px;}#gs_hdr_drw.gs_vis{visibility:visible;transform:translate(0,0);transition:transform .15s ease-in-out,visibility 0s;}.gs_el_tc #gs_hdr_drw{transition:transform .3s cubic-bezier(.4,0,.6,1),visibility 0s .3s;}.gs_el_tc #gs_hdr_drw.gs_vis{transition:transform .225s cubic-bezier(0,0,.2,1),visibility 0s;}#gs_hdr_drw.gs_abt,.gs_el_tc #gs_hdr_drw.gs_abt{transition:none;}#gs_hdr_drw_in{position:relative;box-sizing:border-box;min-height:100%;padding:0 0 8px 0;}.gs_el_ta #gs_hdr_drw_in,.gs_el_ph #gs_hdr_drw_in{padding:0 0 65px 0;}#gs_hdr_drw_top{position:relative;height:63px;border-bottom:1px solid #e5e5e5;margin-bottom:8px;}.gs_el_ta #gs_hdr_drw_top,.gs_el_ph #gs_hdr_drw_top{height:57px;}#gs_hdr_drw_mnu,#gs_hdr_drw_lgo,#gs_hdr_drw_set{position:absolute;top:0;height:100%;}#gs_hdr_drw_mnu{left:0;width:55px;}#gs_hdr_drw_lgo{left:56px;}#gs_hdr_drw_set{right:0;width:53px;}.gs_hdr_drw_sec:before{display:block;content:\" \";height:0;border-bottom:1px solid #e5e5e5;margin:8px 0;}.gs_hdr_drw_sec:first-child:before{display:none;}#gs_hdr_drw_top .gs_btnP,.gs_el_sm #gs_hdr_drw_bs{display:none;}.gs_el_sm #gs_hdr_drw_top .gs_btnP{display:inline-block;}#gs_hdr_drw_bot{display:none;}.gs_el_ta #gs_hdr_drw_bot,.gs_el_ph #gs_hdr_drw_bot{display:block;position:absolute;left:0;bottom:0;width:100%;height:65px;}#gs_hdr_drw_bot .gs_md_li:before{opacity:0;}#gs_hdr_drw_bot .gs_hdr_pp{display:block;position:absolute;bottom:14px;left:15px;pointer-events:none;}#gs_hdr_drw_bot .gs_lbl{display:block;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;}#gs_hdr{position:relative;height:63px;background-color:#f5f5f5;border-bottom:1px solid #e5e5e5;display:flex;}.gs_el_ta #gs_hdr,.gs_el_ph #gs_hdr{height:57px;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_lgo,#gs_hdr_lgt,#gs_hdr_md,#gs_hdr_sre,#gs_hdr_act{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}#gs_hdr_md{flex:1 1 auto;}#gs_hdr .gs_hdr_mbo,#gs_hdr .gs_hdr_mbo,.gs_el_ta #gs_hdr .gs_hdr_dso,.gs_el_ph #gs_hdr .gs_hdr_dso{display:none;}.gs_el_ta #gs_hdr .gs_hdr_mbo,.gs_el_ph #gs_hdr .gs_hdr_mbo{display:inline-block;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_sre{width:55px;margin-right:1px;}#gs_hdr_lgo,#gs_hdr_drw_lgo{width:152px;background:no-repeat url('/intl/ko/scholar/images/1x/scholar_logo_24dp.png') 0% 50%;background-size:152px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){#gs_hdr_lgo,#gs_hdr_drw_lgo{background-image:url('/intl/ko/scholar/images/2x/scholar_logo_24dp.png');}}#gs_hdr_lgo{margin-right:30px;}.gs_el_ph #gs_hdr_lgo{margin-right:0;}#gs_hdr_lgt{min-width:166px;margin-right:16px;}.gs_el_sm #gs_hdr_lgt:empty{min-width:60px;}#gs_hdr_md{margin-right:16px;min-width:1px;}#gs_hdr_lgt,#gs_hdr_md h1{padding:19px 0 0 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-size:20px;line-height:25px;font-weight:normal;color:#666;max-width:100%;text-align:left;}.gs_el_ta #gs_hdr_md h1,.gs_el_ph #gs_hdr_md h1{padding:16px 0 0 0;}#gs_hdr_srch{padding:14px 0 0 0;max-width:600px;}.gs_el_ta #gs_hdr_srch,.gs_el_ph #gs_hdr_srch{padding:10px 0 0 0;max-width:none;}#gs_hdr_frm{position:relative;padding-right:39px;}#gs_hdr_tsi{height:38px;border-radius:2px 0 0 2px;}#gs_hdr_tsi::-ms-clear{display:none;}#gs_hdr_tsc{display:none;position:absolute;top:3px;right:41px;width:21px;height:21px;padding:6px 10px 7px 10px;}.gs_in_acw[dir=\"rtl\"]~#gs_hdr_tsc{right:auto;left:1px;}#gs_hdr_tsb{position:absolute;top:0;right:0;width:40px;height:38px;border-radius:0 2px 2px 0;}#gs_hdr_frm_ac{top:37px;right:40px;}.gs_el_ph #gs_hdr_frm_ac{right:0;}.gs_el_ph .gs_hdr_ifc #gs_hdr_mnu,.gs_el_ph .gs_hdr_ifc #gs_hdr_bck,.gs_hdr_src #gs_hdr_srch,.gs_hdr_src #gs_hdr_lgt,.gs_hdr_srx #gs_hdr_sre,.gs_hdr_srx #gs_hdr_md h1,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_mbo,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_dso,.gs_el_ta .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_mnu,.gs_el_ph .gs_hdr_srx #gs_hdr_bck{display:none;}.gs_el_ph .gs_hdr_ifc #gs_hdr_md,.gs_el_ph .gs_hdr_srx #gs_hdr_md{margin-left:16px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir=\"ltr\"]{padding-right:41px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir=\"rtl\"]{padding-left:41px;}.gs_el_tc .gs_hdr_tsc .gs_in_acw~#gs_hdr_tsc{display:block;}#gs_hdr_act{min-width:64px;max-width:200px;text-align:right;float:right;}.gs_el_ta #gs_hdr_act,.gs_el_ph #gs_hdr_act{display:none;}#gs_hdr_act_i,#gs_hdr_act_s{display:inline-block;padding:23px 24px 23px 16px;max-width:100%;box-sizing:border-box;font-size:13px;line-height:17px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;color:#444;}#gs_hdr_act_s{font-size:15px;}.gs_el_sm #gs_hdr_act_i,.gs_el_sm #gs_hdr_act_s{padding:23px 16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ta #gs_hdr_act_s,.gs_el_ph #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_s{padding:20px 16px;}#gs_hdr_act_i:active,#gs_hdr_act_s:active{color:#d14836;}#gs_hdr_act_i,.gs_el_sm #gs_hdr_act_i{padding-top:15px;padding-bottom:16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_i{padding-top:12px;padding-bottom:13px;}#gs_hdr_act_i .gs_hdr_pp{vertical-align:top;}#gs_hdr_act_d{top:63px;left:auto;right:24px;min-width:288px;max-width:400px;}.gs_el_sm #gs_hdr_act_d{right:16px;}.gs_el_ta #gs_hdr_act_d{top:57px;}.gs_el_ph #gs_hdr_act_d{top:57px;min-width:280px;max-width:280px;max-width:90vw;}/* Account dialog body. */#gs_hdr_act_aw,#gs_hdr_act_ap,.gs_hdr_act_am,#gs_hdr_act_ab{display:block;padding:10px 20px;word-wrap:break-word;white-space:normal;}#gs_hdr_act_aw{background-color:#fef9db;font-size:11px;}#gs_hdr_act_ap,.gs_hdr_act_am{border-bottom:1px solid #ccc;}#gs_hdr_act_ap{padding:20px;}.gs_el_ph #gs_hdr_act_ap{padding:10px;}#gs_hdr_act_apb{margin-top:12px;}#gs_hdr_act_aa:link,#gs_hdr_act_aa:visited{float:right;margin-left:8px;color:#1a0dab;}#gs_hdr_act_aa:active{color:#d14836}.gs_hdr_act_am:link,.gs_hdr_act_am:visited{color:#222;text-decoration:none;background:#fbfbfb;}.gs_hdr_act_am:hover,.gs_hdr_act_am:focus{background:#f1f1f1;}.gs_hdr_act_am:active{background:#eee;}#gs_hdr_act_ab{background:#fbfbfb;padding:10px 0;display:table;width:100%;white-space:nowrap;}#gs_hdr_act_aba,#gs_hdr_act_abs{display:table-cell;padding:0 20px;}#gs_hdr_act_abs{text-align:right;}.gs_el_ph #gs_hdr_act_aba,.gs_el_ph #gs_hdr_act_abs{display:block;padding:10px;text-align:center;}.gs_el_ph #gs_hdr_act_aba button,.gs_el_ph #gs_hdr_act_abs button{width:100%;}#gs_hdr_act_a1,#gs_hdr_act_a2{position:absolute;top:-9px;right:7.5px;width:0;height:0;z-index:1;border:8.5px solid transparent;border-top:none;border-bottom-color:#333;border-bottom-color:rgba(0,0,0,.2);}#gs_hdr_act_a2{top:-8px;border-bottom-color:#fff;}.gs_hdr_act_mw #gs_hdr_act_a2{border-bottom-color:#fef9db;}.gs_hdr_pp{border-radius:50%;overflow:hidden;}#gs_hdr_act_ap .gs_hdr_pp,.gs_hdr_act_am .gs_hdr_pp{float:left;}#gs_hdr_act_ap .gs_hdr_pm{margin-left:116px;}.gs_hdr_act_am .gs_hdr_pm{margin:6px 0 0 58px;}#gs_ab{position:relative;height:41px;border-bottom:1px solid #e5e5e5;display:flex;white-space:nowrap;background-color:#fff;z-index:1000;}.gs_el_ta #gs_ab.gs_nta,.gs_el_ph #gs_ab.gs_nph{display:none;}#gs_ab_g{height:42px;}.gs_sth_vis #gs_ab{position:fixed;}#gs_ab_ico,#gs_ab_ttl,#gs_ab_md,#gs_ab_btns{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}.gs_el_ph #gs_ab_md{display:block;}#gs_ab_ico{width:55px;margin-right:1px;}.gs_el_sm #gs_ab_ico{width:15px;visibility:hidden;}.gs_el_ta #gs_ab_ico,.gs_el_ph #gs_ab_ico{width:55px;visibility:visible;}#gs_ab_ico .gs_ico{position:absolute;top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}#gs_ab_ttl{min-width:174px;padding-right:8px;}.gs_el_sm #gs_ab_ttl{min-width:120px;}.gs_el_ta #gs_ab_ttl,.gs_el_ph #gs_ab_ttl{min-width:0;}#gs_ab_ttl,#gs_ab_ttll{font-size:18px;color:#666;text-transform:none;}.gs_el_sm #gs_ab_ttl,.gs_el_sm #gs_ab_ttll{font-size:16px;}#gs_ab_ttll{overflow:hidden;text-overflow:ellipsis;max-width:200px;}#gs_ab_md{flex:1 0 auto;}.gs_ab_st #gs_ab_md{flex:1 1 auto;font-size:13px;line-height:17px;padding:0 8px;color:#999;overflow:hidden;text-overflow:ellipsis;}.gs_el_ph .gs_ab_st #gs_ab_md{visibility:hidden;padding:0;}#gs_ab_btns{margin-right:8px;}.gs_el_sm #gs_ab_btns{margin-right:0;}.gs_el_ta #gs_ab_btns,.gs_el_ph #gs_ab_btns{margin-right:4px;}#gs_ab_ttl:before,#gs_ab_md:before,#gs_ab_btns:before{content:\"\";display:inline-block;width:0;height:100%;vertical-align:middle;}#gs_ab_md>button,#gs_ab_btns>button,#gs_ab_md>.gs_in_ib,#gs_ab_btns>.gs_in_ib,#gs_ab_md>.gs_md_r,#gs_ab_btns>.gs_md_r,#gs_ab .gs_ab_mdw,#gs_ab .gs_ab_btw{margin:0 8px;vertical-align:middle;}#gs_ab .gs_ab_mdw,.gs_ab_btw{display:inline-block;margin:0;}#gs_ab_btns>.gs_in_ib{margin:0 16px 0 8px;}#gs_ab_btns>#gs_ab_btns_u{margin:0 12px 0 0;}.gs_el_ph #gs_ab_btns>#gs_ab_btns_u.gs_ab_btns_npu{visibility:hidden;margin-left:-41px;}#gs_ab .gs_ab_btw{margin:0 12px 0 16px;}.gs_el_ta .gs_ab_sel #gs_ab_ico,.gs_el_ph .gs_ab_sel #gs_ab_ico,.gs_el_ta .gs_ab_sel #gs_ab_ttl,.gs_el_ph .gs_ab_sel #gs_ab_ttl,.gs_el_ta .gs_ab_sel #gs_ab_btns,.gs_el_ph .gs_ab_sel #gs_ab_btns{display:none;}#gs_bdy{display:table;table-layout:fixed;width:100%;}#gs_bdy_sb{vertical-align:top;width:230px;word-wrap:break-word;display:table-cell;}.gs_el_sm #gs_bdy_sb{width:136px;}.gs_el_ta #gs_bdy_sb,.gs_el_ph #gs_bdy_sb{display:none;}.gs_bdy_sb_sec{margin:0 40px 0 56px;}.gs_el_sm .gs_bdy_sb_sec{margin:0 0 0 16px;}.gs_bdy_sb_sec:before{display:block;content:\" \";height:0;margin:13px 0;border-top:1px solid #eee;}.gs_bdy_sb_sec:first-child:before{margin:21px 0 0 0;border:none;}.gs_el_sm .gs_bdy_sb_sec:first-child:before{margin-top:15px;}#gs_bdy_sb ul{list-style-type:none;}.gs_bdy_sb_sec a:link,.gs_bdy_sb_sec a:visited{color:#222;}.gs_bdy_sb_sec a:active{color:#d14836;}.gs_bdy_sb_sel a:link,.gs_bdy_sb_sel a:visited{color:#d14836;text-decoration:none;}.gs_el_tc .gs_bdy_sb_sec li.gs_ind,.gs_el_tc .gs_bdy_sb_sec li.gs_ind a{padding-top:8px;padding-bottom:5px;}.gs_el_tc .gs_bdy_sb_sec:first-child li.gs_ind:first-child{margin-top:-8px;}#gs_bdy_sb .gs_ind,#gs_bdy_sb .gs_inw{margin-bottom:4px;}.gs_el_tc #gs_bdy_sb .gs_ind,.gs_el_tc #gs_bdy_sb .gs_inw{margin-bottom:0;}#gs_bdy_ccl{display:table-cell;vertical-align:top;padding:0 24px 0 16px;}.gs_el_sm #gs_bdy_ccl{padding:0 16px;}.gs_el_ta #gs_bdy_ccl,.gs_el_ph #gs_bdy_ccl{padding:0 16px;}.gs_el_ph #gs_bdy_ccl{}#gs_ftr_sp{height:62px;}.gs_el_sm #gs_ftr_sp{height:57px;}#gs_ftr{position:absolute;bottom:0;left:0;width:100%;white-space:nowrap;border-top:1px solid #e4e4e4;background-color:#f2f2f2;display:flex;}#gs_ftr_rt{box-sizing:border-box;max-width:100%;overflow-x:auto;margin-left:auto;padding:0 12px;}.gs_el_sm #gs_ftr_rt{padding:0 8px;}.gs_el_ph #gs_ftr_rt:after{content:\" \";position:absolute;top:0;right:0;width:16px;height:100%;background-image:linear-gradient(to right,rgba(242,242,242,0),rgba(242,242,242,1) 80%);}#gs_ftr_rt a{display:inline-block;line-height:16px;padding:12px;white-space:nowrap;}.gs_el_sm #gs_ftr_rt a{padding:12px 8px;}#gs_ftr_rt a:link,#gs_ftr_rt a:visited{color:#666}#gs_ftr_rt a:active{color:#d14836}.gs_res_sb_yyr{padding:5px 0;text-align:center;white-space:nowrap;}.gs_el_tc .gs_res_sb_yyr{padding:10px 0;}.gs_res_sb_yyr .gs_in_txt{width:48px;}#gs_res_ccl{max-width:950px;padding-top:10px;}.gs_el_sm #gs_res_ccl{padding-top:7px;}.gs_el_tc #gs_res_ccl{padding-top:6px;}.gs_el_sm.gs_el_tc #gs_res_ccl{padding-top:0;}.gs_r{position:relative;padding:11px 0 10px 0;}.gs_el_sm .gs_r{padding:7px 0 6px 0;}.gs_el_tc .gs_r{padding:15px 0;border-bottom:1px solid #eee;}.gs_rt{position:relative;font-weight:normal;font-size:17px;line-height:19px;margin-right:100px;margin-bottom:2px;}.gs_el_tc .gs_rt{margin-bottom:0;}.gs_el_ph .gs_rt{margin-right:0;}.gs_rt2{font-size:13px;font-weight:normal;}.gs_rt a:link,.gs_rt a:link b,.gs_rt2 a:link,.gs_rt2 a:link b{color:#1a0dab}.gs_rt a:visited,.gs_rt a:visited b,.gs_rt2 a:visited,.gs_rt2 a:visited b{color:#660099}.gs_rt a:active,.gs_rt a:active b,.gs_rt2 a:active,.gs_rt2 a:active b{color:#d14836}.gs_or_ggsm:focus{outline:none;}.gs_ggs{position:relative;z-index:1;float:right;margin-left:24px;min-width:200px;max-width:256px;width:200px;width:calc(100% - 620px);font-size:17px;line-height:19px;}.gs_el_sm .gs_ggs{margin-left:16px;}@media(max-width:699px){.gs_el_sm .gs_ggs{min-width:0;width:182px;}}.gs_el_ph .gs_ggs{width:72px;height:43px;}.gs_el_tc .gs_ggs{margin-top:-14px;}.gs_el_ph .gs_ggsd{position:absolute;top:-1px;right:0;width:72px;height:43px;overflow:hidden;transition:width 0s .3s,height 0s .3s;}.gs_el_ph .gs_ggsd.gs_vis{width:208px;height:88px;transition:none;}.gs_or_ggsm a{display:block;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;margin-bottom:4px;}.gs_el_tc .gs_or_ggsm a{padding:13px 8px 9px 8px;touch-action:none;background:#fff;height:19px;margin-bottom:0;}.gs_el_ph .gs_or_ggsm a{text-decoration:none;}.gs_el_ph .gs_or_ggsm a:focus{outline:none;background:#f1f1f1;}.gs_el_ph .gs_or_ggsm a:active{color:#1a0dab;}.gs_el_ph .gs_or_ggsm a:visited{color:#660099;}.gs_el_ph .gs_or_ggsm{position:absolute;top:0;right:-132px;margin-right:4px;padding:1px 0;width:200px;height:41px;transform:translate(0,0);}.gs_el_ph .gs_or_ggsm.gs_vis{right:0;height:auto;}.gs_el_ph .gs_or_ggsm>a:nth-child(2){height:0;transform:scale(1,0);transform-origin:0 0;}.gs_el_ph .gs_or_ggsm.gs_vis>a:nth-child(2){height:19px;transform:scale(1,1);}.gs_el_ph .gs_or_ggsm:before{content:\"\";position:absolute;top:0;left:-1px;right:-1px;bottom:0;box-shadow:0 2px 4px rgba(0,0,0,.2);border:1px solid #ccc;opacity:0;z-index:-1;}.gs_el_ph .gs_or_ggsm.gs_vis:before{opacity:1;transition:opacity 0s .3s ;}.gs_el_ph .gs_or_ggsm:after{content:\"\";pointer-events:none;position:absolute;top:0;left:0;right:0;bottom:0;z-index:1;background-image:linear-gradient(to left,rgba(255,255,255,1),rgba(255,255,255,1) 65%,rgba(255,255,255,0) 70%);}.gs_el_ph .gs_or_ggsm.gs_vis:after{visibility:hidden}.gs_el_ph .gs_or_ggsm.gs_vis.gs_anm{animation:gs_anm_hsli .218s ease-in-out;}.gs_el_ph .gs_or_ggsm.gs_anm{animation:gs_anm_hslo .218s ease-out;}.gs_el_ph .gs_ggs .gs_or_ggsm.gs_vis.gs_anm>a:nth-child(2){animation:gs_anm_vscli .218s ease-in;}@keyframes gs_anm_hsli{0%{transform:translate(66%,0);height:41px;}99%{transform:translate(0,0);height:41px;}100%{transform:translate(0,0);height:auto;}}@keyframes gs_anm_hslo{0%{transform:translate(-66%,0);}100%{transform:translate(0,0);}}@keyframes gs_anm_vscli{0%{transform:scale(1,0);}100%{transform:scale(1,1);}}.gs_ct1{display:inline}.gs_ct2{display:none}.gs_el_ph .gs_ct1{display:none}.gs_el_ph .gs_ct2{display:inline;font-size:13px;font-weight:normal}.gs_ri{max-width:712px}.gs_a a:link,.gs_a a:visited{text-decoration:underline;}.gs_ri .gs_fl a,.gs_a a{white-space:nowrap;}.gs_ri .gs_fl a.gs_wno{white-space:normal;}.gs_ri .gs_fl{font-size:1px;}.gs_ri .gs_fl a{font-size:13px;margin-right:12px;}.gs_ri .gs_fl a:last-child{margin-right:0;}.gs_ri .gs_fl .gs_or_sav,.gs_ri .gs_fl .gs_or_cit,.gs_ri .gs_fl .gs_or_mor{margin:-7px 6px -6px -6px;padding:7px 0 6px 0;border-radius:50%;}.gs_ri .gs_fl .gs_or_sav:hover,.gs_ri .gs_fl .gs_or_cit:hover,.gs_ri .gs_fl .gs_or_mor:hover{background-color:rgba(0,0,0,.05);}.gs_el_ph .gs_ri .gs_fl .gs_or_sav,.gs_el_ph .gs_ri .gs_fl .gs_or_cit{margin-right:4px;}.gs_el_ph .gs_ri .gs_fl .gs_or_mor{margin-right:-8px;}.gs_or_svg{position:relative;width:29px;height:16px;vertical-align:text-bottom;fill:none;stroke:#1a0dab;}.gs_or:not([data-lid=\"\"]) .gs_or_sav .gs_or_svg{fill:#1a0dab;}.gs_or[data-lid] .gs_or_ldg .gs_or_svg{fill:#eee;animation:gs_anm_spin 1.2s .5s linear infinite;}a:active .gs_or_svg,a .gs_or_svg:active,a .gs_or_svg>*:active{stroke:#dd4b39;}.gs_or_nvi,.gs_or_mvi .gs_or_mor{display:none}.gs_or_mvi .gs_or_nvi,.gs_or_mvi .gs_nph,.gs_or_mvi .gs_nta{display:inline}.gs_rs{margin:2px 0;word-wrap:break-word;}.gs_el_tc .gs_rs{margin:0}.gs_el_ta .gs_rs{margin-right:10%}@media(max-width:780px){.gs_el_ta .gs_rs,.gs_el_ta .gs_a{margin-right:100px;}}.gs_el_ph .gs_rs br,.gs_el_ta .gs_rs br{display:none}@media screen and (min-width:771px){.gs_el_ta .gs_rs br{display:block}}.gs_age{color:#777777}.gs_rs b,.gs_rt b,.gs_rt2 b{color:#000}.gs_el_tc .gs_rt a{font-size:17px;line-height:20px;padding:12px 0 9px 0;}.gs_el_tc .gs_rt2 a{font-size:14px;line-height:20px;padding:6px 0 4px 0;}.gs_el_tc .gs_a,.gs_el_tc .gs_a a,.gs_el_tc .gs_ri .gs_fl a{padding-top:7px;padding-bottom:6px;}.gs_el_tc .gs_ri .gs_fl a{line-height:29px;}.gs_el_tc .gs_ri .gs_fl{margin-bottom:-6px;}#gs_n{clear:both;margin:1.5em 0;width:600px;text-align:center;}#gs_n td{font-size:13px}#gs_n a:link,#gs_n a:visited{color:#1a0dab}#gs_n a:active{color:#d14836}#gs_nm{clear:both;position:relative;text-align:center;max-width:500px;margin:24px 50px;font-size:15px;line-height:41px;display:none;}#gs_nm button{position:absolute;top:0}#gs_nm .gs_btnPL{left:-50px}#gs_nm .gs_btnPR{right:-50px}#gs_nml{overflow:hidden;white-space:nowrap;}.gs_nma{display:inline-block;width:40px;margin:0 5px;}.gs_el_tc #gs_n,.gs_el_ta #gs_n,.gs_el_ph #gs_n{display:none}.gs_el_tc #gs_nm,.gs_el_ta #gs_nm,.gs_el_ph #gs_nm{display:block}#gs_bdy_sb_ca{margin-top:-6px;}.gs_el_tc #gs_bdy_sb_ca{margin-top:2px;}@media print{#gs_gb,#gs_hdr,#gs_ab,#gs_top #gs_bdy_sb,.gs_pda,.gs_ggs,.gs_alrt_btm,#gs_top #gs_n,#gs_top #gs_nm,#gs_ftr,#gs_top .gs_ctc,#gs_top .gs_ctu,#gs_rt_hdr,.gs_rt_hdr_ttl{display:none}#gs_top,#gs_top #gs_bdy,#gs_top #gs_res_bdy,#gs_top #gs_bdy_ccl,#gs_top .gs_r,#gs_top .gs_ri,#gs_top .gs_rs{font-size:9pt;color:black;position:static;float:none;margin:0;padding:0;width:auto;min-width:0;max-width:none;}#gs_top #gs_bdy a{color:blue;text-decoration:none}#gs_top .gs_r{margin:1em 0;page-break-inside:avoid;border:0;}#gs_top .gs_med,#gs_top .gs_rt{font-size:12pt}#gs_top .gs_a,#gs_top #gs_bdy .gs_a a{font-size:9pt;color:green}#gs_top .gs_fl,#gs_top .gs_fl a{font-size:9pt}#gs_top .gs_rs br{display:inline}}.gs_el_ph #gs_ab_ttll{max-width:98px;max-width:calc(100vw - 222px);}@media(max-width:320px){.gs_el_ph #gs_ab_ttll{max-width:98px;}}#gs_res_ab_yy-r,#gs_res_ab_ad-r{display:none;}.gs_el_ta #gs_res_ab_yy-r,.gs_el_ph #gs_res_ab_yy-r,.gs_el_ta #gs_res_ab_ad-r,.gs_el_ph #gs_res_ab_ad-r{display:inline-block;margin:0;}#gs_res_ab_yy-r:last-child{margin-right:4px;}#gs_res_ab_ad-r:last-child{margin-right:12px;}#gs_res_ab_tmn-d,#gs_res_ab_yy-d,#gs_res_ab_ad-d{white-space:normal;word-wrap:break-word;width:208px;width:-webkit-max-content;width:max-content;min-width:100px;max-width:208px;}#gs_res_ab_yy-d,#gs_res_ab_ad-d{left:auto;right:0;}.gs_res_ab_dd_bdy{padding:8px 0;box-sizing:border-box;}.gs_res_ab_dd_sec a.gs_res_ab_sel,.gs_res_ab_dd_sec a[role=menuitemradio]:active{color:#d14836;}.gs_res_ab_dd_sec:before{display:block;content:\" \";height:0;border-bottom:1px solid #e5e5e5;margin:8px 0;}.gs_res_ab_dd_sec:first-child:before{display:none;}.gs_fsvg line{stroke:#222222}a:link .gs_fsvg{fill:#1a0dab;}a:link .gs_fsvg line{stroke:#1a0dab;}a:visited .gs_fsvg{fill:#660099;}a:visited .gs_fsvg line{stroke:#660099;}a:active .gs_fsvg{fill:#d14836;}a:active .gs_fsvg line{stroke:#d14836;}a .gs_fsvg{border-bottom:1px solid transparent;}a:hover .gs_fsvg,a:focus .gs_fsvg{border-bottom-color:inherit;}.gs_fsml{font-size:13px}.gs_fscp{font-variant:small-caps}.gs_qsuggest{max-width:712px;line-height:21px;margin-bottom:2px;}.gs_r .gs_qsuggest{max-width:600px;}.gs_el_ta .gs_r .gs_qsuggest{margin-right:100px;}.gs_qsuggest h2{margin-bottom:8px;font-weight:normal;font-size:17px;}.gs_qsuggest li{display:inline-block;width:100%;font-size:15px;line-height:18px;padding:4px 0 3px;}.gs_qsuggest ul{list-style-type:none;columns:2;column-gap:40px;margin-bottom:-3px;}.gs_el_sm .gs_qsuggest ul{column-gap:16px;margin-bottom:3px;}.gs_qsuggest li:only-child{column-span:all;}.gs_qsuggest li>a{display:inline-block;max-width:100%;word-wrap:break-word;}.gs_el_tc .gs_qsuggest a{padding:8px 0 5px;}.gs_el_tc .gs_qsuggest li{padding:2px 0 1px;}.gs_el_tc .gs_qsuggest ul{margin:0;}.gs_el_tc .gs_qsuggest h2{margin:6px 0;}.gs_qsuggest_bottom h2{padding-top:16px;}.gs_el_tc .gs_qsuggest_wrap .gs_qsuggest_related h2{padding-bottom:0;}.gs_el_ph .gs_r .gs_qsuggest{margin-bottom:-15px;}.gs_el_ph .gs_qsuggest ul{columns:1;margin:0;}.gs_el_ph .gs_qsuggest li{margin:0;padding:0;position:relative;}.gs_el_ph .gs_qsuggest h2{margin:1px 0 16px;}.gs_el_ph .gs_qsuggest a{display:block;padding:11px 29px 9px 0;border-bottom:1px solid #eee;}.gs_el_ph .gs_qsuggest li:first-child a{border-top:1px solid #eee;}.gs_el_ph .gs_qsuggest_wrap.gs_r li:last-child a{border-bottom:0;}.gs_el_ph .gs_qsuggest a:link,.gs_el_ph .gs_qsuggest a:visited{color:#222;}.gs_el_ph .gs_qsuggest a:hover,.gs_el_ph .gs_qsuggest a:focus{background:#f1f1f1;text-decoration:none;outline:none;}.gs_el_ph .gs_qsuggest li>a:after{content:\"\";position:absolute;width:7px;height:7px;top:50%;margin-top:-4px;right:10px;border:2px solid #777;border-left:none;border-bottom:none;transform:rotate(45deg);}</style><script>!function(GSP){var l,aa=function(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}},ba=function(a){var b=\"undefined\"!=typeof Symbol&&Symbol.iterator&&a[Symbol.iterator];return b?b.call(a):{next:aa(a)}},ca=\"function\"==typeof Object.create?Object.create:function(a){var b=function(){};b.prototype=a;return new b},da;\n",
       "if(\"function\"==typeof Object.setPrototypeOf)da=Object.setPrototypeOf;else{var ea;a:{var fa={Ga:!0},ha={};try{ha.__proto__=fa;ea=ha.Ga;break a}catch(a){}ea=!1}da=ea?function(a,b){a.__proto__=b;if(a.__proto__!==b)throw new TypeError(a+\" is not extensible\");return a}:null}\n",
       "var ia=da,ja=function(a,b){a.prototype=ca(b.prototype);a.prototype.constructor=a;if(ia)ia(a,b);else for(var c in b)if(\"prototype\"!=c)if(Object.defineProperties){var d=Object.getOwnPropertyDescriptor(b,c);d&&Object.defineProperty(a,c,d)}else a[c]=b[c]},ka=function(){},la=function(a){var b=typeof a;if(\"object\"==b)if(a){if(a instanceof Array)return\"array\";if(a instanceof Object)return b;var c=Object.prototype.toString.call(a);if(\"[object Window]\"==c)return\"object\";if(\"[object Array]\"==c||\"number\"==typeof a.length&&\n",
       "\"undefined\"!=typeof a.splice&&\"undefined\"!=typeof a.propertyIsEnumerable&&!a.propertyIsEnumerable(\"splice\"))return\"array\";if(\"[object Function]\"==c||\"undefined\"!=typeof a.call&&\"undefined\"!=typeof a.propertyIsEnumerable&&!a.propertyIsEnumerable(\"call\"))return\"function\"}else return\"null\";else if(\"function\"==b&&\"undefined\"==typeof a.call)return\"object\";return b},ma=function(a){var b=typeof a;return\"object\"==b&&null!=a||\"function\"==b},na=function(a,b){var c=Array.prototype.slice.call(arguments,1);return function(){var d=\n",
       "c.slice();d.push.apply(d,arguments);return a.apply(this,d)}};var oa=function(){this.R=this.R;this.W=this.W};oa.prototype.R=!1;oa.prototype.ua=function(){this.R||(this.R=!0,this.aa())};oa.prototype.aa=function(){if(this.W)for(;this.W.length;)this.W.shift()()};var n=function(a,b){a.classList.add(b)},p=function(a,b){a.classList.remove(b)},q=function(a,b){return a.classList?a.classList.contains(b):!1},u=function(a,b,c){c=void 0!==c?c:!q(a,b);(c?n:p)(a,b)};var v=function(a){return 0<=(navigator.userAgent||\"\").indexOf(a)},pa=v(\"iPhone\")||v(\"iPad\")||v(\"iPod\"),qa=v(\"iPhone\")||v(\"Android\")&&v(\"Mobile\"),ra=function(){if(void 0===b){var a=window.screen;a={width:window.innerWidth,height:window.innerHeight,rb:a.width,qb:a.height}}else a=b;var b=a;a=b.width;var c=b.height,d=b.rb;b=b.qb;var e=4;if(600>a||48E4>d*b||qa)e=1;else if(982>a)e=2;else if(1136>a||590>c)e=3;return e},sa,ta=/[?&]tc=([01])/.exec(location.search||\"\");\n",
       "sa=ta?0<+ta[1]:v(\"Android\")?!0:window.matchMedia&&window.matchMedia(\"(pointer)\").matches?window.matchMedia(\"(pointer:coarse)\").matches:!v(\"Firefox\")||v(\"Mobile\")||v(\"Tablet\")?pa||\"ontouchstart\"in window||0<(navigator.msMaxTouchPoints||0):!1;var va=function(){if(void 0==ua){ua=!1;try{var a=Object.defineProperty({},\"passive\",{get:function(){ua=!0}});window.addEventListener(\"testPassive\",ka,a);window.removeEventListener(\"testPassive\",ka,a)}catch(b){}}return ua},ua;var wa=function(a){this.Fa=a},xa=new wa(\"INPUT\"),ya=new wa(\"STYLE\"),w=function(a){return document.getElementById(a)},x=function(a){return a.id||(a.id=\"gs_id\"+za++)},Aa=function(a){a=(void 0===a?null:a)||document.body;return\"rtl\"==(a?window.getComputedStyle(a,null):null).direction},Ba=function(a,b){var c=[];a=a.elements;for(var d=a.length,e=0;e<d;e++){var f=a[e],h=encodeURIComponent(f.name||\"\"),g=f.type;!h||b&&!b(f)||f.disabled||!(\"checkbox\"!=g&&\"radio\"!=g||f.checked)||c.push(h+\"=\"+encodeURIComponent(f.value||\n",
       "\"\"))}return c.join(\"&\")},Ca=function(a){var b=a.elements.scipsc;b||(b=document.createElement(xa.Fa),b.type=\"hidden\",b.name=\"scipsc\",a.appendChild(b));return b},Ea=function(a){a.match(Da)&&(window.location.href=a)},za=100,Fa=/\\S+/g,Da=/^(?:https?:|[^:/?#]*(?:[/?#]|$))/i,Ga=/^(?:#|\\/[a-z0-9_-]*(?:[?].*)?$)/i;var Ia=function(a){return a.hasOwnProperty(\"gs_uid\")?a.gs_uid:a.gs_uid=++Ha},Ha=0;var z=function(){this.f=[];this.O={};this.ka=this.A=0};z.prototype.add=function(a){var b=Ia(a);this.O[b]||(this.f.push(a),this.O[b]=this.f.length,++this.A)};z.prototype.remove=function(a){a=Ia(a);var b=this.O[a];b&&(this.f[b-1]=null,delete this.O[a],2*--this.A<this.f.length&&!this.ka&&Ja(this))};z.prototype.v=function(a){var b=this.f;try{++this.ka;for(var c=0;c<b.length;c++){var d=b[c];d&&d.apply(null,arguments)}}finally{!--this.ka&&2*this.A<b.length&&Ja(this)}};\n",
       "var Ja=function(a){var b=a.f,c=b.length;a=a.O;for(var d=0,e=0;e<c;e++){var f=b[e];f&&(b[d]=f,a[Ia(f)]=++d)}b.length=d};var A=function(a,b,c,d,e){Ka(a,b,c,void 0===d?!1:d,void 0===e?!1:e,La)},B=function(a,b,c,d){Ka(a,b,c,void 0===d?!1:d,!1,Ma)},Na=function(a,b,c,d,e){function f(h){B(a,b,f,d);c(h)}d=void 0===d?!1:d;A(a,b,f,d,void 0===e?!1:e);return f},Oa=function(a,b,c,d,e){var f=Na(a,b,function(g){clearTimeout(h);c(g)}),h=setTimeout(function(){B(a,b,f);e&&e()},d)},D=function(a){Pa?Pa.add(a):a()},Qa=window.requestAnimationFrame?function(a){window.requestAnimationFrame(a)}:function(a){setTimeout(a,33)},Ra=function(a){a.stopPropagation();\n",
       "a.preventDefault()},Sa=function(a){return(a.ctrlKey?1:0)|(a.altKey?2:0)|(a.metaKey?4:0)|(a.shiftKey?8:0)};function Ta(a,b){return(b=b&&va())?{passive:b,capture:a}:a}function La(a,b,c,d,e){a.addEventListener(b,c,Ta(d,e))}function Ma(a,b,c,d){a.removeEventListener(b,c,d)}function Ka(a,b,c,d,e,f){if(\"string\"===typeof b)f(a,b,c,d,e);else for(var h=b.length,g=0;g<h;g++)f(a,b[g],c,d,e)}function Ua(){Pa.v();Pa=null}function Va(){\"complete\"==document.readyState&&(B(document,\"readystatechange\",Va),Ua())}\n",
       "var Pa,Wa=!!document.attachEvent,Xa=document.readyState;if(Wa?\"complete\"!=Xa:\"loading\"==Xa)Pa=new z,Wa?A(document,\"readystatechange\",Va):Na(document,\"DOMContentLoaded\",Ua);function Ya(){Na(document,[\"mousedown\",\"touchstart\"],function(){u(document.documentElement,\"gs_pfcs\",!0);A(document,\"keydown\",Za,!0)},!0,!0)}function Za(a){9==a.keyCode&&(u(document.documentElement,\"gs_pfcs\",!1),B(document,\"keydown\",Za,!0),Ya())}Ya();var ab=function(a,b,c,d,e){var f=w(a);$a(f,function(){n(f,\"gs_vis\");b&&b()},function(){p(f,\"gs_vis\");c&&c()},d,e)},$a=function(a,b,c,d,e){var f=x(a);if(!F[f]){var h=document.activeElement;bb(cb(a),!0);b&&b();H.push(function(g){delete F[f];try{g||(e||h).focus()}catch(k){}c&&c()});F[f]=H.length;h&&a.contains(h)||setTimeout(function(){var g=d,k=g&&\"text\"==g.type;if(!g||k&&sa)g=a;try{g.focus(),k&&(g.value=g.value)}catch(t){}},0)}},I=function(a){bb((F[a]||1E6)-1,!1)};\n",
       "function db(a){a=void 0===a?!1:a;H.pop()(a)}function bb(a,b){for(b=void 0===b?!1:b;H.length>a;)db(b||H.length>a+1)}function cb(a){for(var b=0;a&&!(b=F[a.id]||0);)a=a.parentNode;return b}var H=[],F={};A(document,\"click\",function(a){var b=H.length;b&&!Sa(a)&&b>cb(a.target)&&db(!0)});A(document,\"keydown\",function(a){27==a.keyCode&&!Sa(a)&&H.length&&db()});\n",
       "A(document,\"focus\",function(a){var b=H.length;if(b)for(var c=cb(a.target);c<b;){var d=\"\",e;for(e in F)if(F[e]==b){d=e;break}a:{d=(w(d).getAttribute(\"data-wfc\")||\"\").match(Fa)||[];for(var f=0;f<d.length;f++){var h=w(d[f]);if(h&&h.offsetWidth){d=h;break a}}d=void 0}if(d){Ra(a);d.focus();break}else db(!0),--b}},!0);function eb(a,b,c,d){if((void 0===d?0:d)||!(c in fb)){a=a&&a.getItem(c);if(a)try{var e=JSON.parse(a)}catch(f){}b[c]=e}return b[c]}function gb(a,b,c,d){b[c]=d;try{a&&a.setItem(c,JSON.stringify(d))}catch(e){}}var ib=function(a,b){return eb(hb,fb,a,void 0===b?!1:b)},fb={},hb,jb={},kb;try{hb=window.localStorage,kb=window.sessionStorage}catch(a){};function lb(a){return\"object\"==typeof a?a:null}\n",
       "var rb=function(a,b){b=mb(b);a=nb(a);a=ob(a)||\"#\";pb=lb(b);qb?window.history.pushState(b,\"\",a):window.location.assign(a)},sb=function(a,b){b=mb(b);a=nb(a);a=ob(a)||\"#\";pb=lb(b);qb?window.history.replaceState(b,\"\",a):window.location.replace(a)},ob=function(a){var b=[],c;for(c in a)b.push(encodeURIComponent(c)+\"=\"+encodeURIComponent(a[c]));return(a=b.sort().join(\"&\"))?\"#\"+a:\"\"},tb=function(a){var b={};a=a.split(\"&\");for(var c=0;c<a.length;c++){var d=a[c],e=d.indexOf(\"=\");if(e+1){var f=d.substr(0,e);\n",
       "d=d.substr(e+1)}else f=d,d=\"\";f&&(b[decodeURIComponent(f)]=decodeURIComponent(d))}return b},ub=function(){var a=window.location.hash,b=a.indexOf(\"#\")+1;return tb(b?a.substr(b):\"\")};function vb(a,b){for(var c in b){var d=b[c];void 0!==d?a[c]=d:delete a[c]}}function nb(a){var b=ub();vb(b,a);return b}function mb(a){var b=pb||lb(window.history.state),c={},d;for(d in b)c[d]=b[d];vb(c,a);return c}function wb(){setTimeout(function(){if(!xb){var a=window.history.state;xb=!0;pb=lb(a);yb.v()}zb=!1},0)}\n",
       "var yb=new z,pb,xb=!1,zb=!0,qb=\"pushState\"in window.history,Ab;if(\"undefined\"==typeof GSP)Ab=!1;else{var Bb=.001*Date.now(),Cb=GSP.eventId,Db=!1,J=eb(kb,jb,\"nh\",!1);J instanceof Array||(J=[]);for(var Eb=J.length,Fb=0,Gb=0;Gb<Eb;Gb++){var Jb=J[Gb];if(Jb instanceof Array&&2==Jb.length){var Kb=Jb[1]==Cb;Db=Db||Kb;10>=Eb-Gb&&+Jb[0]>Bb-86400&&!Kb&&(J[Fb++]=Jb)}}J.length=Fb;J.push([Bb,Cb]);gb(kb,jb,\"nh\",J);Ab=Db}var Lb=Ab;\"onpageshow\"in window?A(window,\"pageshow\",wb):D(wb);\n",
       "A(window,qb?\"popstate\":\"hashchange\",function(a){\"loading\"!=document.readyState&&(a=a.state,xb=!0,pb=lb(a),yb.v())});var Nb=function(a){var b=void 0===b?\"\":b;var c=void 0===c?\"\":c;var d=void 0===d?[]:d;w(\"gs_alrt_m\").innerHTML=a;w(\"gs_alrt\").action=c.match(Da)?c:\"\";w(\"gs_alrt_l\").textContent=b;a=w(\"gs_alrt_h\");a.innerHTML=\"\";for(var e in d)b=document.createElement(\"input\"),b.type=\"hidden\",b.name=e,b.value=d[e],a.appendChild(b);Mb()};function Mb(){var a=w(\"gs_alrt_w\");n(a,\"gs_anm\");n(a,\"gs_vis\");A(document,\"click\",Ob);A(window,\"scroll\",Ob);clearTimeout(Pb);Pb=setTimeout(Ob,6E4);++Qb;setTimeout(Rb,0)}\n",
       "function Ob(){Qb||(B(document,\"click\",Ob),B(window,\"scroll\",Ob),clearTimeout(Pb),Pb=void 0,p(w(\"gs_alrt_w\"),\"gs_vis\"))}function Rb(){Qb=0}var Pb,Qb=0;D(function(){var a=w(\"gs_alrt_m\");a&&(a.innerHTML&&!Lb&&Mb(),A(window,\"pagehide\",function(){Qb=0;Ob();p(w(\"gs_alrt_w\"),\"gs_anm\")}))});var K=function(a,b,c){b=void 0===b?Sb:b;c=void 0===c?!1:c;b.length=0;a.normalize&&(a=a.normalize(\"NFKD\").replace(Tb,\"\"));return a.toLowerCase().replace(Ub,function(d,e){b.length||e&&b.push(0);b.push(d.length);return e&&(!c||e+d.length<a.length)?\" \":\"\"})},Wb=function(a,b,c,d,e){var f=c.indexOf(a),h=\"\",g=\"\";0<f&&(f=c.indexOf(\" \"+a));!(a&&f+1)||void 0!==e&&e&&f||(f+=\" \"==c[f],h=Vb(c.substr(0,f),b,d),g=Vb(c.substr(0,f+a.length),b,d).substr(h.length));return[h,g,b.substr(h.length+g.length)]};\n",
       "function Vb(a,b,c){var d=a.length;for(a=a.split(\" \").length;a--;)d+=(c[a]||0)-1;return b.substr(0,d+1)}var Sb=[],Tb=/[\\u0300-\\u036f]+/g,Ub=/[\\s\\x00-/:-@[-`{-\\u00bf\\u2000-\\u206f\\u2e00-\\u2e42\\u3000-\\u303f\\uff00-\\uff0f\\uff1a-\\uff20\\uff3b-\\uff40\\uff5b-\\uff65]+/g,Xb=/^[\\d\\s]*[\\u0590-\\u08ff\\ufb1d-\\ufdff\\ufe70-\\ufefc]/;var Yb=function(a,b,c,d,e,f,h){e=void 0===e?[]:e;this.i=a;this.source=b;this.wa=void 0===c?\"\":c;this.g=void 0===d?\"\":d;this.H=e;this.mb=void 0===f?\"\":f;this.za=void 0===h?\"\":h},Zb=function(a){var b=a.indexOf(\"|\"),c=a.substr(0,b),d=K(c);a=a.substr(b+1);b=[];return new Yb(a,0,\"\",K(a,b),b,c,d)},$b=function(a){var b=[];return new Yb(a,2,\"\",K(a,b),b)};var ac=function(){this.Ha=100;this.A=0;this.G=this.D=null;this.T=Object.create(null)};ac.prototype.get=function(a){if(a=this.T[a])return bc(this,a),a.value};ac.prototype.set=function(a,b){var c=this.T[a];c?(c.value=b,bc(this,c)):(this.A>=this.Ha&&(delete this.T[this.G.key],this.G=this.G.F,this.G.V=null,--this.A),c=this.T[a]={key:a,value:b,V:this.D,F:null},this.D?this.D.F=c:this.G=c,this.D=c,++this.A)};var bc=function(a,b){var c=b.V,d=b.F;d&&((d.V=c)?c.F=d:a.G=d,a.D.F=b,b.V=a.D,b.F=null,a.D=b)};var cc=function(a,b,c){var d=new XMLHttpRequest;d.onreadystatechange=function(){if(4==d.readyState){var e=d.status,f=d.responseText,h=d.responseURL,g=window.location,k=g.protocol;g=\"//\"+g.host+\"/\";h&&h.indexOf(k+g)&&h.indexOf(\"https:\"+g)&&(e=0,f=\"\");c(e,f)}};d.open(b?\"POST\":\"GET\",a,!0);d.setRequestHeader(\"X-Requested-With\",\"XHR\");b&&d.setRequestHeader(\"Content-Type\",\"application/x-www-form-urlencoded\");b?d.send(b):d.send();return d},dc=function(a){a&&(a.onreadystatechange=ka,a.abort())};var ec=function(a,b){this.nb=a;this.Ca=b;this.N=this.K=0;this.ma=this.na=\"\";this.oa=void 0;this.ta=new ac},hc=function(a,b,c){var d=b?a.ta.get(fc(a,b,c)):[];d?a.Ca(b,c,d):(a.na=b,a.ma=c,10<=a.K||3<=a.N||(a.K?void 0!==a.oa||(a.oa=setTimeout(function(){gc(a)},100<<Math.max(a.K-4,0))):gc(a)))},gc=function(a){a.oa=void 0;var b=a.na,c=a.ma;a.na=a.ma=\"\";if(b){++a.K;var d=new XMLHttpRequest;d.onreadystatechange=function(){if(d&&4==d.readyState){var e=d.status;200==e&&a.ha(b,c,d.responseText);d=null;ic(a,\n",
       "e)}};d.ontimeout=function(){d&&(d=null,ic(a))};d.open(\"GET\",fc(a,b,c),!0);d.timeout=3E4;d.send()}},ic=function(a,b){b=void 0===b?0:b;--a.K;var c=3*(403==b)+(499<b&&600>b);a.N+=c;c&&setTimeout(function(){a.N-=c},3E4)};ec.prototype.ha=function(a,b,c){try{var d=JSON.parse(c)}catch(h){}if(d&&\"object\"==typeof d&&(c=d.l,c instanceof Array)){d=[];for(var e=c.length,f=0;f<e;f++)d.push(Zb(\"\"+c[f]));this.ta.set(fc(this,a,b),d);this.Ca(a,b,d)}};\n",
       "var fc=function(a,b,c){return\"/scholar_complete?\"+encodeURIComponent(a.nb)+\"=\"+encodeURIComponent(b)+\"&\"+c};var kc=function(a){this.Da=\"H:\"+a;this.o=[];this.lb=.001*Date.now();a=ib(this.Da);a instanceof Array||(a=[]);for(var b=this.o,c={\"\":1},d=0;d<a.length&&50>b.length;d++){var e=new jc(a[d]);c.hasOwnProperty(e.g)||(c[e.g]=1,b.push(e))}};\n",
       "kc.prototype.add=function(a,b,c){c=(void 0===c?0:c)||.001*Date.now();b=(void 0===b?0:b)||c;a=new jc([0,0,a]);if(a.g){for(var d=this.o,e=d.length,f=0;f<e&&d[f].g!=a.g;)++f;f<e||d.push(a);e=d[f];if(!(2>b-e.m)){e.m=b;e.i=a.i;e.H=a.H;for(e.w=Math.min(e.w+lc(b),10*lc(c));f&&mc(d[f],d[f-1]);)a=d[f],d[f]=d[f-1],d[--f]=a;d.splice(50,1);nc(this)}}};kc.prototype.remove=function(a){for(var b=this.o,c=b.length,d=0;d<c;d++)if(b[d].i==a){b.splice(d,1);nc(this);break}};\n",
       "var nc=function(a){for(var b=[],c=a.o,d=c.length,e=0;e<d;e++)b.push(c[e].encode());gb(hb,fb,a.Da,b)};function lc(a){return Math.exp(.0231*(Math.max(a-1422777600,0)/86400|0))}var jc=function(a){a instanceof Array||(a=oc);this.m=+a[0]||0;this.w=+a[1]||0;this.i=\"\"+a[2];this.H=[];this.g=K(this.i,this.H,!0)};jc.prototype.encode=function(){return[this.m,this.w,this.i]};\n",
       "var mc=function(a,b){var c=a.w-b.w;return 0<c||!c&&a.m>b.m},oc=[0,0,\"\"],pc=function(a,b,c){this.m=a;this.w=b;this.i=c},qc=function(a,b){var c=a.w-b.w;return 0<c||!c&&a.m>b.m};var rc=function(a){this.j=a};function sc(a){var b=document.createElement(\"b\");b.textContent=a;return b};var tc=function(a,b,c){this.type=a;this.currentTarget=this.target=b;this.b=void 0===c?null:c;this.pa=!1};tc.prototype.stopPropagation=function(){this.b&&this.b.stopPropagation();this.pa=!0};var L=function(a){a.b&&Ra(a.b);a.pa=!0};var N=function(a,b){this.ra=a;this.kb=b},uc=function(a){this.ra=a},vc=function(a,b){O(a,\"click\",b)},P=function(a,b){var c=b.length;if(c){var d=Ia(a),e=wc[d];if(!e){e=wc[d]=[];d=xc(b[0].ra);for(var f in d){var h=yc[f];h||(h=yc[f]=Object.create(null));for(var g in d[f]){var k=h[g];k||(k=h[g]=[]);k.push(a)}}zc(a,e,b[0],Ac);for(f=1;f<c;f++)zc(a,e,b[f],Bc)}}},Q=function(a,b,c){Cc(new tc(a,b,void 0===c?null:c))};\n",
       "function O(a,b,c){var d=Dc;\"string\"===typeof b&&(Ec[0]=b,b=Ec);var e=b.length;a=xc(a);for(var f in a)for(var h in a[f])for(var g=0;g<e;g++)d(f,h,b[g],c)}function xc(a){\"string\"===typeof a&&(Fc[0]=a,a=Fc);for(var b=a.length,c=Object.create(null),d=0;d<b;d++){var e=a[d],f=e.charAt(0),h=e.substr(1);if(\"#\"!=f&&\".\"!=f||!h)throw Error(\"bad selector: \"+e);(e=c[f])||(e=c[f]=Object.create(null));e[h]=!0}return c}\n",
       "function Dc(a,b,c,d){var e=Gc[c];e||(\"touchstart\"!=c&&\"mouseover\"!=c&&\"mouseout\"!=c&&A(document,c,Hc,\"focus\"==c||\"blur\"==c),e=Gc[c]=Object.create(null));(c=e[a])||(c=e[a]=Object.create(null));(a=c[b])||(a=c[b]=new z);a.add(d)}function Hc(a){var b=a.target;b&&3==b.nodeType&&(b=b.parentNode);Cc(new tc(a.type,b,a))}\n",
       "function Cc(a){for(var b=a.target;b&&b!=document&&!b.disabled&&!q(b,\"gs_dis\");){a.currentTarget=b;var c=b.id;if(c&&!Ic(\"#\",c,a))break;c=b.classList||[];for(var d=c.length,e=0;e<d;e++)if(!Ic(\".\",c[e],a))return;b=b.parentNode}}function Ic(a,b,c){var d=Gc[c.type];(b=(a=d&&d[a])&&a[b])&&b.v(c);return!c.pa}function zc(a,b,c,d){var e=c.ra;c=c.kb;for(var f in c)O(e,f,na(d,a,c[f])),b.push(new uc(e))}function Ac(a,b,c){var d=c.currentTarget;a=Jc(a,d)||a;a=Kc(a,d);b.call(a,c)}\n",
       "function Bc(a,b,c){a:{for(var d=c.currentTarget;d&&d!=document;){var e=Jc(a,d);if(e){a=Kc(e,d);break a}d=d.parentNode}a=void 0}a&&b.call(a,c)}function Kc(a,b){var c=Lc(b),d=Mc[c];d||(d=Mc[c]=[]);for(var e=d.length,f=0;f<e;f++){var h=d[f];if(h instanceof a)return h}b=new a(b);d.push(b);a=Ia(a);(d=Nc[a])||(d=Nc[a]=[]);d.push(c);return b}function Jc(a,b){var c,d=b.id;d&&(c=Oc(a,c,\"#\",d));b=b.classList||[];d=b.length;for(var e=0;e<d;e++)c=Oc(a,c,\".\",b[e]);return c}\n",
       "function Oc(a,b,c,d){c=(d=(c=yc[c])&&c[d])?d.length:0;for(var e=0;e<c;e++){var f=d[e];!(f===a||f.prototype instanceof a)||b&&!(f===b||f.prototype instanceof b)||(b=f)}return b}function Lc(a){var b=a.getAttribute(\"data-duid\");b||a.setAttribute(\"data-duid\",b=\"\"+Pc++);return b}var Gc=Object.create(null),Fc=[\"\"],Ec=[\"\"],yc=Object.create(null),wc=Object.create(null),Nc=Object.create(null),Mc=Object.create(null),Pc=100;window.gs_evt_dsp=Hc;var Qc=function(a){if(\"string\"===typeof a){var b=a.charAt(0),c=a.slice(1);if(\"#\"==b)a=function(d){return d.id==c&&0<d.offsetWidth};else if(\".\"==b)a=function(d){return q(d,c)&&0<d.offsetWidth};else throw Error(\"bad selector: \"+a);}return a},Rc=function(a,b){return a&&((void 0===b?0:b)?a.lastElementChild:a.firstElementChild)},Sc=function(a,b){return a&&((void 0===b?0:b)?a.previousElementSibling:a.nextElementSibling)},Uc=function(a,b,c,d){d=void 0===d?!1:d;return Tc(a,b,Qc(c),d,!1)};\n",
       "function Tc(a,b,c,d,e){for(var f;b&&a;){if(c(b)){if(e)return b}else for(f=Rc(b,d);f;f=Sc(f,d))if(e=Tc(f,f,c,d,!0))return e;for(e=!0;;){if(b==a)return null;f=b.parentNode;if(b=Sc(b,d))break;b=f}}return null};var R=function(a){var b=this;this.a=a.querySelector(\".gs_in_ac\");this.j=a.querySelector(\".gs_md_ac\");this.J=this.C=!1;this.o=new kc(this.a.name);this.Ka=new ec(this.a.name,function(c,d,e){d==b.X&&Vc(b,c)&&(c.length>=b.Y.length||!Vc(b,b.Y))&&(b.Y=c,b.qa=e,Wc(b))});this.Aa=0;this.ob=new rc(this.j);this.xa=[];this.ya=[];this.Y=\"\";this.qa=[];this.X=\"\";this.B=this.a.value;Xc(this);A(this.a.form,[\"change\",\"gs-change\"],function(){Xc(b)})},Yc=function(a){return\"block\"==a.j.style.display},$c=function(a){if(Yc(a)){var b=\n",
       "Zc(a);b&&p(b,\"gs_sel\");a.C=a.J=!1;a.j.style.display=\"none\"}},ad=function(a,b,c){c=void 0===c?[]:c;a.xa=c;c=a.o;var d=K(b);var e=\" \"+d,f=d.length,h=d.split(\" \").length,g=.1/lc(c.lb),k=c.o,t=k.length;c=[];for(var m=0;m<t;m++){var y=k[m],r=y.g,E=r.indexOf(d);if(!(0>E)){var G=10;E&&(E=r.lastIndexOf(e),G=+(0<=E));r=G*(2*(h-1)+(1+(\" \"==(r[E+f]||\" \"))))/h;E=y.w*g;if(r=d?r*E:1){y=new pc(y.m,r,y.i);for(r=0;r<c.length&&!qc(y,c[r]);)++r;3>r&&c.splice(r,0,y);c.splice(3,1)}}}d=[];for(e=0;e<c.length;e++)d.push($b(c[e].i));\n",
       "a.ya=d;hc(a.Ka,b,a.X);Wc(a)},Vc=function(a,b){return 0==K(a.a.value).indexOf(K(b))},bd=function(a){var b=a.a.value;a.B=b;Xc(a);var c=[],d=a.a.getAttribute(\"data-iq\")||\"\",e=a.a.getAttribute(\"data-is\");if(d==b&&e){d=document.querySelectorAll(e);e=d.length;for(var f=0;f<e&&10>f;f++){var h=d[f];c.push(new Yb(h.textContent,1,h.innerHTML))}}ad(a,b,c)},Wc=function(a){a.Aa++||Qa(function(){a.Aa=0;var b=a.xa;var c=a.qa;if(b.length)b=b.slice(0,10);else{b=a.ya.slice(0,3);var d=c.length&&c[0].za,e=d?3:10,f=b.length;\n",
       "if(!f||!d){for(d=Object.create(null);f--;)d[b[f].g]=!0;for(f=0;f<c.length&&b.length<e;f++){var h=c[f];d[h.g]||b.push(h)}}}c=b;var g=a.a.value,k=a.ob.j.firstElementChild;h=k.querySelector(\".gs_md_acs\");b=k.querySelector(\"ul\");e=(e=b.querySelector(\".gs_sel\"))?e.getAttribute(\"data-q\"):\"\";f=c.length;var t=[];d=K(g,t);b.innerHTML=\"\";if(f){var m=c[0].za,y=m&&\"gs_md_acp\";\"string\"===typeof y||(y=y.join(\" \"));k.className!=y&&(k.className=y);g=Wb(m,g,d,t,!0);h.textContent=g[0]+g[1];g=g[2];d=K(g,t);for(h=0;h<\n",
       "f;h++){m=c[h];k=document.createElement(\"li\");t=(m.mb||\"\")+m.i;k.className=\"gs_md_ac_li\";k.setAttribute(\"data-q\",t);k.setAttribute(\"onclick\",\"\");if(m.wa)k.innerHTML=m.wa;else{g=Wb(d,m.i,m.g,m.H);if(!g[1]){for(g=0;m.g[g]==d[g];)++g;g=Wb(d.substr(0,g),m.i,m.g,m.H)}g[0]&&k.appendChild(sc(g[0]));k.appendChild(document.createTextNode(g[1]));g[2]&&k.appendChild(sc(g[2]));2==m.source&&(n(k,\"gs_md_ac_lh\"),g=document.createElement(\"span\"),g.className=\"gs_ico gs_ico_X gs_ico_Xt\",k.appendChild(g))}t==e&&n(k,\n",
       "\"gs_sel\");b.appendChild(k)}}c=c.length&&document.activeElement==a.a;c!=Yc(a)&&(c?Yc(a)||(a.C=a.J=!1,a.j.style.display=\"block\"):$c(a))})},Zc=function(a){return a.j.querySelector(\".gs_sel\")},dd=function(a,b){var c=a.a.getAttribute(\"data-oq\")||\"oq\",d=a.a.form,e=d.elements[c];e||(e=document.createElement(\"input\"),e.name=c,e.type=\"hidden\",d.appendChild(e));e.value=a.B;a.a.value=cd(b)},ed=function(a){Q(\"gs-change\",a.a)};l=R.prototype;\n",
       "l.$a=function(){var a=this.a.value;this.B!=a&&(this.B=a,ad(this,a),fd(this.a,K(a).match(Xb)?\"rtl\":\"ltr\"))};\n",
       "l.fa=function(a){if(!this.J){var b=a.b,c=b.keyCode;b=Sa(b);var d;13!=c||b?27!=c||b?38!=c&&40!=c||b?(46==c&&!b||88==c&&(1==b||4==b))&&(d=Zc(this))&&q(d,\"gs_md_ac_lh\")&&(this.a.selectionStart||0)>=this.a.value.length&&(this.o.remove(cd(d)),ad(this,this.a.value=this.B),L(a),ed(this)):(Yc(this)?((d=Zc(this))&&p(d,\"gs_sel\"),(d=Uc(this.j,d||this.j,\".gs_md_ac_li\",38==c))?(n(d,\"gs_sel\"),this.a.value=cd(d)):this.a.value=this.B,ed(this)):bd(this),L(a)):Yc(this)&&(this.a.value=this.B,$c(this),L(a),ed(this)):\n",
       "((d=Zc(this))&&dd(this,d),$c(this),ed(this))}};l.ga=function(){var a=this;document.activeElement==this.a?bd(this):(clearTimeout(this.la),this.la=setTimeout(function(){a.la=void 0},500))};l.Za=function(){void 0!==this.la&&bd(this)};l.Na=function(){var a=this;setTimeout(function(){$c(a)},this.C?300:0)};l.Ma=function(a){this.C&&L(a)};l.Xa=function(){this.J=!0};l.Wa=function(){this.J=!1};var Xc=function(a){var b=a.a,c=Ba(b.form,function(d){return d!=b});c!=a.X&&(a.X=c,a.Y=\"\",a.qa=[])};l=R.prototype;\n",
       "l.Ra=function(a){this.C=!0;L(a)};l.Sa=function(){this.C=!0};l.da=function(){this.C=!1};l.Oa=function(a){var b=a.currentTarget;if(q(a.target,\"gs_ico_X\"))this.o.remove(cd(b)),ad(this,this.a.value=this.B);else{dd(this,b);$c(this);this.a.blur();var c=this.a.form;setTimeout(function(){c.submit()},0)}ed(this)};l.Qa=function(a){a=a.currentTarget;if(!q(a,\"gs_sel\")){var b=Zc(this);b&&p(b,\"gs_sel\");n(a,\"gs_sel\")}};l.Pa=function(a){p(a.currentTarget,\"gs_sel\")};\n",
       "var gd=[new N(\".gs_in_acw\",{}),new N(\".gs_in_ac\",{input:R.prototype.$a,keydown:R.prototype.fa,mousedown:R.prototype.ga,focus:R.prototype.Za,blur:R.prototype.Na,beforedeactivate:R.prototype.Ma,compositionstart:R.prototype.Xa,compositionend:R.prototype.Wa}),new N(\".gs_md_ac\",{mousedown:R.prototype.Ra,touchstart:R.prototype.Sa,mouseup:R.prototype.da,touchend:R.prototype.da,touchcancel:R.prototype.da}),new N(\".gs_md_ac_li\",{click:R.prototype.Oa,mouseover:R.prototype.Qa,mouseout:R.prototype.Pa})];\n",
       "function cd(a){return a.getAttribute(\"data-q\")||\"\"}function fd(a,b){a.getAttribute(\"dir\")!=b&&(a.setAttribute(\"dir\",b),a.parentNode.setAttribute(\"dir\",b),a.parentNode.querySelector(\".gs_md_ac\").setAttribute(\"dir\",b))}function hd(){for(var a=document.querySelectorAll(\".gs_in_ac\"),b=a.length,c=0;c<b;c++){var d=a[c],e=d.getAttribute(\"data-iq\")||\"\";d.value=e;fd(d,K(e).match(Xb)?\"rtl\":\"ltr\");Q(\"gs-change\",d);e=d.getAttribute(\"data-oq\")||\"oq\";(e=d.form.elements[e])&&d.form.removeChild(e)}};var id=function(a){return!!q(a,\"gs_sel\")+2*!!q(a,\"gs_par\")},jd=[\"false\",\"true\",\"mixed\"];var kd=function(a){var b=window,c=this;this.f=new z;this.Ba=0;this.sa=[b,a,function(){c.Ba++||Qa(d)},!1];var d=function(){c.Ba=0;c.f.v()}};kd.prototype.addListener=function(a){this.f.A||A.apply(null,this.sa);this.f.add(a)};kd.prototype.removeListener=function(a){this.f.remove(a);this.f.A||B.apply(null,this.sa)};var md=new kd(\"scroll\"),od=new kd(\"resize\");var pd=new z;function qd(){var a=document.documentElement,b=ra();b={gs_el_ph:1==b,gs_el_ta:2==b,gs_el_sm:4!=b,gs_el_tc:sa||1==b};var c;for(c in b){var d=b[c];if(q(a,c)!=d){var e=!0;u(a,c,d)}}e&&pd.v()}u(document.documentElement,\"gs_el_ios\",pa);qd();od.addListener(qd);A(window,[\"pageshow\",\"load\"],qd);var Ed=function(a,b,c,d){function e(){var C=E&&q(h,\"gs_el_ph\");u(y,\"gs_vis\",!C);h.style.overflowY=Ge&&!C?\"scroll\":\"\"}function f(){var C=h.clientHeight,M=+r.getAttribute(\"data-h\");M||(t.style.maxHeight=\"none\",M=k.offsetHeight);M=Math.max((C-M)/2,10);C=Math.max(C-48-2*M,10);var ld=E&&q(h,\"gs_el_ph\");k.style.top=ld?\"auto\":M+\"px\";t.style.maxHeight=ld?\"none\":C+\"px\";rd(t)}b=void 0===b?\"\":b;c=void 0===c?\"\":c;d=void 0===d?\"\":d;var h=document.documentElement,g=w(\"gs_top\"),k=w(a),t=w(a+\"-bdy\"),m=w(k.getAttribute(\"data-cid\")||\n",
       "k.id+\"-bdy\")||k,y=w(k.getAttribute(\"data-shd\")||\"gs_md_s\"),r=sd(k),E=!!r&&q(r,\"gs_md_wmw\"),G=window.pageYOffset,Ge=g.scrollHeight>h.clientHeight,Hb=!!F[a],Ib=Hb?\"\":S,nd=b&&\"#\"!=b[0]&&!d,Ie=a==S&&b==td&&c==T;nd?(Hb?u(m,\"gs_md_ldg\",!0):ud(k,m,'<div class=\"gs_md_prg\">'+w(\"gs_md_ldg\").innerHTML+\"</div>\"),Q(\"gs-md-ldin\",m)):(d&&ud(k,m,d),Q(\"gs-md-lded\",m));Ib&&(++vd,I(Ib),--vd);S=a;td=b;T=c;wd=d;Ie||vd||(xd+=1,(Ib?sb:rb)(yd(),zd()));Hb||$a(k,function(){r&&n(r,\"gs_vis\");n(k,\"gs_vis\");u(k,\"gs_abt\",zb);Ad(a);\n",
       "pd.add(e);e();r&&t&&(f(),od.addListener(f));n(g,\"gs_nscl\");g.style.top=-G+\"px\"},function(){pd.remove(e);od.removeListener(f);r&&p(r,\"gs_vis\");p(k,\"gs_vis\");p(k,\"gs_abt\");p(y,\"gs_vis\");h.style.overflowY=\"\";p(g,\"gs_nscl\");g.style.top=\"auto\";dc(U);U=null;window.scrollTo(0,G);S=td=T=wd=\"\";var C=xd;xd=0;vd||(0<C?window.history.go(-C):sb(yd(),zd()))},Bd(k),Cd(k));nd&&(dc(U),U=null,U=cc(b,c,function(C,M){U=null;C=200==C;ud(k,m,C?M:Dd());C&&a==S&&b==td&&c==T&&(wd=M,sb(yd(),zd()));Q(\"gs-md-lded\",m)}))};\n",
       "function sd(a){a=a.parentNode;return q(a,\"gs_md_wnw\")?a:null}function Bd(a){return(a=a.getAttribute(\"data-ifc\"))?w(a):null}function Cd(a){return(a=a.getAttribute(\"data-cfc\"))?w(a):null}\n",
       "function ud(a,b,c){u(b,\"gs_md_ldg\",!1);for(var d=b.querySelectorAll(\"[data-duid]\"),e=d.length,f={},h=0;h<e;h++){for(var g=Lc(d[h]),k=Mc[g],t=k?k.length:0,m=0;m<t;m++){var y=k[m],r=Ia(y.constructor),E=f[r];E||(E=f[r]={});E[g]=!0;y&&\"function\"==typeof y.ua&&y.ua()}delete Mc[g]}for(var G in f){G=+G;d=f[G];h=(e=Nc[G])?e.length:0;for(k=g=0;k<h;k++)t=e[k],t in d||(e[g++]=t);g?e.length=g:delete Nc[G]}b.innerHTML=c;Ad(a.id);dc(U);U=null}\n",
       "var Ad=function(a){if(a=document.querySelector(\"#\"+a+\">.gs_md_bdy\"))a.scrollTop=a.scrollLeft=0,rd(a)};function rd(a){var b=a.style,c=\"padding\"+(Aa(a)?\"Left\":\"Right\");b[c]=\"\";var d=a.offsetWidth-a.clientWidth;2<d&&(a=parseInt(window.getComputedStyle(a,null)[c],10)||0,b[c]=Math.max(a-d,0)+\"px\")}var Fd=function(){return w(\"gs_md_err\").innerHTML},Dd=function(){return'<div class=\"gs_md_prg\"><div class=\"gs_alrt\">'+Fd()+\"</div></div>\"};function yd(){return{d:S||void 0,u:td||void 0,p:T?\"1\":void 0}}\n",
       "function zd(){return{n:xd,p:T,h:wd}}var U=null,S=\"\",td=\"\",T=\"\",wd=\"\",xd=0,vd=0;yb.add(function(){var a=ub(),b=a.d||\"\",c=b?w(b):null;++vd;if(c){c=a.u||\"\";a=0<+a.p;var d=pb||lb(window.history.state)||{},e=+d.n||0,f=\"\"+(d.p||\"\");d=\"\"+(d.h||\"\");c.match(Ga)||(c=\"\");a!=!!f?Ed(b,\"\",\"\",Dd()):b==S&&c==td&&f==T&&d==wd||Ed(b,c,f,d);xd=e}else S&&I(S);--vd});var Gd=function(a){oa.call(this);this.S=a;this.ia=Object.create(null);this.P=null;a=a.querySelectorAll(\".gs_in_txtw>input[type=text]\");for(var b=a.length;b--;){var c=a[b],d=c.parentNode.querySelector(\".gs_in_txts\");c=c.name;d&&c&&(this.ia[c]=d.innerHTML)}};ja(Gd,oa);Gd.prototype.aa=function(){dc(this.P);this.S=this.P=null;oa.prototype.aa.call(this)};Gd.prototype.gb=function(a){var b=this;L(a);if((a=this.S)&&!this.P){var c=\"json=&\"+Ba(a);Hd(this,!0);this.P=cc(a.action,c,function(d,e){b.ha(d,e)})}};\n",
       "Gd.prototype.ha=function(a,b){this.P=null;Hd(this,!1);var c=this.S,d=c.getAttribute(\"data-alrt\");if(d=d?w(d):null)d.innerHTML=\"\";try{var e=200==a&&JSON.parse(b)}catch(t){}e&&\"object\"==typeof e||(e=Fd(),d?d.innerHTML=e:Nb(e),e={});if(a=e.L)Ea(\"\"+a);else{if(a=e.M)d?d.innerHTML=a:Nb(a);a=1E6;if(d&&d.innerHTML){var f=d;a=d.getBoundingClientRect().top}c=c.elements;e=e.E;\"object\"==typeof e||(e=Object.create(null));for(var h in this.ia){d=c[h];b=void 0;var g=\"\"+(e[h]||\"\"),k=d.parentNode.querySelector(\".gs_in_txts\");\n",
       "u(d.parentNode,\"gs_in_txte\",!!g);k&&(k.innerHTML=g||this.ia[h]||\"\");g&&(b=d.getBoundingClientRect().top)<a&&(f=d,a=b)}f&&f.scrollIntoView&&(0>a||a+20>window.innerHeight)&&f.scrollIntoView()}};var Hd=function(a,b){a=a.S;var c=a.getAttribute(\"data-bsel\");a=c?document.querySelectorAll(c):a.querySelectorAll(\"button\");for(c=a.length;c--;){var d=a[c];d.disabled=b;u(d,\"gs_bsp\",b)}};P(Gd,[new N(\".gs_ajax_frm\",{submit:Gd.prototype.gb})]);var Id=[[1,0,1],[2,0,1]];O(\".gs_cb_gen\",\"click\",function(a){var b=a.currentTarget,c=id(b),d=2==+b.getAttribute(\"data-s\");c=Id[+d][c];d=!0;d=void 0===d?!1:d;u(b,\"gs_sel\",1==c);u(b,\"gs_par\",2==c);b.setAttribute(\"aria-checked\",jd[c]);d||b.setAttribute(\"data-s\",\"\"+c);Q(\"gs-change\",b,a.b)});O(\".gs_cb_gen\",[\"keydown\",\"keyup\"],function(a){var b=a.currentTarget,c=a.b.keyCode;\"BUTTON\"!=b.tagName||13!=c&&32!=c||(L(a),\"keydown\"==a.type&&b.click())});O([\".gs_cb_gen\",\".gs_md_li\"],\"keydown\",function(a){var b=a.currentTarget,c=b.tagName,d=a.b.keyCode;\"BUTTON\"!=c&&(32==d||13==d&&\"A\"!=c)&&(L(a),b.click())});var Jd=[\"click\",\"contextmenu\",\"mouseup\"].concat(navigator.sendBeacon&&GSP.neverBounce?[]:[\"mousedown\",\"touchstart\"]),Kd=GSP.bouncePrefix||\"http://\"+window.location.host,Ld=\"\",Md=null;function Nd(){Md=null}function Od(a){navigator.sendBeacon?navigator.sendBeacon(a):Md&&a==Md.src||((Md=new Image).src=a,setTimeout(Nd,1E3))}\n",
       "function Pd(){var a=document.location.href,b=a.indexOf(\"?\")+1;a=b?a.substr(b):\"\";b=a.indexOf(\"#\");a=tb(b+1?a.substr(0,b):a).hl||\"\";a=\"/scholar_bfnav?url=\"+encodeURIComponent(document.location.href)+\"&hl=\"+encodeURIComponent(a)+\"&ei=\"+GSP.eventId;Od(a)}D(function(){Ld=Lb?\"&bn=1\":\"\";Lb&&Pd()});A(window,\"pageshow\",function(a){a.persisted&&(Ld=\"&bn=1\",Pd())});\n",
       "A(document,Jd,function(a){if(!(\"click\"==a.type&&a.button||\"mouseup\"==a.type&&1!=a.button)){var b,c;a:{for(a=a.target;a;){var d=a.nodeName;if(\"A\"==d)break a;if(\"SPAN\"==d||\"B\"==d||\"I\"==d||\"EM\"==d||\"IMG\"==d)a=a.parentNode;else break}a=null}if(a&&(b=a.getAttribute(\"href\"))&&(c=a.getAttribute(\"data-clk\"))){b=\"/scholar_url?url=\"+encodeURIComponent(b)+\"&\"+c+\"&ws=\"+window.innerWidth+\"x\"+window.innerHeight+\"&at=\";d=encodeURIComponent;var e=a.getAttribute(\"data-clk-atid\");e=e&&w(e);b=b+d(e&&e.innerText||\"\")+\n",
       "Ld;0<c.indexOf(\"scisig=\")?(a.setAttribute(\"href\",Kd+b),a.removeAttribute(\"data-clk\")):Od(b)}}},!1,!0);O(\".gs_fm_s\",\"click\",function(a){a=a.currentTarget.getAttribute(\"data-fm\")||\"\";(a=w(a))&&a.submit()});var V=function(a){this.I=x(a.querySelector(\".gs_md_d\"));this.$=x(a.querySelector(\".gs_md_tb\"))};l=V.prototype;l.ca=function(a){var b=w(this.I);return void 0!==a?Uc(b,b,\".gs_md_li\",a):null};l.open=function(a){a=this.ca(a);if(q(w(this.$),\"gs_sel\"))try{a&&a.focus()}catch(c){}else{var b=w(this.$);ab(this.I,function(){n(b,\"gs_sel\")},function(){p(b,\"gs_sel\")},a,b)}};l.close=function(){I(this.I)};l.Ta=function(a){L(a);q(w(this.$),\"gs_sel\")?this.close():this.open(\"keydown\"==a.b.type?!1:void 0)};\n",
       "l.va=function(a){var b=a.b.keyCode;if(38==b||40==b)L(a),this.open(38==b)};l.Ya=function(a){a.target.id==this.I&&this.va(a)};P(V,[new N(\".gs_md_rmb\",{}),new N(\".gs_md_tb\",{\"gs-press\":V.prototype.Ta,keydown:V.prototype.va}),new N(\".gs_md_d\",{keydown:V.prototype.Ya})]);var W=function(a){V.call(this,a);this.ib=x(a.querySelector(\".gs_md_in\"));this.jb=x(a.querySelector(\".gs_md_tb .gs_lbl\"))};ja(W,V);W.prototype.ca=function(){return w(this.I).querySelector(\".gs_md_li[aria-selected]\")};W.prototype.ab=function(a){Qd(this,a)};W.prototype.ea=function(a){var b=a.b.keyCode;13!=b&&32!=b||Qd(this,a)};\n",
       "var Qd=function(a,b){var c=b.currentTarget,d=w(a.ib),e=a.ca();c!=e&&(d.value=c.getAttribute(\"data-v\"),w(a.jb).innerHTML=c.innerHTML,e&&Rd(e,!1),Rd(c,!0));L(b);a.close();Q(\"gs-change\",d,b.b)},Rd=function(a,b){u(a,\"gs_sel\",b);b?a.setAttribute(\"aria-selected\",\"true\"):a.removeAttribute(\"aria-selected\")};P(W,[new N(\".gs_md_ris\",{}),new N(\".gs_md_li\",{click:W.prototype.ab,keydown:W.prototype.ea})]);O(\"#gs_lp\",\"click\",function(a){L(a);Ed(\"gs_lp_d\")});O(\"#gs_lp_cur\",\"click\",function(a){L(a);I(\"gs_lp_d\")});var Sd=function(a){this.Ea=x(a)};Sd.prototype.ea=function(a){var b=a.currentTarget,c=a.b.keyCode;if(38==c||40==c){var d=w(this.Ea);d=Uc(d,b,\".gs_md_li\",38==c)||Uc(d,d,\".gs_md_li\",38==c)}else if(37==c||39==c)a:{c=!!(37==c^Aa(b.parentNode));d=b.parentNode;var e=d.children,f=e.length;if(d.id!=this.Ea){for(;e[--f]!=b;);d=Sc(d,c)||Rc(d.parentNode,c);e=d.children;if(f=Math.min(f+1,e.length))if(d=e[f-1],q(d,\"gs_md_li\")&&d.offsetLeft!=b.offsetLeft)break a}d=void 0}d&&(L(a),d.focus())};\n",
       "P(Sd,[new N(\".gs_md_ulr\",{}),new N(\".gs_md_li\",{keydown:Sd.prototype.ea})]);O(\"#gs_hdr_mnu\",\"click\",function(a){L(a);Ed(\"gs_hdr_drw\")});O(\"#gs_hdr_drw_mnu\",\"click\",function(a){L(a);I(\"gs_hdr_drw\")});O(\"#gs_hdr_act_i\",\"click\",function(a){L(a);1==ra()?Ea(document.querySelector(\"#gs_hdr_drw_bot>a\").href):ab(\"gs_hdr_act_d\")});O(\"#gs_hdr_drw\",\"keydown\",function(a){var b=a.b.keyCode;if(38==b||40==b){var c=a.currentTarget;if(b=Uc(c,c,\".gs_md_li\",38==b))L(a),b.focus()}});\n",
       "O(\"#gs_hdr_tsi\",[\"focus\",\"blur\"],function(a){function b(){var h=d.getBoundingClientRect().top-10;10<Math.abs(h)&&window.scrollBy(0,h);clearTimeout(e);c()}function c(){B(window,f,b)}var d=a.target;a=\"focus\"==a.type;u(w(\"gs_hdr\"),\"gs_hdr_ifc\",a);if(a&&sa&&!(749<window.innerHeight)){var e=setTimeout(c,1E3),f=[\"scroll\",\"resize\"];A(window,f,b)}});O(\"#gs_hdr_tsi\",[\"input\",\"gs-change\"],function(a){u(w(\"gs_hdr_frm\"),\"gs_hdr_tsc\",!!a.currentTarget.value)});\n",
       "O(\"#gs_hdr_tsc\",\"mousedown\",function(a){L(a);var b=w(\"gs_hdr_tsi\");b.value=\"\";b.focus();Q(\"input\",b,a.b)});O(\"#gs_hdr_sre\",\"click\",function(a){L(a);var b=w(\"gs_hdr\");ab(\"gs_hdr_frm\",function(){p(b,\"gs_hdr_src\");n(b,\"gs_hdr_srx\")},function(){n(b,\"gs_hdr_src\");p(b,\"gs_hdr_srx\")},w(\"gs_hdr_tsi\"))});O(\".gs_md_x\",\"click\",function(a){(a=a.currentTarget.getAttribute(\"data-mdx\"))&&I(a)});var X=function(){},Td,Ud;l=X.prototype;l.Va=function(a){a.b.button||(L(a),Vd(a))};l.fa=function(a){Wd(a)&&(L(a),Vd(a))};l.bb=function(a){Wd(a)&&L(a)};l.ga=function(a){if(!a.b.button){L(a);var b=a.b;b&&(Xd=b.clientX||0,Yd=b.clientY||0,A(document,Zd,$d,!0),clearTimeout(Td),Td=setTimeout(ae,2E3));Vd(a)}};l.hb=function(a){L(a);if(be){var b=a.b;if(b=(b=b&&b.touches)&&1==b.length&&b[0])ce=b.clientX,de=b.clientY,A(document,ee,fe,!0),clearTimeout(Ud),Ud=setTimeout(ge,2E3)}Vd(a)};\n",
       "var Wd=function(a){a=a.b.keyCode;return 32==a||13==a},Vd=function(a){Q(\"gs-press\",a.currentTarget,a.b)},ae=function(){B(document,Zd,$d,!0);clearTimeout(Td);Td=void 0},$d=function(a){\"mousedown\"!=a.type&&10>Math.abs(a.clientX-Xd)&&10>Math.abs(a.clientY-Yd)?(Ra(a),\"click\"==a.type&&ae()):ae()},ge=function(){B(document,ee,fe,!0);clearTimeout(Ud);Ud=void 0},fe=function(a){\"touchstart\"!=a.type&&10>Math.abs(a.clientX-ce)&&10>Math.abs(a.clientY-de)?(Ra(a),\"click\"==a.type&&ge()):ge()},Xd=0,Yd=0,Zd=[\"mousedown\",\n",
       "\"mouseup\",\"click\"],be=v(\"Android\")&&!v(\"Chrome\"),ce=0,de=0,ee=[\"touchstart\",\"mousedown\",\"mouseup\",\"click\"];P(X,[new N(\".gs_press\",{click:X.prototype.Va,keydown:X.prototype.fa,keyup:X.prototype.bb,mousedown:X.prototype.ga,touchstart:X.prototype.hb})]);function he(){var a=0>ie.getBoundingClientRect().top;je!=a&&(je=a,u(ke,\"gs_sth_vis\",a),a?le():(me.style.left=\"\",me.style.width=\"\",ne()))}function le(){if(je){var a=ie.getBoundingClientRect();me.style.left=a.left+\"px\";me.style.width=a.width+\"px\";ne()}}function ne(){Q(\"gs-sth-change\",w(\"gs_sth\"))}var ke,ie,me,je=!1;D(function(){if(ke=w(\"gs_sth\"))ie=ke.querySelector(\".gs_sth_g\"),me=ke.querySelector(\".gs_sth_b\"),md.addListener(he),od.addListener(le),he()});function oe(){w(\"gs_asd_frm\").submit()};function pe(a){a&&a.querySelectorAll&&a.querySelectorAll(qe).length&&Ea(re)}function se(){pe(document.body);te=new MutationObserver(function(a){a=ba(a);for(var b=a.next();!b.done;b=a.next())pe(b.value.target)});te.observe(document.body,{childList:!0,subtree:!0})}function ue(a){var b=[];a=ba(a);for(var c=a.next();!c.done;c=a.next())c=c.value.charCodeAt(0),b.push(32>c||126<=c?c:String.fromCharCode(32+(c-32+47)%94));return b.join(\"\")}\n",
       "var te,qe=[ue(\"R8D02D50AD3,7@C>.\"),ue(\":7C2>6,4=2DDYlC6=:6G65.\"),ue(\"2,52E2\\\\<@A6C?:@\\\\:5.\")].join(),re=ue(\"^D49@=2C^<@A6C?:@]9E>=\");var ve=function(a,b,c){var d=(w(\"gs_citd\").getAttribute(\"data-u\")||\"\").replace(\"{id}\",a).replace(\"{p}\",\"\"+b);cc(d,\"\",function(e,f){F.gs_cit||(200==e?Ed(\"gs_cit\",d,\"\",f):Nb(Fd()));c&&c()})},we;var xe=function(){vc(\"#gsb_promo_x\",function(a){w(\"gsb_promo\").className=\"\";L(a);cc(a.target.href,\"\",function(){})});A(window,\"message\",function(a){var b=a.data,c;a.origin.match(/[.]google[.]com(:[0-9]+)?$/)&&b&&\"object\"==typeof b&&0<=(c=+b.gsbPromo)&&(w(\"gsb_promo\").className=c?\"gsb_not_installed\":\"gsb_installed\")});D(function(){var a=document.createElement(\"iframe\");a.id=\"gsb_promo_ping\";a.frameBorder=\"0\";a.scrolling=\"no\";a.tabIndex=-1;a.src=(window.location.host.indexOf(\"scholar.google.\")?\"\":\"//scholar.google.com\")+\n",
       "\"/scholar_gsb_promo_ping\";document.body.appendChild(a)})};var Ee=function(a,b){if(!ye[a]){ye[a]=!0;ze.v({ba:a,ja:b,error:void 0});var c=b?Ae.replace(\"{id}\",Be+\":\"+b):Ce.replace(\"{id}\",a);cc(c,\"\",function(d,e){delete ye[a];var f=b,h=\"\";if(200==d)try{var g=JSON.parse(e)}catch(k){}ma(g)?g.L?Ea(\"\"+g.L):g.M?h=\"\"+g.M:\"array\"==la(g.U)&&1==g.U.length&&ma(g.U[0])?(d=(\"\"+(g.U[0].c||\"\")).split(\":\"),f=d[1]||\"\",e={},e[a+\",\"+d[0]]=f,De(e)):h=Fd():h=Fd();ze.v({ba:a,ja:f,error:h})})}};function Fe(a){return(a=ib(\"s\",void 0===a?!1:a))&&ma(a)?a:{}}\n",
       "function De(a){var b=Date.now(),c=Fe(!0),d;for(d in c){var e=c[d];e instanceof Array&&2==e.length&&12E5>b-e[1]||delete c[d]}for(var f in a)c[f]=[a[f],b];gb(hb,fb,\"s\",c)}var ye={},ze=new z,Be,Ae,Ce;function Y(a){var b=w(\"gs_res_glb\");return b?b.getAttribute(a)||\"\":\"\"};var Z=function(a){this.Z=a;this.Ia=a.getAttribute(\"data-cid\")||\"\";this.Ja=He(a);this.pb=+(a.getAttribute(\"data-rp\")||0)||0};Z.prototype.cb=function(a){u(a.currentTarget.parentNode,\"gs_or_mvi\")};Z.prototype.Ua=function(a){var b=a.currentTarget;q(b,\"gs_or_ldg\")||(u(b,\"gs_or_ldg\",!0),ve(this.Ia,this.pb,function(){u(b,\"gs_or_ldg\",!1)}))};Z.prototype.La=function(a){var b=a.currentTarget,c=b.parentNode;ab(x(b),function(){p(b,\"gs_press\");n(c,\"gs_vis\");n(b,\"gs_anm\")},function(){n(b,\"gs_press\");p(c,\"gs_vis\")})};\n",
       "Z.prototype.fb=function(){var a=this.Z.getAttribute(\"data-lid\")||\"\";Ee(this.Ja,a)};var Je=[new N(\".gs_or\",{}),new N(\".gs_or_ggsm\",{\"gs-press\":Z.prototype.La}),new N(\".gs_or_cit\",{click:Z.prototype.Ua}),new N(\".gs_or_sav\",{click:Z.prototype.fb}),new N(\".gs_or_mor\",{click:Z.prototype.cb})];function Ke(){for(var a=q(document.documentElement,\"gs_el_ph\"),b=document.querySelectorAll(\".gs_or_ggsm\"),c=b.length;c--;){var d=b[c];q(d,\"gs_vis\")&&I(x(d));u(d,\"gs_press\",a);p(d,\"gs_anm\")}}\n",
       "function Le(a){var b=document.querySelector('.gs_or[data-did=\"'+a.ba+'\"]');if(b){var c=b.querySelector(\".gs_or_sav\");c&&(u(c,\"gs_or_ldg\",void 0===a.error),a.error?Nb(a.error):b.setAttribute(\"data-lid\",a.ja))}}var He=function(a){return a.getAttribute(\"data-did\")||\"\"};var Me=function(a){this.Z=a};Me.prototype.eb=function(){5>(+(this.Z.getAttribute(\"data-rp\")||0)||0)?Ne({}):(Oe=He(this.Z),Pe=Date.now())};function Qe(){var a=document.location.href;return a.substr(0,a.indexOf(\"#\"))||a}function Re(){return document.querySelector(\".gs_r_rfr\")}function Se(a){var b=Re();return!!b&&He(b)==a&&!!b.querySelector(\".gs_rfr\")}function Ne(a){gb(hb,fb,\"rfr\",a)}function Te(){var a=ib(\"rfr\");return a&&ma(a)?a:null}\n",
       "function Ue(a,b,c){n(a,\"gs_r_rfr\");var d=document.createElement(\"div\");d.className=\"gs_rfr\";d.innerHTML=b;a.appendChild(d);Ve();if(c){b=\"@keyframes gs_r_vsld_anm{0%{transform:translate(0,-\"+d.offsetHeight+\"px);}100%{transform:translate(0,0);}}\";c=w(\"gs_r_vsld_style\");c||(c=document.createElement(ya.Fa),c.id=\"gs_r_vsld_style\",document.head.appendChild(c));c.textContent=b;for(b=a.nextElementSibling;b;)n(b,\"gs_r_vsld\"),b=b.nextElementSibling;(b=w(\"gs_res_ccl_bot\"))&&n(b,\"gs_r_vsld\");n(a,\"gs_anm\");Oa(d,\n",
       "\"animationend\",We,500,We)}}function We(){var a=Re();a&&p(a,\"gs_anm\");a=document.querySelectorAll(\".gs_r_vsld\");for(var b=a.length,c=0;c<b;c++)p(a[c],\"gs_r_vsld\")}function Xe(){var a=Re();if(!a)return!1;p(a,\"gs_r_rfr\");var b=a.querySelector(\".gs_rfr\");if(!b)return!1;a.removeChild(b);return!0}function Ye(){var a=window.pageYOffset,b=Re();if(!b)return a;b=b.querySelector(\".gs_rfr\");if(!b)return a;b=b.getBoundingClientRect();0>b.top&&(a-=b.bottom-b.top);return a}\n",
       "function Ze(a,b){var c=b.getBoundingClientRect();b=c.bottom;c=b-(b-c.top)/3;var d=1E4,e=-1E4,f=!1;a=a.getClientRects();for(var h=0;h<a.length;h++){var g=a[h];4<=b-g.top&&4<=g.bottom-c?(d=Math.min(d,g.left),e=Math.max(e,g.right)):g.top>=b&&(f=!0)}return 1E4==d?f?0:-1:f?e-d:-1}\n",
       "function Ve(){for(var a=document.querySelectorAll(\".gs_rfr_rt>a\"),b=0;b<a.length;b++){var c=a[b],d=c.parentNode,e=d.firstElementChild,f=e.style;c=c.querySelector(\"[dir]\")||c;f.display=\"none\";var h=Ze(c,d);if(0<=h){var g=Aa(d),k=Aa(c);f.display=\"block\";e.setAttribute(\"dir\",k?\"rtl\":\"ltr\");h=Ze(c,d);f.transform=\"translateX(\"+[-1,0,0,1][2*g+k]*(d.offsetWidth-e.offsetWidth-h)+\"px)\"}}}var $e=[new N([\".gs_r\"],{}),new N([\".gs_rt\",\".gs_or_ggsm\"],{click:Me.prototype.eb})],Oe,Pe;GSP.customAC&&(P(R,gd),D(hd),A(window,\"pageshow\",function(){setTimeout(hd,0)}));window.MutationObserver&&D(se);O(\"#gs_asd_psb\",\"click\",oe);O(\"#gs_asd_frm\",\"keydown\",function(a){var b=a.target;\"INPUT\"==b.tagName&&\"text\"==b.type&&13==a.b.keyCode&&oe()});O(\".gs_citr\",\"focus\",function(a){var b=a.currentTarget;b!=we&&(we=b,L(a),setTimeout(function(){window.getSelection().selectAllChildren(b);b.focus()},0))});O(\".gs_cith\",\"click\",function(a){(a=a.currentTarget.parentNode.querySelector(\".gs_citr\"))&&a.focus()});\n",
       "P(Z,Je);D(function(){Ke();ze.add(Le);for(var a={},b=document.querySelectorAll(\".gs_or[data-did]\"),c=b.length;c--;){var d=b[c],e=He(d);d=d.getAttribute(\"data-lid\")||\"\";a[e]=d}b=Y(\"data-lpu\");c=Y(\"data-sva\");e=Y(\"data-tra\");d=Y(\"data-lsl\");Be=b;Ae=e;Ce=c;try{var f=JSON.parse(void 0===d?\"\":d)}catch(g){}f&&ma(f)&&!Lb||(f={});De(f);f=Fe();for(var h in a)b=a[h],c=f[h+\",\"+Be],c instanceof Array&&(c=\"\"+c[0],b!=c&&(b=c,ze.v({ba:h,ja:b,error:\"\"})))});pd.add(Ke);Ke();A(window,\"pagehide\",Ke);\n",
       "O(\"#gs_res_sb_yyc\",\"click\",function(){w(\"gs_res_sb_yyf\").style.display=\"block\";for(var a=document.querySelectorAll(\"#gs_res_sb_yyl>li\"),b=a.length;b--;)u(a[b],\"gs_bdy_sb_sel\",b==a.length-1)});O(\"#gs_scipsc\",\"gs-change\",function(a){var b=id(a.currentTarget),c=Ca(w(\"gs_hdr_frm\")),d=Ca(w(\"gs_asd_frm\"));c.value=d.value=b?\"1\":\"\";a=a.currentTarget.getAttribute(\"data-msg\")||\"\";w(\"gs_hdr_tsi\").placeholder=b?a:\"\"});vc(\"#gs_res_drw_adv\",function(){Ed(\"gs_asd\")});\n",
       "D(function(){var a=Y(\"data-ttl\");a&&(document.title=a);a=new kc(\"q\");var b=Y(\"data-ahq\");b&&a.add(b);Y(\"data-gsb\")&&xe()});P(Me,$e);A(window,\"pagehide\",function(){We();if(Oe&&!Se(Oe)){var a={d:Oe,u:Qe(),t:Date.now()};5E3<=Date.now()-Pe&&(a={});var b=Ye();Xe()&&window.scrollTo(0,b);a.s=b;Ne(a)}});\n",
       "A(window,\"pageshow\",function(){var a=Te(),b=Qe();if(a&&a.u==b)if(864E5<=Date.now()-(+a.t||0))Ne({});else{b=\"\"+a.d;var c=Y(\"data-rfr\");if(c)if(Se(b))Ve();else{var d=Xe(),e=+a.s;e&&!d&&(v(\"Trident\")||v(\"Edge\"))&&Oa(window,\"scroll\",function(){window.scrollTo(0,e)},20);a.s=0;Ne(a);var f=document.querySelector('.gs_or[data-did=\"'+b+'\"]');if(f)if(d=a.h)Ue(f,\"\"+d,!1);else{b=c.replace(\"{id}\",b);var h=cc(b,\"\",function(k,t){200==k&&t&&(Ue(f,t,!0),a.h=t,a.t=Date.now(),Ne(a));clearTimeout(g)}),g=setTimeout(function(){dc(h)},\n",
       "1E3)}}}});od.addListener(Ve);\n",
       "}({\"bouncePrefix\":\"https://scholar.google.co.kr\",\"neverBounce\":!0,\"customAC\":2,\"eventId\":\"g14lXqO6CZSiygS5vpq4Cw\"});</script></head><body><div id=\"gs_top\" onclick=\"\"><style>#gs_md_s,.gs_md_wnw{z-index:1200;position:fixed;top:0;left:0;width:100%;height:100%;visibility:hidden;}#gs_md_s{background-color:#fff;opacity:.5;}.gs_el_ta #gs_md_s,.gs_el_ph #gs_md_s{background-color:#666;}.gs_md_wnw{transition:all 0s .218s;}#gs_md_s.gs_vis,.gs_md_wnw.gs_vis{visibility:visible;transition:all 0s;}.gs_md_wnw>.gs_md_d{position:relative;margin:0 auto;width:464px;box-shadow:2px 2px 8px rgba(0,0,0,.2);white-space:normal;}.gs_el_ta .gs_md_wnw>.gs_md_d,.gs_el_ph .gs_md_wnw>.gs_md_d{box-shadow:2px 2px 8px rgba(0,0,0,.65);}.gs_el_ph .gs_md_wnw>.gs_md_d{width:80%;max-width:440px;}.gs_el_ph .gs_md_wmw>.gs_md_d{width:100%;height:100%;max-width:none;border:none;box-shadow:none;transform:translate(0,100%);transform:translate(0,100vh);transition:transform .27s cubic-bezier(.4,0,.6,1),opacity 0s .27s,visibility 0s .27s,max-height 0s .27s;}.gs_el_ph .gs_md_wmw>.gs_md_d.gs_vis{transform:translate(0,0);transition:transform .3s cubic-bezier(0,0,.2,1);}.gs_md_wmw>.gs_md_d.gs_abt,.gs_el_ph .gs_md_wmw>.gs_md_d.gs_abt{transition:none;}.gs_md_hdr{display:flex;align-items:center;height:47px;border-bottom:1px solid #e0e0e0;border-bottom-color:rgba(0,0,0,.12);background-color:#f5f5f5;}.gs_md_hdr>a,.gs_md_hdr>a.gs_btn_lrge{flex:0 0 auto;width:41px;height:47px;}.gs_el_ph .gs_md_hdr>a{margin:0 2px 0 0;}.gs_el_ph a.gs_md_hdr_c{margin:0 0 0 2px;}.gs_md_hdr_b{margin:0 41px 0 16px;}.gs_el_ph .gs_md_hdr_b{margin:0 16px;}.gs_md_hdr_t:empty~.gs_md_hdr_b{margin-left:0;}.gs_md_hdr_b:empty{width:41px;margin:0;}.gs_el_ph .gs_md_hdr_b:empty{margin-right:2px;}.gs_md_hdr_b:empty:not(:last-child){display:none;}.gs_md_hdr_b>button{min-width:51px;height:33px;}.gs_md_hdr_t{flex:1 1 auto;font-size:18px;font-weight:normal;color:#666;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;text-align:center;}.gs_md_bdy{overflow-y:auto;box-sizing:border-box;padding:24px 41px 0 41px;}.gs_md_bdy:after{display:block;content:\"\";clear:both;padding-bottom:24px;}.gs_el_ph .gs_md_bdy{padding:16px 16px 0 16px;}.gs_el_ph .gs_md_bdy:after{padding-bottom:16px;}.gs_el_ph .gs_md_wmw .gs_md_bdy{position:absolute;width:100%;top:48px;bottom:0;}.gs_md_lbl{display:block;font-size:16px;margin:0 0 16px 0;word-wrap:break-word;}.gs_md_btns{margin:24px 0 0 0;white-space:nowrap;}.gs_el_ph .gs_md_btns{margin:16px 0 0 0;}.gs_md_btns button{margin-right:16px;}.gs_md_btns button:last-child{margin-right:0;}.gs_md_prg{margin:24px 0;text-align:center;}.gs_md_prg .gs_alrt{padding:4px 16px;}.gs_md_ldg:before{content:\"\";position:absolute;top:0;left:0;bottom:0;right:0;background-color:#fff;opacity:.5;z-index:100;}</style><div id=\"gs_md_ldg\" style=\"display:none\">로드 중...</div><div id=\"gs_md_err\" style=\"display:none\">현재 시스템이 작동되지 않습니다. 나중에 다시 시도해 주세요.</div><div id=\"gs_md_s\"></div><div class=\"gs_md_wnw gs_md_wmw\" data-h=\"0\"><div aria-labelledby=\"gs_cit-t\" class=\"gs_md_d gs_ttzi\" data-cid=\"gs_citd\" data-wfc=\"gs_cit-x\" id=\"gs_cit\" role=\"dialog\" tabindex=\"-1\"><div class=\"gs_md_hdr\"><a aria-label=\"취소\" class=\"gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge\" data-mdx=\"gs_cit\" href=\"javascript:void(0)\" id=\"gs_cit-x\" role=\"button\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></a><h2 class=\"gs_md_hdr_t\" id=\"gs_cit-t\">인용</h2><div class=\"gs_md_hdr_b\"></div></div><div class=\"gs_md_bdy\" id=\"gs_cit-bdy\"><style>#gs_cit{width:520px;max-width:80%;}.gs_el_ph #gs_cit{width:100%;max-width:100%;}#gs_citt table{width:100%;margin-top:-8px;}#gs_citt td,#gs_citt th{vertical-align:top;padding:8px 0;}#gs_citt th{text-align:right;font-weight:normal;color:#777;padding-right:16px;white-space:nowrap;-webkit-user-select:none;user-select:none;}#gs_citi{margin:16px 0 0 0;text-align:center;}.gs_el_ph #gs_citi{margin:16px 0 8px 0;}.gs_citi{margin-right:16px;white-space:nowrap;padding:7px 0 5px 0;}.gs_citi:first-child{margin-left:16px;}</style><div aria-live=\"assertive\" data-u=\"/scholar?q=info:{id}:scholar.google.com/&amp;output=cite&amp;scirp={p}&amp;hl=ko\" id=\"gs_citd\"></div></div></div></div><div class=\"gs_md_wnw gs_md_wmw\" data-h=\"0\"><div aria-labelledby=\"gs_asd-t\" class=\"gs_md_d gs_ttzi\" data-ifc=\"gs_asd_q\" data-wfc=\"gs_asd-x\" id=\"gs_asd\" role=\"dialog\" tabindex=\"-1\"><div class=\"gs_md_hdr\"><a aria-label=\"취소\" class=\"gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge\" data-mdx=\"gs_asd\" href=\"javascript:void(0)\" id=\"gs_asd-x\" role=\"button\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></a><h2 class=\"gs_md_hdr_t\" id=\"gs_asd-t\">고급 검색</h2><div class=\"gs_md_hdr_b\"><button aria-label=\"검색\" class=\"gs_btnG gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb\" id=\"gs_asd_psb\" type=\"button\"><span class=\"gs_wr\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></span></button></div></div><div class=\"gs_md_bdy\" id=\"gs_asd-bdy\"><style>#gs_asd{width:80%;max-width:552px;}.gs_el_ph #gs_asd{width:100%;max-width:100%;}#gs_asd_frm{margin-top:-6px;}.gs_el_tc #gs_asd_frm{margin-top:-8px;}.gs_asd_tr{clear:both;}.gs_el_tc .gs_asd_tr{padding:8px 0;}.gs_el_tc .gs_asd_tr:first-child{padding-bottom:0;}.gs_asd_dt{float:left;width:190px;padding:6px 2px 2px;}.gs_el_tc .gs_asd_dt{float:none;width:auto;padding:0 0 4px 0;}.gs_asd_dd{margin-left:194px;padding:2px;}.gs_el_tc .gs_asd_dd{margin-left:0;padding:0;}.gs_asd_yri .gs_in_txt{width:48px;}.gs_el_ph #gs_asd input,.gs_el_ph #gs_asd label{-webkit-tap-highlight-color:rgba(0,0,0,0);}.gs_asd_occtr{padding:5px 0;}.gs_el_tc .gs_asd_occtr{padding:0;}</style><form action=\"/scholar\" class=\"gs_scl\" id=\"gs_asd_frm\"><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\" id=\"gs_asd_dt_t\"><b>논문/자료 검색</b></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_q\">다음 단어 <b>모두</b> 포함</label></div><div class=\"gs_asd_dd\"><div class=\"gs_in_txtw gs_in_txtm gs_in_txtb\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_q\" name=\"as_q\" type=\"text\" value=\"reinforcement learning\"/></div></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_epq\">다음 <b>문구 정확하게</b> 포함</label></div><div class=\"gs_asd_dd\"><div class=\"gs_in_txtw gs_in_txtm gs_in_txtb\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_epq\" name=\"as_epq\" type=\"text\" value=\"\"/></div></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_oq\">다음 단어 <b>적어도 하나</b> 포함</label></div><div class=\"gs_asd_dd\"><div class=\"gs_in_txtw gs_in_txtm gs_in_txtb\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_oq\" name=\"as_oq\" type=\"text\" value=\"\"/></div></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_eq\">다음 단어 <b>제외</b></label></div><div class=\"gs_asd_dd\"><div class=\"gs_in_txtw gs_in_txtm gs_in_txtb\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_eq\" name=\"as_eq\" type=\"text\" value=\"\"/></div></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_occt\">검색어 위치 설정</label></div><div class=\"gs_asd_dd\"><div class=\"gs_asd_occtr\"><span class=\"gs_in_ra\" onclick=\"void(0)\"><input checked=\"\" id=\"gs_asd_occt_a\" name=\"as_occt\" type=\"radio\" value=\"any\"/><label for=\"gs_asd_occt_a\">논문/자료 전체에서 검색</label><span class=\"gs_chk\"></span><span class=\"gs_cbx\"></span></span></div><div class=\"gs_asd_occtr\"><span class=\"gs_in_ra\" onclick=\"void(0)\"><input id=\"gs_asd_occt_t\" name=\"as_occt\" type=\"radio\" value=\"title\"/><label for=\"gs_asd_occt_t\">논문/자료 제목에서 검색</label><span class=\"gs_chk\"></span><span class=\"gs_cbx\"></span></span></div></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_sau\">다음 <b>저자</b>의 문서 검색</label></div><div class=\"gs_asd_dd\"><div class=\"gs_in_txtw gs_in_txtm gs_in_txtb\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_sau\" name=\"as_sauthors\" type=\"text\" value=\"\"/></div><div>예: <i>\"PJ Hayes\"</i> 또는 <i>McCarthy</i></div></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_pub\">다음 매체에 <b>발표</b>된 문서 검색</label></div><div class=\"gs_asd_dd\"><div class=\"gs_in_txtw gs_in_txtm gs_in_txtb\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_pub\" name=\"as_publication\" type=\"text\" value=\"\"/></div><div>예: <i>대한안과학회지</i> 또는 <i>한국물리학회지</i></div></div></div><div class=\"gs_asd_tr\"><div class=\"gs_asd_dt\"><label for=\"gs_asd_ylo\">다음 <b>기간 중</b> 발표된 문서 검색</label></div><div class=\"gs_asd_dd\"><div class=\"gs_asd_yri\"><div class=\"gs_in_txtw gs_in_txtm\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_ylo\" maxlength=\"4\" name=\"as_ylo\" pattern=\"[0-9]*\" size=\"4\" type=\"text\" value=\"\"/></div> — <div class=\"gs_in_txtw gs_in_txtm\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_asd_yhi\" maxlength=\"4\" name=\"as_yhi\" pattern=\"[0-9]*\" size=\"4\" type=\"text\" value=\"\"/></div></div><div>예: <i>1996</i></div></div></div><input name=\"hl\" type=\"hidden\" value=\"ko\"/><input name=\"as_sdt\" type=\"hidden\" value=\"0,5\"/></form></div></div></div><!--[if lte IE 9]><div class=\"gs_alrt\" style=\"padding:16px\"><div>죄송합니다. 현재 Internet Explorer 버전에서는 일부 기능이 작동하지 않을 수 있습니다.</div><div>최적의 상태로 사용하려면 <a href=\"//www.google.co.kr/chrome/\">Chrome</a> 또는 <a href=\"//www.mozilla.com/firefox/\">Mozilla Firefox</a>를 사용해 주세요.</div></div><![endif]--><div id=\"gs_hdr_drs\"></div><div class=\"gs_md_ulr\" data-cfc=\"gs_hdr_mnu\" data-shd=\"gs_hdr_drs\" data-wfc=\"gs_hdr_drw_mnu\" id=\"gs_hdr_drw\" role=\"dialog\" tabindex=\"-1\"><div id=\"gs_hdr_drw_in\"><div id=\"gs_hdr_drw_top\"><a aria-controls=\"gs_hdr_drw\" aria-label=\"옵션\" class=\"gs_btnMNT gs_in_ib gs_btn_lrge\" href=\"javascript:void(0)\" id=\"gs_hdr_drw_mnu\" role=\"button\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></a><a aria-label=\"홈페이지\" href=\"/schhp?hl=ko&amp;as_sdt=0,5\" id=\"gs_hdr_drw_lgo\"></a><a aria-label=\"설정\" class=\"gs_btnP gs_in_ib gs_btn_lrge\" href=\"/scholar_settings?q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" id=\"gs_hdr_drw_set\" role=\"button\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></a></div><div><div class=\"gs_hdr_drw_sec\"><a class=\"gs_in_ib gs_md_li gs_md_lix gs_in_gray gs_sel\" href=\"/scholar?as_sdt=0,5&amp;q=reinforcement+learning&amp;hl=ko\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">학술자료</span></a><a class=\"gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"/citations?view_op=search_authors&amp;mauthors=reinforcement+learning&amp;hl=ko&amp;oi=drw\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">프로필</span></a></div><div class=\"gs_hdr_drw_sec\"><a class=\"gs_btnPRO gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"/citations?hl=ko\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">내 프로필</span></a><a class=\"gs_btnL gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"/scholar?scilib=1&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">내 서재</span></a><a class=\"gs_btnM gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"/scholar_alerts?view_op=list_alerts&amp;hl=ko\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">알리미</span></a><a class=\"gs_btnJ gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"/citations?view_op=top_venues&amp;hl=ko\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">통계</span></a></div><div class=\"gs_hdr_drw_sec\"><a class=\"gs_btnADV gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"javascript:void(0)\" id=\"gs_res_drw_adv\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">고급 검색</span></a></div><div class=\"gs_hdr_drw_sec\" id=\"gs_hdr_drw_bs\"><a class=\"gs_btnP gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"/scholar_settings?q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitem\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">설정</span></a></div></div><div class=\"gs_hdr_drw_sec\" id=\"gs_hdr_drw_bot\"><a class=\"gs_in_ib gs_md_li gs_md_lix gs_in_gray\" href=\"https://accounts.google.com/Login?hl=ko&amp;continue=https://scholar.google.co.kr/scholar%3Fstart%3D0%26q%3Dreinforcement%2Blearning%26hl%3Dko%26as_sdt%3D0,5\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">로그인</span></a></div></div></div><div id=\"gs_hdr\" role=\"banner\"><a aria-controls=\"gs_hdr_drw\" class=\"gs_btnMNT gs_in_ib gs_btn_lrge\" href=\"javascript:void(0)\" id=\"gs_hdr_mnu\" role=\"button\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></a><a aria-label=\"홈페이지\" class=\"gs_hdr_dso\" href=\"/schhp?hl=ko&amp;as_sdt=0,5\" id=\"gs_hdr_lgo\"></a><div id=\"gs_hdr_md\"><div id=\"gs_hdr_srch\"><form action=\"/scholar\" class=\"gs_hdr_tsc\" id=\"gs_hdr_frm\"><input name=\"hl\" type=\"hidden\" value=\"ko\"/><input name=\"as_sdt\" type=\"hidden\" value=\"0,5\"/><div class=\"gs_in_txtw gs_in_txtb gs_in_acw\"><input aria-label=\"검색\" autocapitalize=\"off\" autocomplete=\"off\" class=\"gs_in_txt gs_in_ac\" data-iq=\"reinforcement learning\" data-is=\".gs_qsuggest_regular li&gt;a\" dir=\"ltr\" id=\"gs_hdr_tsi\" maxlength=\"2048\" name=\"q\" size=\"50\" type=\"text\" value=\"reinforcement learning\"/><div aria-hidden=\"true\" class=\"gs_md_ac\" dir=\"ltr\" id=\"gs_hdr_frm_ac\" onmouseout=\"gs_evt_dsp(event)\" onmouseover=\"gs_evt_dsp(event)\" ontouchstart=\"gs_evt_dsp(event)\"><div><div class=\"gs_md_acs\"></div><ul></ul></div></div></div><span id=\"gs_hdr_tsc\"><span class=\"gs_ico gs_ico_X\"></span></span><button aria-label=\"검색\" class=\"gs_btnG gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb\" id=\"gs_hdr_tsb\" name=\"btnG\" type=\"submit\"><span class=\"gs_wr\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></span></button></form></div></div><div id=\"gs_hdr_act\"><a href=\"https://accounts.google.com/Login?hl=ko&amp;continue=https://scholar.google.co.kr/scholar%3Fstart%3D0%26q%3Dreinforcement%2Blearning%26hl%3Dko%26as_sdt%3D0,5\" id=\"gs_hdr_act_s\">로그인</a></div></div><style>#gs_alrt_w{position:fixed;width:100%;z-index:1050;visibility:hidden;opacity:0;}#gs_alrt_w.gs_alrt_pos_h{top:30px;}.gs_el_ta #gs_alrt_w.gs_alrt_pos_h,.gs_el_ph #gs_alrt_w.gs_alrt_pos_h{top:27px;}#gs_alrt_w.gs_anm{transition:opacity .218s ease-out,visibility 0s .218s;}#gs_alrt_w.gs_vis{visibility:visible;opacity:1;transition:opacity .218s ease-out;}#gs_alrt_p{position:absolute;top:-15px;right:0;width:100%;text-align:center;}#gs_alrt{display:inline-block;font-size:13px;line-height:16px;padding:0 16px;}#gs_alrt_m,#gs_alrt_l{display:inline-block;padding:7px 0 6px 0;}#gs_alrt_l:link,#gs_alrt_l:visited{margin-left:16px;color:#222;text-decoration:underline;}#gs_alrt_l:hover{color:#1a0dab}#gs_alrt_l:active{color:#d14836}#gs_alrt_l:empty{display:none}</style><div class=\"\" id=\"gs_alrt_w\" role=\"alert\"><div id=\"gs_alrt_p\"><form action=\"\" class=\"gs_alrt\" id=\"gs_alrt\" method=\"post\"><span id=\"gs_alrt_m\"></span><span id=\"gs_alrt_h\"></span><a href=\"javascript:void(0)\" id=\"gs_alrt_l\" onclick=\"document.getElementById('gs_alrt').submit()\"></a></form></div></div><div class=\"gs_ab_st\" id=\"gs_ab\"><div class=\"gs_btnGSL\" id=\"gs_ab_ico\"><span class=\"gs_ico\"></span></div><div id=\"gs_ab_ttl\"><div class=\"gs_ab_mdw\"><span class=\"gs_nph gs_nta\">학술자료</span><div class=\"gs_oph gs_ota\">학술검색</div></div></div><div id=\"gs_ab_md\"><div class=\"gs_ab_mdw\">검색결과 약 2,640,000개 (<b>0.05</b>초)</div></div><div id=\"gs_ab_btns\"><a class=\"gs_btnPRO gs_in_ib gs_nph gs_nta\" href=\"/citations?hl=ko\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">내 프로필</span></a><a class=\"gs_btnL gs_in_ib gs_nph gs_nta\" href=\"/scholar?scilib=1&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">내 서재</span></a><div class=\"gs_md_r gs_md_rmb gs_md_rmbl\" id=\"gs_res_ab_yy-r\"><button aria-controls=\"gs_res_ab_yy-d\" aria-haspopup=\"true\" class=\"gs_in_se gs_btn_mnu gs_btn_flat gs_btn_lrge gs_btn_half gs_btn_lsu gs_press gs_md_tb\" id=\"gs_res_ab_yy-b\" ontouchstart=\"gs_evt_dsp(event)\" type=\"button\"><span class=\"gs_wr\"><span class=\"gs_lbl\">연도</span><span class=\"gs_icm\"></span></span></button><div class=\"gs_md_d gs_md_ulr\" id=\"gs_res_ab_yy-d\" role=\"menu\" tabindex=\"-1\"><div class=\"gs_res_ab_dd_bdy\"><div class=\"gs_res_ab_dd_sec\"><a aria-checked=\"true\" class=\"gs_md_li gs_res_ab_sel\" href=\"/scholar?q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitemradio\" tabindex=\"-1\">모든 날짜</a><a class=\"gs_md_li\" href=\"/scholar?as_ylo=2020&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitemradio\" tabindex=\"-1\">2020 년부터</a><a class=\"gs_md_li\" href=\"/scholar?as_ylo=2019&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitemradio\" tabindex=\"-1\">2019 년부터</a><a class=\"gs_md_li\" href=\"/scholar?as_ylo=2016&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitemradio\" tabindex=\"-1\">2016 년부터</a></div><div class=\"gs_res_ab_dd_sec\"><a aria-checked=\"true\" class=\"gs_md_li gs_res_ab_sel\" href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;q=%22reinforcement+learning%22\" role=\"menuitemradio\" tabindex=\"-1\">관련도별 정렬</a><a class=\"gs_md_li\" href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;q=%22reinforcement+learning%22&amp;scisbd=1\" role=\"menuitemradio\" tabindex=\"-1\">날짜별 정렬</a></div></div></div></div><div class=\"gs_md_r gs_md_rmb gs_md_rmbl\" id=\"gs_res_ab_ad-r\"><button aria-controls=\"gs_res_ab_ad-d\" aria-haspopup=\"true\" aria-label=\"더보기\" class=\"gs_btnFLT gs_in_ib gs_btn_flat gs_btn_lrge gs_btn_half gs_btn_lsu gs_press gs_md_tb\" id=\"gs_res_ab_ad-b\" ontouchstart=\"gs_evt_dsp(event)\" type=\"button\"><span class=\"gs_wr\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></span></button><div class=\"gs_md_d gs_md_ulr\" id=\"gs_res_ab_ad-d\" role=\"menu\" tabindex=\"-1\"><div class=\"gs_res_ab_dd_bdy\"><div class=\"gs_res_ab_dd_sec\"><a aria-checked=\"true\" class=\"gs_md_li gs_res_ab_sel\" href=\"/scholar?lr=&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitemradio\" tabindex=\"-1\">모든 언어</a><a class=\"gs_md_li\" href=\"/scholar?lr=lang_ko&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitemradio\" tabindex=\"-1\">한국어 웹</a></div><div class=\"gs_res_ab_dd_sec\"><a aria-checked=\"true\" class=\"gs_cb_gen gs_in_cb gs_md_li gs_sel\" data-s=\"1\" href=\"/scholar?as_sdt=1,5&amp;q=reinforcement+learning&amp;hl=ko\" role=\"menuitemcheckbox\" tabindex=\"-1\"><span class=\"gs_lbl\">특허 포함</span><span class=\"gs_chk\"></span><span class=\"gs_cbx\"></span></a><a aria-checked=\"true\" class=\"gs_cb_gen gs_in_cb gs_md_li gs_sel\" data-s=\"1\" href=\"/scholar?as_vis=1&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"menuitemcheckbox\" tabindex=\"-1\"><span class=\"gs_lbl\">서지정보 포함</span><span class=\"gs_chk\"></span><span class=\"gs_cbx\"></span></a></div></div></div></div></div></div><div id=\"gs_bdy\"><div id=\"gs_bdy_sb\" role=\"navigation\"><div id=\"gs_bdy_sb_in\"><div class=\"gs_bdy_sb_sec\"><ul id=\"gs_res_sb_yyl\"><li class=\"gs_ind gs_bdy_sb_sel\"><a href=\"/scholar?q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">모든 날짜</a></li><li class=\"gs_ind\"><a href=\"/scholar?as_ylo=2020&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">2020 년부터</a></li><li class=\"gs_ind\"><a href=\"/scholar?as_ylo=2019&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">2019 년부터</a></li><li class=\"gs_ind\"><a href=\"/scholar?as_ylo=2016&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">2016 년부터</a></li><li class=\"gs_ind\"><a href=\"javascript:void(0)\" id=\"gs_res_sb_yyc\">기간 설정...</a></li></ul><form action=\"/scholar\" class=\"gs_pad\" id=\"gs_res_sb_yyf\" style=\"display:none\"><input name=\"q\" type=\"hidden\" value=\"reinforcement learning\"/><input name=\"hl\" type=\"hidden\" value=\"ko\"/><input name=\"as_sdt\" type=\"hidden\" value=\"0,5\"/><div class=\"gs_res_sb_yyr\"><div class=\"gs_in_txtw gs_in_txtm\"><input autocapitalize=\"off\" class=\"gs_in_txt\" id=\"gs_as_ylo\" maxlength=\"4\" name=\"as_ylo\" pattern=\"[0-9]*\" size=\"4\" type=\"text\" value=\"\"/></div> — <div class=\"gs_in_txtw gs_in_txtm\"><input autocapitalize=\"off\" class=\"gs_in_txt\" maxlength=\"4\" name=\"as_yhi\" pattern=\"[0-9]*\" size=\"4\" type=\"text\" value=\"\"/></div></div><div class=\"gs_res_sb_yyr\"><button class=\"gs_btn_lsb\" type=\"submit\"><span class=\"gs_wr\"><span class=\"gs_lbl\">검색</span></span></button></div></form></div><ul class=\"gs_bdy_sb_sec\"><li class=\"gs_ind gs_bdy_sb_sel\"><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;q=%22reinforcement+learning%22\">관련도별 정렬</a></li><li class=\"gs_ind\"><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;q=%22reinforcement+learning%22&amp;scisbd=1\">날짜별 정렬</a></li></ul><ul class=\"gs_bdy_sb_sec\"><li class=\"gs_ind gs_bdy_sb_sel\"><a href=\"/scholar?lr=&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">모든 언어</a></li><li class=\"gs_ind\"><a href=\"/scholar?lr=lang_ko&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">한국어 웹</a></li></ul><ul class=\"gs_bdy_sb_sec\"><li class=\"gs_inw\"><a aria-checked=\"true\" class=\"gs_cb_gen gs_in_cb gs_sel\" data-s=\"1\" href=\"/scholar?as_sdt=1,5&amp;q=reinforcement+learning&amp;hl=ko\" role=\"checkbox\"><span class=\"gs_lbl\">특허 포함</span><span class=\"gs_chk\"></span><span class=\"gs_cbx\"></span></a></li><li class=\"gs_inw\"><a aria-checked=\"true\" class=\"gs_cb_gen gs_in_cb gs_sel\" data-s=\"1\" href=\"/scholar?as_vis=1&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\" role=\"checkbox\"><span class=\"gs_lbl\">서지정보 포함</span><span class=\"gs_chk\"></span><span class=\"gs_cbx\"></span></a></li></ul><div class=\"gs_bdy_sb_sec\"><a class=\"gs_btnM gs_in_ib\" href=\"/scholar_alerts?view_op=create_alert_options&amp;hl=ko&amp;alert_query=intitle:%22reinforcement+learning%22&amp;alert_params=%3Fhl%3Dko%26as_sdt%3D0,5\" id=\"gs_bdy_sb_ca\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">알림 만들기</span></a></div></div></div><div id=\"gs_bdy_ccl\" role=\"main\"><div data-ahq=\"reinforcement learning\" data-exp=\"\" data-gsb=\"\" data-lph=\"\" data-lpu=\"\" data-lsl=\"\" data-mlu=\"\" data-rfr=\"/scholar?q=related:{id}:scholar.google.com/&amp;output=rfrra&amp;scioq=reinforcement%2Blearning&amp;ei=g14lXqO6CZSiygS5vpq4Cw&amp;hl=ko\" data-sva=\"/citations?hl=ko&amp;xsrf=&amp;continue=/scholar%3Fq%3Dreinforcement%2Blearning%26hl%3Dko%26as_sdt%3D0,5&amp;citilm=1&amp;json=&amp;update_op=library_add&amp;info={id}\" data-tra=\"/citations?hl=ko&amp;xsrf=&amp;continue=/scholar%3Fq%3Dreinforcement%2Blearning%26hl%3Dko%26as_sdt%3D0,5&amp;citilm=1&amp;json=&amp;update_op=trash_citations&amp;s={id}\" data-ttl=\"reinforcement learning - Google 학술 검색\" data-via=\"/citations?view_op=view_citation&amp;continue=/scholar%3Fq%3Dreinforcement%2Blearning%26hl%3Dko%26as_sdt%3D0,5&amp;citilm=1&amp;citation_for_view={id}&amp;hl=ko&amp;oi=saved\" id=\"gs_res_glb\" style=\"display:none\"></div><div id=\"gs_res_ccl\"><div id=\"gs_res_ccl_top\"></div><div id=\"gs_res_ccl_mid\"> <div class=\"gs_r gs_or gs_scl\" data-cid=\"CTeeMoqfgxMJ\" data-did=\"CTeeMoqfgxMJ\" data-lid=\"\" data-rp=\"0\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=0&amp;d=1406142924573259529&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"CTeeMoqfgxMJ\" href=\"https://login.cs.utexas.edu/sites/default/files/legacy_files/research/documents/1%20intro%20up%20to%20RL%3ATD.pdf\"><span class=\"gs_ctg2\">[PDF]</span> utexas.edu</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><span class=\"gs_ctc\"><span class=\"gs_ct1\">[책]</span><span class=\"gs_ct2\">[B]</span></span> <a data-clk=\"hl=ko&amp;sa=T&amp;oi=ggp&amp;ct=res&amp;cd=0&amp;d=1406142924573259529&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"CTeeMoqfgxMJ\" href=\"https://login.cs.utexas.edu/sites/default/files/legacy_files/research/documents/1%20intro%20up%20to%20RL%3ATD.pdf\" id=\"CTeeMoqfgxMJ\">Introduction to <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=6m4wv6gAAAAJ&amp;hl=ko&amp;oi=sra\">RS Sutton</a>, AG Barto - 1998 - login.cs.utexas.edu</div><div class=\"gs_rs\">“We are nearing an important milestone in the history of life on earth, the point at which we <br/>can construct machines with the potential for exhibiting an intelligence comparable to ours.”--<br/>David Waltz, 1988 (recent president of AAAI) Should occur in≈ 2030 for≈ $1000 We don't …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=1406142924573259529&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">6358회 인용</a> <a href=\"/scholar?q=related:CTeeMoqfgxMJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=1406142924573259529&amp;hl=ko&amp;as_sdt=0,5\">전체 6개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"/scholar?output=instlink&amp;q=info:CTeeMoqfgxMJ:scholar.google.com/&amp;hl=ko&amp;as_sdt=0,5&amp;scillfp=10110385682573663327&amp;oi=llo\">FindIt @ KHU Seoul Lib</a> <a class=\"gs_or_nvi\" href=\"https://scholar.googleusercontent.com/scholar?q=cache:CTeeMoqfgxMJ:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">HTML 버전</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"sYjBhwHnt2AJ\" data-did=\"sYjBhwHnt2AJ\" data-lid=\"\" data-rp=\"1\"><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><a data-clk=\"hl=ko&amp;sa=T&amp;ct=res&amp;cd=1&amp;d=6969292942137723057&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"sYjBhwHnt2AJ\" href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.2894\" id=\"sYjBhwHnt2AJ\">Efficient exploration in <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=7K34d7cAAAAJ&amp;hl=ko&amp;oi=sra\">SB Thrun</a> - 1992 - Citeseer</div><div class=\"gs_rs\">Exploration plays a fundamental role in any active <b>learning </b>system. This study evaluates the <br/>role of exploration in active <b>learning </b>and describes several local techniques for exploration <br/>in finite, discrete domains, embedded in a <b>reinforcement learning </b>framework (delayed …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=6969292942137723057&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">401회 인용</a> <a href=\"/scholar?q=related:sYjBhwHnt2AJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=6969292942137723057&amp;hl=ko&amp;as_sdt=0,5\">전체 4개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"http://scholar.googleusercontent.com/scholar?q=cache:sYjBhwHnt2AJ:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">저장된 페이지</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"K_zLI7PhYo4J\" data-did=\"K_zLI7PhYo4J\" data-lid=\"\" data-rp=\"2\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=2&amp;d=10260011060619377707&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"K_zLI7PhYo4J\" href=\"http://people.eecs.berkeley.edu/~russell/classes/cs294/s11/readings/Abbeel+Ng:2004.pdf\"><span class=\"gs_ctg2\">[PDF]</span> berkeley.edu</a><a href=\"/scholar?output=instlink&amp;q=info:K_zLI7PhYo4J:scholar.google.com/&amp;hl=ko&amp;as_sdt=0,5&amp;scillfp=1191580102968898895&amp;oi=lle\">Full View</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><a data-clk=\"hl=ko&amp;sa=T&amp;ct=res&amp;cd=2&amp;d=10260011060619377707&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"K_zLI7PhYo4J\" href=\"https://dl.acm.org/citation.cfm?id=1015430\" id=\"K_zLI7PhYo4J\">Apprenticeship <b>learning </b>via inverse <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=vtwH6GkAAAAJ&amp;hl=ko&amp;oi=sra\">P Abbeel</a>, <a href=\"/citations?user=mG4imMEAAAAJ&amp;hl=ko&amp;oi=sra\">AY Ng</a> - … -first international conference on Machine <b>learning</b>, 2004 - dl.acm.org</div><div class=\"gs_rs\">We consider <b>learning </b>in a Markov decision process where we are not explicitly given a <br/>reward function, but where instead we can observe an expert demonstrating the task that we <br/>want to learn to perform. This setting is useful in applications (such as the task of driving) …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=10260011060619377707&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">1933회 인용</a> <a href=\"/scholar?q=related:K_zLI7PhYo4J:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=10260011060619377707&amp;hl=ko&amp;as_sdt=0,5\">전체 32개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"/scholar?output=instlink&amp;q=info:K_zLI7PhYo4J:scholar.google.com/&amp;hl=ko&amp;as_sdt=0,5&amp;scillfp=10719971293236102319&amp;oi=llo\">FindIt @ KHU Seoul Lib</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"UYUlZeFRKUUJ\" data-did=\"UYUlZeFRKUUJ\" data-lid=\"\" data-rp=\"3\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=3&amp;d=4983604491168613713&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"UYUlZeFRKUUJ\" href=\"https://www.jair.org/index.php/jair/article/download/10166/24110/\"><span class=\"gs_ctg2\">[PDF]</span> jair.org</a><a href=\"/scholar?output=instlink&amp;q=info:UYUlZeFRKUUJ:scholar.google.com/&amp;hl=ko&amp;as_sdt=0,5&amp;scillfp=13284260007266901328&amp;oi=lle\">FindIt @ KHU Seoul Lib</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><a data-clk=\"hl=ko&amp;sa=T&amp;ct=res&amp;cd=3&amp;d=4983604491168613713&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"UYUlZeFRKUUJ\" href=\"http://www.jair.org/papers/paper301.html\" id=\"UYUlZeFRKUUJ\"><b>Reinforcement learning</b>: A survey</a></h3><div class=\"gs_a\"><a href=\"/citations?user=IcasIiwAAAAJ&amp;hl=ko&amp;oi=sra\">LP Kaelbling</a>, <a href=\"/citations?user=iRMZ2hoAAAAJ&amp;hl=ko&amp;oi=sra\">ML Littman</a>, <a href=\"/citations?user=PbfkKLcAAAAJ&amp;hl=ko&amp;oi=sra\">AW Moore</a> - Journal of artificial intelligence …, 1996 - jair.org</div><div class=\"gs_rs\">This paper surveys the field of reinforcement learning from a computer-science perspective. <br/>It is written to be accessible to researchers familiar with machine learning. Both the historical <br/>basis of the field and a broad selection of current work are summarized. Reinforcement …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=4983604491168613713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">7256회 인용</a> <a href=\"/scholar?q=related:UYUlZeFRKUUJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=4983604491168613713&amp;hl=ko&amp;as_sdt=0,5\">전체 111개의 버전</a> <a class=\"gs_nta gs_nph\" data-clk=\"hl=ko&amp;sa=T&amp;ct=wosc&amp;cd=3&amp;d=4983604491168613713&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"UYUlZeFRKUUJ\" href=\"http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=GSSearch&amp;SrcAuth=Scholar&amp;DestApp=WOS_CPL&amp;DestLinkType=CitingArticles&amp;UT=A1996UJ31200001&amp;SrcURL=https://scholar.google.co.kr/&amp;SrcDesc=Back+to+Google+Scholar&amp;GSPage=TC\">Web of Science: 2305</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"https://scholar.googleusercontent.com/scholar?q=cache:UYUlZeFRKUUJ:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">HTML 버전</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div><div class=\"gs_qsuggest_wrap gs_r\"><div class=\"gs_qsuggest gs_qsuggest_regular\"><h2>관련 검색어</h2><ul><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=1&amp;q=deep+reinforcement+learning&amp;qst=ib\"><b>deep </b>reinforcement learning</a></li><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=2&amp;q=inverse+reinforcement+learning&amp;qst=ib\"><b>inverse </b>reinforcement learning</a></li><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=3&amp;q=hierarchical+reinforcement+learning&amp;qst=ib\"><b>hierarchical </b>reinforcement learning</a></li><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=4&amp;q=multi+agent+reinforcement+learning&amp;qst=ib\"><b>multi agent </b>reinforcement learning</a></li><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=5&amp;q=reinforcement+learning+human-level&amp;qst=ib\">reinforcement learning <b>human-level</b></a></li><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=6&amp;q=%22control+through+deep%22+reinforcement+learning&amp;qst=ib\"><b>control through deep </b>reinforcement learning</a></li><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=7&amp;q=reward+reinforcement+learning&amp;qst=ib\"><b>reward </b>reinforcement learning</a></li><li><a href=\"/scholar?hl=ko&amp;as_sdt=0,5&amp;qsp=8&amp;q=reinforcement+learning+robot&amp;qst=ib\">reinforcement learning <b>robot</b></a></li></ul></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"L8T7Jue8J5MJ\" data-did=\"L8T7Jue8J5MJ\" data-lid=\"\" data-rp=\"4\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=4&amp;d=10603651548644623407&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"L8T7Jue8J5MJ\" href=\"https://arxiv.org/pdf/1312.5602.pdf)\"><span class=\"gs_ctg2\">[PDF]</span> arxiv.org</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><a data-clk=\"hl=ko&amp;sa=T&amp;ct=res&amp;cd=4&amp;d=10603651548644623407&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"L8T7Jue8J5MJ\" href=\"https://arxiv.org/abs/1312.5602\" id=\"L8T7Jue8J5MJ\">Playing atari with deep <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=rLdfJ1gAAAAJ&amp;hl=ko&amp;oi=sra\">V Mnih</a>, <a href=\"/citations?user=sGFyDIUAAAAJ&amp;hl=ko&amp;oi=sra\">K Kavukcuoglu</a>, <a href=\"/citations?user=-8DNE4UAAAAJ&amp;hl=ko&amp;oi=sra\">D Silver</a>, <a href=\"/citations?user=DaFHynwAAAAJ&amp;hl=ko&amp;oi=sra\">A Graves</a>… - arXiv preprint arXiv …, 2013 - arxiv.org</div><div class=\"gs_rs\">We present the first deep <b>learning </b>model to successfully learn control policies directly from <br/>high-dimensional sensory input using <b>reinforcement learning</b>. The model is a convolutional <br/>neural network, trained with a variant of Q-<b>learning</b>, whose input is raw pixels and whose …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=10603651548644623407&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">3459회 인용</a> <a href=\"/scholar?q=related:L8T7Jue8J5MJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=10603651548644623407&amp;hl=ko&amp;as_sdt=0,5\">전체 25개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"https://scholar.googleusercontent.com/scholar?q=cache:L8T7Jue8J5MJ:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">HTML 버전</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"uiYh7C2joKwJ\" data-did=\"uiYh7C2joKwJ\" data-lid=\"\" data-rp=\"5\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=5&amp;d=12439121588427761338&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"uiYh7C2joKwJ\" href=\"https://daiwk.github.io/assets/dqn.pdf\"><span class=\"gs_ctg2\">[PDF]</span> github.io</a><a href=\"/scholar?output=instlink&amp;q=info:uiYh7C2joKwJ:scholar.google.com/&amp;hl=ko&amp;as_sdt=0,5&amp;scillfp=17827465068675686287&amp;oi=lle\">FindIt @ KHU Seoul Lib</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><a data-clk=\"hl=ko&amp;sa=T&amp;ct=res&amp;cd=5&amp;d=12439121588427761338&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"uiYh7C2joKwJ\" href=\"https://www.nature.com/articles/nature14236?wm=book_wap_0005\" id=\"uiYh7C2joKwJ\">Human-level control through deep <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=rLdfJ1gAAAAJ&amp;hl=ko&amp;oi=sra\">V Mnih</a>, <a href=\"/citations?user=sGFyDIUAAAAJ&amp;hl=ko&amp;oi=sra\">K Kavukcuoglu</a>, <a href=\"/citations?user=-8DNE4UAAAAJ&amp;hl=ko&amp;oi=sra\">D Silver</a>, <a href=\"/citations?user=n_7ggqIAAAAJ&amp;hl=ko&amp;oi=sra\">AA Rusu</a>, <a href=\"/citations?user=_iYrAxEAAAAJ&amp;hl=ko&amp;oi=sra\">J Veness</a>… - Nature, 2015 - nature.com</div><div class=\"gs_rs\">The theory of <b>reinforcement learning </b>provides a normative account 1, deeply rooted in <br/>psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may <br/>optimize their control of an environment. To use <b>reinforcement learning </b>successfully in …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=12439121588427761338&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">8265회 인용</a> <a href=\"/scholar?q=related:uiYh7C2joKwJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=12439121588427761338&amp;hl=ko&amp;as_sdt=0,5\">전체 38개의 버전</a> <a class=\"gs_nta gs_nph\" data-clk=\"hl=ko&amp;sa=T&amp;ct=wosc&amp;cd=5&amp;d=12439121588427761338&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"uiYh7C2joKwJ\" href=\"http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=GSSearch&amp;SrcAuth=Scholar&amp;DestApp=WOS_CPL&amp;DestLinkType=CitingArticles&amp;UT=000350097300045&amp;SrcURL=https://scholar.google.co.kr/&amp;SrcDesc=Back+to+Google+Scholar&amp;GSPage=TC\">Web of Science: 2408</a> <a class=\"gs_or_mor gs_ota gs_oph\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"t8N5xiW9bXoJ\" data-did=\"t8N5xiW9bXoJ\" data-lid=\"\" data-rp=\"6\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=6&amp;d=8821915215029978039&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"t8N5xiW9bXoJ\" href=\"http://www.academia.edu/download/38529120/9780262257053_index.pdf\"><span class=\"gs_ctg2\">[PDF]</span> academia.edu</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><span class=\"gs_ctu\"><span class=\"gs_ct1\">[인용]</span><span class=\"gs_ct2\">[C]</span></span> <span id=\"t8N5xiW9bXoJ\"><b>Reinforcement learning</b>: An introduction</span></h3><div class=\"gs_a\"><a href=\"/citations?user=6m4wv6gAAAAJ&amp;hl=ko&amp;oi=sra\">RS Sutton</a>, AG Barto - 2018 - MIT press</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=8821915215029978039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">33585회 인용</a> <a href=\"/scholar?q=related:t8N5xiW9bXoJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=8821915215029978039&amp;hl=ko&amp;as_sdt=0,5\">전체 43개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"/scholar?output=instlink&amp;q=info:t8N5xiW9bXoJ:scholar.google.com/&amp;hl=ko&amp;as_sdt=0,5&amp;scillfp=14071317134698981574&amp;oi=llo\">FindIt @ KHU Seoul Lib</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"YW9AmGuXrcgJ\" data-did=\"YW9AmGuXrcgJ\" data-lid=\"\" data-rp=\"7\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=7&amp;d=14460380466928185185&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"YW9AmGuXrcgJ\" href=\"http://www.jmlr.org/proceedings/papers/v48/mniha16.pdf\"><span class=\"gs_ctg2\">[PDF]</span> jmlr.org</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><span class=\"gs_ctc\"><span class=\"gs_ct1\">[PDF]</span><span class=\"gs_ct2\">[PDF]</span></span> <a data-clk=\"hl=ko&amp;sa=T&amp;oi=ggp&amp;ct=res&amp;cd=7&amp;d=14460380466928185185&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"YW9AmGuXrcgJ\" href=\"http://www.jmlr.org/proceedings/papers/v48/mniha16.pdf\" id=\"YW9AmGuXrcgJ\">Asynchronous methods for deep <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=rLdfJ1gAAAAJ&amp;hl=ko&amp;oi=sra\">V Mnih</a>, <a href=\"/citations?user=DcWRJW4AAAAJ&amp;hl=ko&amp;oi=sra\">AP Badia</a>, <a href=\"/citations?user=c646VbAAAAAJ&amp;hl=ko&amp;oi=sra\">M Mirza</a>, <a href=\"/citations?user=DaFHynwAAAAJ&amp;hl=ko&amp;oi=sra\">A Graves</a>, <a href=\"/citations?user=htPVdRMAAAAJ&amp;hl=ko&amp;oi=sra\">T Lillicrap</a>… - … on machine <b>learning</b>, 2016 - jmlr.org</div><div class=\"gs_rs\">We propose a conceptually simple and lightweight framework for deep <b>reinforcement </b><br/><b>learning </b>that uses asynchronous gradient descent for optimization of deep neural network <br/>controllers. We present asynchronous variants of four standard <b>reinforcement learning </b> …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=14460380466928185185&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">2672회 인용</a> <a href=\"/scholar?q=related:YW9AmGuXrcgJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=14460380466928185185&amp;hl=ko&amp;as_sdt=0,5\">전체 24개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"http://scholar.googleusercontent.com/scholar?q=cache:YW9AmGuXrcgJ:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">HTML 버전</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"mlg_xz067S0J\" data-did=\"mlg_xz067S0J\" data-lid=\"\" data-rp=\"8\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=8&amp;d=3309365338197416090&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"mlg_xz067S0J\" href=\"http://ai.stanford.edu/~ang/papers/icml00-irl.pdf\"><span class=\"gs_ctg2\">[PDF]</span> stanford.edu</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><span class=\"gs_ctc\"><span class=\"gs_ct1\">[PDF]</span><span class=\"gs_ct2\">[PDF]</span></span> <a data-clk=\"hl=ko&amp;sa=T&amp;oi=ggp&amp;ct=res&amp;cd=8&amp;d=3309365338197416090&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"mlg_xz067S0J\" href=\"http://ai.stanford.edu/~ang/papers/icml00-irl.pdf\" id=\"mlg_xz067S0J\">Algorithms for inverse <b>reinforcement learning</b>.</a></h3><div class=\"gs_a\"><a href=\"/citations?user=mG4imMEAAAAJ&amp;hl=ko&amp;oi=sra\">AY Ng</a>, <a href=\"/citations?user=2oy3OXYAAAAJ&amp;hl=ko&amp;oi=sra\">SJ Russell</a> - Icml, 2000 - ai.stanford.edu</div><div class=\"gs_rs\">This paper addresses the problem of inverse <b>reinforcement learning </b>(IRL) in Markov <br/>decision processes, that is, the problem of extracting a reward function given observed, <br/>optimal behavior. IRL may be useful for apprenticeship <b>learning </b>to acquire skilled behavior …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=3309365338197416090&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">1698회 인용</a> <a href=\"/scholar?q=related:mlg_xz067S0J:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=3309365338197416090&amp;hl=ko&amp;as_sdt=0,5\">전체 14개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"http://scholar.googleusercontent.com/scholar?q=cache:mlg_xz067S0J:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">HTML 버전</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div> <div class=\"gs_r gs_or gs_scl\" data-cid=\"lTNo4sNhWzkJ\" data-did=\"lTNo4sNhWzkJ\" data-lid=\"\" data-rp=\"9\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=9&amp;d=4133004576987558805&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"lTNo4sNhWzkJ\" href=\"https://arxiv.org/pdf/1509.02971\"><span class=\"gs_ctg2\">[PDF]</span> arxiv.org</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><a data-clk=\"hl=ko&amp;sa=T&amp;ct=res&amp;cd=9&amp;d=4133004576987558805&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"lTNo4sNhWzkJ\" href=\"https://arxiv.org/abs/1509.02971\" id=\"lTNo4sNhWzkJ\">Continuous control with deep <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=htPVdRMAAAAJ&amp;hl=ko&amp;oi=sra\">TP Lillicrap</a>, <a href=\"/citations?user=IdhJtDwAAAAJ&amp;hl=ko&amp;oi=sra\">JJ Hunt</a>, <a href=\"/citations?user=GPgAyU0AAAAJ&amp;hl=ko&amp;oi=sra\">A Pritzel</a>, <a href=\"/citations?user=79k7bGEAAAAJ&amp;hl=ko&amp;oi=sra\">N Heess</a>, <a href=\"/citations?user=gVFnjOcAAAAJ&amp;hl=ko&amp;oi=sra\">T Erez</a>… - arXiv preprint arXiv …, 2015 - arxiv.org</div><div class=\"gs_rs\">We adapt the ideas underlying the success of Deep Q-<b>Learning </b>to the continuous action <br/>domain. We present an actor-critic, model-free algorithm based on the deterministic policy <br/>gradient that can operate over continuous action spaces. Using the same <b>learning </b>algorithm …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=4133004576987558805&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">2779회 인용</a> <a href=\"/scholar?q=related:lTNo4sNhWzkJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=4133004576987558805&amp;hl=ko&amp;as_sdt=0,5\">전체 12개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"https://scholar.googleusercontent.com/scholar?q=cache:lTNo4sNhWzkJ:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">HTML 버전</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div></div><div id=\"gs_res_ccl_bot\"><div class=\"gs_r gs_alrt_btm gs_oph gs_ota\"><a class=\"gs_btnM gs_in_ib\" href=\"/scholar_alerts?view_op=create_alert_options&amp;hl=ko&amp;alert_query=intitle:%22reinforcement+learning%22&amp;alert_params=%3Fhl%3Dko%26as_sdt%3D0,5\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\">알림 만들기</span></a></div><div id=\"gs_n\" role=\"navigation\"><center><table cellpadding=\"0\" width=\"1%\"><tr align=\"center\" valign=\"top\"><td align=\"right\" nowrap=\"\"><span class=\"gs_ico gs_ico_nav_first\"></span><b style=\"display:block;margin-right:35px;visibility:hidden\">이전</b></td><td><span class=\"gs_ico gs_ico_nav_current\"></span><b>1</b></td><td><a href=\"/scholar?start=10&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>2</a></td><td><a href=\"/scholar?start=20&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>3</a></td><td><a href=\"/scholar?start=30&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>4</a></td><td><a href=\"/scholar?start=40&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>5</a></td><td><a href=\"/scholar?start=50&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>6</a></td><td><a href=\"/scholar?start=60&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>7</a></td><td><a href=\"/scholar?start=70&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>8</a></td><td><a href=\"/scholar?start=80&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>9</a></td><td><a href=\"/scholar?start=90&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_page\"></span>10</a></td><td align=\"left\" nowrap=\"\"><a href=\"/scholar?start=10&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\"><span class=\"gs_ico gs_ico_nav_next\"></span><b style=\"display:block;margin-left:53px\">다음</b></a></td></tr></table></center></div><div id=\"gs_nm\" role=\"navigation\"><button aria-label=\"이전\" class=\"gs_btnPL gs_in_ib gs_btn_lrge gs_btn_half gs_btn_lsu\" disabled=\"\" type=\"button\"><span class=\"gs_wr\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></span></button><button aria-label=\"다음\" class=\"gs_btnPR gs_in_ib gs_btn_lrge gs_btn_half gs_btn_lsu\" onclick=\"window.location='/scholar?start\\x3d10\\x26q\\x3dreinforcement+learning\\x26hl\\x3dko\\x26as_sdt\\x3d0,5'\" type=\"button\"><span class=\"gs_wr\"><span class=\"gs_ico\"></span><span class=\"gs_lbl\"></span></span></button><div id=\"gs_nml\"><b class=\"gs_nma\">1</b><a class=\"gs_nma\" href=\"/scholar?start=10&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">2</a><a class=\"gs_nma\" href=\"/scholar?start=20&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">3</a><a class=\"gs_nma\" href=\"/scholar?start=30&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">4</a><a class=\"gs_nma\" href=\"/scholar?start=40&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">5</a><a class=\"gs_nma\" href=\"/scholar?start=50&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">6</a><a class=\"gs_nma\" href=\"/scholar?start=60&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">7</a><a class=\"gs_nma\" href=\"/scholar?start=70&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">8</a><a class=\"gs_nma\" href=\"/scholar?start=80&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">9</a><a class=\"gs_nma\" href=\"/scholar?start=90&amp;q=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">10</a></div></div></div></div><iframe src=\"//scholar.google.com/gen_nid\" style=\"display:none\"></iframe></div></div><div id=\"gs_ftr_sp\" role=\"presentation\"></div><div id=\"gs_ftr\" role=\"contentinfo\"><div id=\"gs_ftr_rt\"><a href=\"/intl/ko/scholar/about.html\">도움말</a><a href=\"//www.google.co.kr/intl/ko/policies/privacy/\">개인정보취급방침</a><a href=\"//www.google.co.kr/intl/ko/policies/terms/\">약관</a></div></div></div></body></html>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Info = soup.find_all('div',{'class':'gs_r gs_or gs_scl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"gs_r gs_or gs_scl\" data-cid=\"CTeeMoqfgxMJ\" data-did=\"CTeeMoqfgxMJ\" data-lid=\"\" data-rp=\"0\"><div class=\"gs_ggs gs_fl\"><div class=\"gs_ggsd\"><div class=\"gs_or_ggsm\" ontouchstart=\"gs_evt_dsp(event)\" tabindex=\"-1\"><a data-clk=\"hl=ko&amp;sa=T&amp;oi=gga&amp;ct=gga&amp;cd=0&amp;d=1406142924573259529&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"CTeeMoqfgxMJ\" href=\"https://login.cs.utexas.edu/sites/default/files/legacy_files/research/documents/1%20intro%20up%20to%20RL%3ATD.pdf\"><span class=\"gs_ctg2\">[PDF]</span> utexas.edu</a></div></div></div><div class=\"gs_ri\"><h3 class=\"gs_rt\" ontouchstart=\"gs_evt_dsp(event)\"><span class=\"gs_ctc\"><span class=\"gs_ct1\">[책]</span><span class=\"gs_ct2\">[B]</span></span> <a data-clk=\"hl=ko&amp;sa=T&amp;oi=ggp&amp;ct=res&amp;cd=0&amp;d=1406142924573259529&amp;ei=g14lXqO6CZSiygS5vpq4Cw\" data-clk-atid=\"CTeeMoqfgxMJ\" href=\"https://login.cs.utexas.edu/sites/default/files/legacy_files/research/documents/1%20intro%20up%20to%20RL%3ATD.pdf\" id=\"CTeeMoqfgxMJ\">Introduction to <b>reinforcement learning</b></a></h3><div class=\"gs_a\"><a href=\"/citations?user=6m4wv6gAAAAJ&amp;hl=ko&amp;oi=sra\">RS Sutton</a>, AG Barto - 1998 - login.cs.utexas.edu</div><div class=\"gs_rs\">“We are nearing an important milestone in the history of life on earth, the point at which we <br/>can construct machines with the potential for exhibiting an intelligence comparable to ours.”--<br/>David Waltz, 1988 (recent president of AAAI) Should occur in≈ 2030 for≈ $1000 We don't …</div><div class=\"gs_fl\"><a class=\"gs_or_sav\" href=\"javascript:void(0)\" role=\"button\" title=\"저장\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M8 11.57l3.824 2.308-1.015-4.35 3.379-2.926-4.45-.378L8 2.122 6.261 6.224l-4.449.378 3.379 2.926-1.015 4.35z\"></path></svg></a> <a aria-controls=\"gs_cit\" aria-haspopup=\"true\" class=\"gs_or_cit gs_nph\" href=\"javascript:void(0)\" role=\"button\" title=\"인용\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 3.5v5h2v.375L1.75 12.5h3L6.5 8.875V3.5zM9.5 3.5v5h2v.375L9.75 12.5h3L14.5 8.875V3.5z\"></path></svg></a> <a href=\"/scholar?cites=1406142924573259529&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=ko\">6358회 인용</a> <a href=\"/scholar?q=related:CTeeMoqfgxMJ:scholar.google.com/&amp;scioq=reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">관련 학술자료</a> <a class=\"gs_nph\" href=\"/scholar?cluster=1406142924573259529&amp;hl=ko&amp;as_sdt=0,5\">전체 6개의 버전</a> <a class=\"gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"더보기\"><svg class=\"gs_or_svg\" viewbox=\"-1 0 17 16\"><path d=\"M1.5 5.5l2-2L8 8l-4.5 4.5-2-2L4 8zM8.5 5.5l2-2L15 8l-4.5 4.5-2-2L11 8z\"></path></svg></a> <a class=\"gs_or_nvi\" href=\"/scholar?output=instlink&amp;q=info:CTeeMoqfgxMJ:scholar.google.com/&amp;hl=ko&amp;as_sdt=0,5&amp;scillfp=10110385682573663327&amp;oi=llo\">FindIt @ KHU Seoul Lib</a> <a class=\"gs_or_nvi\" href=\"https://scholar.googleusercontent.com/scholar?q=cache:CTeeMoqfgxMJ:scholar.google.com/+reinforcement+learning&amp;hl=ko&amp;as_sdt=0,5\">HTML 버전</a> <a class=\"gs_or_nvi gs_or_mor\" href=\"javascript:void(0)\" role=\"button\" title=\"숨기기\"><svg class=\"gs_or_svg\" viewbox=\"0 0 17 16\"><path d=\"M8.5 5.5l-2-2L2 8l4.5 4.5 2-2L6 8zM15.5 5.5l-2-2L9 8l4.5 4.5 2-2L13 8z\"></path></svg></a></div></div></div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction to reinforcement learning'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info[0].find('div',{\"class\":\"gs_ri\"}).a.text # paper title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://login.cs.utexas.edu/sites/default/files/legacy_files/research/documents/1%20intro%20up%20to%20RL%3ATD.pdf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info[0].find('div',{\"class\":\"gs_ri\"}).a['href'] # paper link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RS Sutton, AG Barto - 1998 - login.cs.utexas.edu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info[0].find('div',{\"class\":\"gs_a\"}).text # author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"“We are nearing an important milestone in the history of life on earth, the point at which we can construct machines with the potential for exhibiting an intelligence comparable to ours.”--David Waltz, 1988 (recent president of AAAI) Should occur in≈ 2030 for≈ $1000 We don't\\xa0…\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info[0].find('div',{\"class\":\"gs_rs\"}).text # abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### citation issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PDF] utexas.edu\n"
     ]
    }
   ],
   "source": [
    "print(Info[0].find('div',{\"class\":\"gs_fl\"}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PDF] utexas.edu\n",
      "  401회 인용 관련 학술자료 전체 4개의 버전  저장된 페이지 \n",
      "[PDF] berkeley.eduFull View\n",
      "[PDF] jair.orgFindIt @ KHU Seoul Lib\n",
      "[PDF] arxiv.org\n",
      "[PDF] github.ioFindIt @ KHU Seoul Lib\n",
      "[PDF] academia.edu\n",
      "[PDF] jmlr.org\n",
      "[PDF] stanford.edu\n",
      "[PDF] arxiv.org\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(Info[i].find('div',{\"class\":\"gs_fl\"}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(Info[0].find_all('div',{\"class\":\"gs_fl\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PDF] utexas.edu'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info[0].find_all('div',{\"class\":\"gs_fl\"})[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  6358회 인용 관련 학술자료 전체 6개의 버전  FindIt @ KHU Seoul Lib HTML 버전 '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info[0].find_all('div',{\"class\":\"gs_fl\"})[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(len(Info[i].find_all('div',{\"class\":\"gs_fl\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6358회 인용 관련 학술자료 전체 6개의 버전  FindIt @ KHU Seoul Lib HTML 버전 \n",
      "  401회 인용 관련 학술자료 전체 4개의 버전  저장된 페이지 \n",
      "  1933회 인용 관련 학술자료 전체 32개의 버전  FindIt @ KHU Seoul Lib \n",
      "  7256회 인용 관련 학술자료 전체 111개의 버전 Web of Science: 2305  HTML 버전 \n",
      "  3459회 인용 관련 학술자료 전체 25개의 버전  HTML 버전 \n",
      "  8265회 인용 관련 학술자료 전체 38개의 버전 Web of Science: 2408  \n",
      "  33585회 인용 관련 학술자료 전체 43개의 버전  FindIt @ KHU Seoul Lib \n",
      "  2672회 인용 관련 학술자료 전체 24개의 버전  HTML 버전 \n",
      "  1698회 인용 관련 학술자료 전체 14개의 버전  HTML 버전 \n",
      "  2779회 인용 관련 학술자료 전체 12개의 버전  HTML 버전 \n"
     ]
    }
   ],
   "source": [
    "Cite = []\n",
    "for i in range(0,10):\n",
    "    tmptext = Info[i].find_all('div',{\"class\":\"gs_fl\"})\n",
    "    for tag in tmptext:\n",
    "        if '[PDF]' not in tag.text:\n",
    "            print(tag.text)\n",
    "            Cite.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  6358회 인용 관련 학술자료 전체 6개의 버전  FindIt @ KHU Seoul Lib HTML 버전 ',\n",
       " '  401회 인용 관련 학술자료 전체 4개의 버전  저장된 페이지 ',\n",
       " '  1933회 인용 관련 학술자료 전체 32개의 버전  FindIt @ KHU Seoul Lib ',\n",
       " '  7256회 인용 관련 학술자료 전체 111개의 버전 Web of Science: 2305  HTML 버전 ',\n",
       " '  3459회 인용 관련 학술자료 전체 25개의 버전  HTML 버전 ',\n",
       " '  8265회 인용 관련 학술자료 전체 38개의 버전 Web of Science: 2408  ',\n",
       " '  33585회 인용 관련 학술자료 전체 43개의 버전  FindIt @ KHU Seoul Lib ',\n",
       " '  2672회 인용 관련 학술자료 전체 24개의 버전  HTML 버전 ',\n",
       " '  1698회 인용 관련 학술자료 전체 14개의 버전  HTML 버전 ',\n",
       " '  2779회 인용 관련 학술자료 전체 12개의 버전  HTML 버전 ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Cite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36',\n",
    "    'referer' : 'http://www.naver.com'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'reinforcement learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://scholar.google.co.kr/scholar?start='\n",
    "url2 = '&q=reinforcement+learning&hl=ko&as_sdt=0,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchPages = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetUrl = []\n",
    "for i in range(0,searchPages):\n",
    "    tmpUrl = url1+str(i*10)+url2\n",
    "    TargetUrl.append(tmpUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:07<00:00,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "POST = pd.DataFrame(columns=['title','paperLink','AuthorInfo','Abstract','Citation'])\n",
    "\n",
    "for url in tqdm(TargetUrl):\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    Info = soup.find_all('div',{'class':'gs_r gs_or gs_scl'})\n",
    "    for i in range(0, len(Info)):\n",
    "        title = Info[i].find('div',{\"class\":\"gs_ri\"}).a.text\n",
    "        paperLink = Info[i].find('div',{\"class\":\"gs_ri\"}).a['href']\n",
    "        authorinfo = Info[i].find('div',{\"class\":\"gs_a\"}).text\n",
    "        try:\n",
    "            abstract = Info[i].find('div',{\"class\":\"gs_rs\"}).text\n",
    "\n",
    "        except AttributeError:\n",
    "            abstract = '999'\n",
    "            \n",
    "        tmptext = Info[i].find_all('div',{\"class\":\"gs_fl\"})\n",
    "        for tag in tmptext:\n",
    "            if '[PDF]' not in tag.text:\n",
    "                citation = tag.text\n",
    "\n",
    "        tmpDict = {'title' : title,\n",
    "                   'paperLink' : paperLink,\n",
    "                   'AuthorInfo' : authorinfo,\n",
    "                   'Abstract' : abstract,\n",
    "                   'Citation' : citation\n",
    "                  }\n",
    "\n",
    "        TMP = pd.DataFrame.from_dict(tmpDict, orient='index').transpose()\n",
    "        POST = POST.append(TMP)\n",
    "    sleep(randint(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>paperLink</th>\n",
       "      <th>AuthorInfo</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Citation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction to reinforcement learning</td>\n",
       "      <td>https://login.cs.utexas.edu/sites/default/file...</td>\n",
       "      <td>RS Sutton, AG Barto - 1998 - login.cs.utexas.edu</td>\n",
       "      <td>“We are nearing an important milestone in the ...</td>\n",
       "      <td>6358회 인용 관련 학술자료 전체 6개의 버전  FindIt @ KHU Seo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficient exploration in reinforcement learning</td>\n",
       "      <td>http://citeseerx.ist.psu.edu/viewdoc/summary?d...</td>\n",
       "      <td>SB Thrun - 1992 - Citeseer</td>\n",
       "      <td>Exploration plays a fundamental role in any ac...</td>\n",
       "      <td>401회 인용 관련 학술자료 전체 4개의 버전  저장된 페이지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apprenticeship learning via inverse reinforcem...</td>\n",
       "      <td>https://dl.acm.org/citation.cfm?id=1015430</td>\n",
       "      <td>P Abbeel, AY Ng - … -first international confe...</td>\n",
       "      <td>We consider learning in a Markov decision proc...</td>\n",
       "      <td>1933회 인용 관련 학술자료 전체 32개의 버전  FindIt @ KHU Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reinforcement learning: A survey</td>\n",
       "      <td>http://www.jair.org/papers/paper301.html</td>\n",
       "      <td>LP Kaelbling, ML Littman, AW Moore - Journal o...</td>\n",
       "      <td>This paper surveys the field of reinforcement ...</td>\n",
       "      <td>7256회 인용 관련 학술자료 전체 111개의 버전 Web of Science:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Playing atari with deep reinforcement learning</td>\n",
       "      <td>https://arxiv.org/abs/1312.5602</td>\n",
       "      <td>V Mnih, K Kavukcuoglu, D Silver, A Graves… - a...</td>\n",
       "      <td>We present the first deep learning model to su...</td>\n",
       "      <td>3459회 인용 관련 학술자료 전체 25개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human-level control through deep reinforcement...</td>\n",
       "      <td>https://www.nature.com/articles/nature14236?wm...</td>\n",
       "      <td>V Mnih, K Kavukcuoglu, D Silver, AA Rusu, J Ve...</td>\n",
       "      <td>The theory of reinforcement learning provides ...</td>\n",
       "      <td>8265회 인용 관련 학술자료 전체 38개의 버전 Web of Science: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RS Sutton</td>\n",
       "      <td>/citations?user=6m4wv6gAAAAJ&amp;hl=ko&amp;oi=sra</td>\n",
       "      <td>RS Sutton, AG Barto - 2018 - MIT press</td>\n",
       "      <td>999</td>\n",
       "      <td>33585회 인용 관련 학술자료 전체 43개의 버전  FindIt @ KHU S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asynchronous methods for deep reinforcement le...</td>\n",
       "      <td>http://www.jmlr.org/proceedings/papers/v48/mni...</td>\n",
       "      <td>V Mnih, AP Badia, M Mirza, A Graves, T Lillicr...</td>\n",
       "      <td>We propose a conceptually simple and lightweig...</td>\n",
       "      <td>2672회 인용 관련 학술자료 전체 24개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algorithms for inverse reinforcement learning.</td>\n",
       "      <td>http://ai.stanford.edu/~ang/papers/icml00-irl.pdf</td>\n",
       "      <td>AY Ng, SJ Russell - Icml, 2000 - ai.stanford.edu</td>\n",
       "      <td>This paper addresses the problem of inverse re...</td>\n",
       "      <td>1698회 인용 관련 학술자료 전체 14개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Continuous control with deep reinforcement lea...</td>\n",
       "      <td>https://arxiv.org/abs/1509.02971</td>\n",
       "      <td>TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T E...</td>\n",
       "      <td>We adapt the ideas underlying the success of D...</td>\n",
       "      <td>2779회 인용 관련 학술자료 전체 12개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep reinforcement learning with double q-lear...</td>\n",
       "      <td>https://www.aaai.org/ocs/index.php/AAAI/AAAI16...</td>\n",
       "      <td>H Van Hasselt, A Guez, D Silver - Thirtieth AA...</td>\n",
       "      <td>The popular Q-learning algorithm is known to o...</td>\n",
       "      <td>1631회 인용 관련 학술자료 전체 10개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feudal reinforcement learning</td>\n",
       "      <td>http://papers.nips.cc/paper/714-feudal-reinfor...</td>\n",
       "      <td>P Dayan, GE Hinton - Advances in neural inform...</td>\n",
       "      <td>One way to speed up reinforcement learning is ...</td>\n",
       "      <td>528회 인용 관련 학술자료 전체 18개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maximum entropy inverse reinforcement learning</td>\n",
       "      <td>http://new.aaai.org/Papers/AAAI/2008/AAAI08-22...</td>\n",
       "      <td>BD Ziebart, A Maas, JA Bagnell, AK Dey - 2008 ...</td>\n",
       "      <td>Recent research has shown the benefit of frami...</td>\n",
       "      <td>1193회 인용 관련 학술자료 전체 34개의 버전  FindIt @ KHU Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Policy gradient methods for reinforcement lear...</td>\n",
       "      <td>http://papers.nips.cc/paper/1713-policy-gradie...</td>\n",
       "      <td>RS Sutton, DA McAllester, SP Singh… - Advances...</td>\n",
       "      <td>Function approximation is essential to reinfor...</td>\n",
       "      <td>2716회 인용 관련 학술자료 전체 29개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improving elevator performance using reinforce...</td>\n",
       "      <td>http://papers.nips.cc/paper/1073-improving-ele...</td>\n",
       "      <td>RH Crites, AG Barto - Advances in neural infor...</td>\n",
       "      <td>This paper describes the application of reinfo...</td>\n",
       "      <td>766회 인용 관련 학술자료 전체 14개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reinforcement learning</td>\n",
       "      <td>https://link.springer.com/content/pdf/10.1007/...</td>\n",
       "      <td>M Wiering, M Van Otterlo - Adaptation, learnin...</td>\n",
       "      <td>Adaptation, Learning, and Optimization, Volume...</td>\n",
       "      <td>489회 인용 관련 학술자료 전체 5개의 버전  FindIt @ KHU Seou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple statistical gradient-following algorith...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/BF00...</td>\n",
       "      <td>RJ Williams - Machine learning, 1992 - Springer</td>\n",
       "      <td>This article presents a general class of assoc...</td>\n",
       "      <td>4025회 인용 관련 학술자료 전체 20개의 버전 Web of Science: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reinforcement learning with hierarchies of mac...</td>\n",
       "      <td>http://papers.nips.cc/paper/1384-reinforcement...</td>\n",
       "      <td>R Parr, SJ Russell - Advances in neural inform...</td>\n",
       "      <td>We present a new approach to reinforcement lea...</td>\n",
       "      <td>730회 인용 관련 학술자료 전체 26개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization in reinforcement learning: Succ...</td>\n",
       "      <td>http://papers.nips.cc/paper/1109-generalizatio...</td>\n",
       "      <td>RS Sutton - Advances in neural information pro...</td>\n",
       "      <td>On large problems, reinforcement learning syst...</td>\n",
       "      <td>1382회 인용 관련 학술자료 전체 19개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intrinsically motivated reinforcement learning</td>\n",
       "      <td>http://papers.nips.cc/paper/2552-intrinsically...</td>\n",
       "      <td>N Chentanez, AG Barto, SP Singh - Advances in ...</td>\n",
       "      <td>Psychologists call behavior intrinsically moti...</td>\n",
       "      <td>586회 인용 관련 학술자료 전체 28개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Residual algorithms: Reinforcement learning wi...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>L Baird - Machine Learning Proceedings 1995, 1...</td>\n",
       "      <td>ABSTRACT A number of reinforcement learning al...</td>\n",
       "      <td>954회 인용 관련 학술자료 전체 20개의 버전  FindIt @ KHU Seo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-agent reinforcement learning: Independen...</td>\n",
       "      <td>https://books.google.co.kr/books?hl=ko&amp;lr=&amp;id=...</td>\n",
       "      <td>M Tan - … the tenth international conference o...</td>\n",
       "      <td>Intelligent human agents exist in a coop-erati...</td>\n",
       "      <td>1158회 인용 관련 학술자료 전체 13개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Markov games as a framework for multi-agent re...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ML Littman - Machine learning proceedings 1994...</td>\n",
       "      <td>In the Markov decision process (MDP) formaliza...</td>\n",
       "      <td>1985회 인용 관련 학술자료 전체 30개의 버전  FindIt @ KHU Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By carrot or by stick: cognitive reinforcement...</td>\n",
       "      <td>https://science.sciencemag.org/content/306/570...</td>\n",
       "      <td>MJ Frank, LC Seeberger, RC O'reilly - Science,...</td>\n",
       "      <td>To what extent do we learn from the positive v...</td>\n",
       "      <td>1621회 인용 관련 학술자료 전체 33개의 버전 Web of Science: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kernel-based reinforcement learning</td>\n",
       "      <td>https://link.springer.com/article/10.1023/A:10...</td>\n",
       "      <td>D Ormoneit, Ś Sen - Machine learning, 2002 - S...</td>\n",
       "      <td>We present a kernel-based approach to reinforc...</td>\n",
       "      <td>505회 인용 관련 학술자료 전체 15개의 버전 Web of Science: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward, motivation, and reinforcement learning</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>P Dayan, BW Balleine - Neuron, 2002 - Elsevier</td>\n",
       "      <td>There is substantial evidence that dopamine is...</td>\n",
       "      <td>829회 인용 관련 학술자료 전체 28개의 버전 Web of Science: 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algorithms for reinforcement learning</td>\n",
       "      <td>https://www.morganclaypool.com/doi/abs/10.2200...</td>\n",
       "      <td>C Szepesvári - … on artificial intelligence an...</td>\n",
       "      <td>Reinforcement learning is a learning paradigm ...</td>\n",
       "      <td>867회 인용 관련 학술자료 전체 21개의 버전  FindIt @ KHU Seo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiagent reinforcement learning: theoretical...</td>\n",
       "      <td>http://citeseerx.ist.psu.edu/viewdoc/download?...</td>\n",
       "      <td>J Hu, MP Wellman - ICML, 1998 - Citeseer</td>\n",
       "      <td>In this paper, we adopt general-sum stochastic...</td>\n",
       "      <td>905회 인용 관련 학술자료 전체 16개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous inverted helicopter flight via rein...</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/1155...</td>\n",
       "      <td>AY Ng, A Coates, M Diel, V Ganapathi, J Schult...</td>\n",
       "      <td>Helicopters have highly stochastic, nonlinear,...</td>\n",
       "      <td>515회 인용 관련 학술자료 전체 26개의 버전  FindIt @ KHU Seo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural architecture search with reinforcement ...</td>\n",
       "      <td>https://arxiv.org/abs/1611.01578</td>\n",
       "      <td>B Zoph, QV Le - arXiv preprint arXiv:1611.0157...</td>\n",
       "      <td>Neural networks are powerful and flexible mode...</td>\n",
       "      <td>1215회 인용 관련 학술자료 전체 13개의 버전  HTML 버전</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0             Introduction to reinforcement learning   \n",
       "0    Efficient exploration in reinforcement learning   \n",
       "0  Apprenticeship learning via inverse reinforcem...   \n",
       "0                   Reinforcement learning: A survey   \n",
       "0     Playing atari with deep reinforcement learning   \n",
       "0  Human-level control through deep reinforcement...   \n",
       "0                                          RS Sutton   \n",
       "0  Asynchronous methods for deep reinforcement le...   \n",
       "0     Algorithms for inverse reinforcement learning.   \n",
       "0  Continuous control with deep reinforcement lea...   \n",
       "0  Deep reinforcement learning with double q-lear...   \n",
       "0                      Feudal reinforcement learning   \n",
       "0     Maximum entropy inverse reinforcement learning   \n",
       "0  Policy gradient methods for reinforcement lear...   \n",
       "0  Improving elevator performance using reinforce...   \n",
       "0                             Reinforcement learning   \n",
       "0  Simple statistical gradient-following algorith...   \n",
       "0  Reinforcement learning with hierarchies of mac...   \n",
       "0  Generalization in reinforcement learning: Succ...   \n",
       "0     Intrinsically motivated reinforcement learning   \n",
       "0  Residual algorithms: Reinforcement learning wi...   \n",
       "0  Multi-agent reinforcement learning: Independen...   \n",
       "0  Markov games as a framework for multi-agent re...   \n",
       "0  By carrot or by stick: cognitive reinforcement...   \n",
       "0                Kernel-based reinforcement learning   \n",
       "0     Reward, motivation, and reinforcement learning   \n",
       "0              Algorithms for reinforcement learning   \n",
       "0  Multiagent reinforcement learning: theoretical...   \n",
       "0  Autonomous inverted helicopter flight via rein...   \n",
       "0  Neural architecture search with reinforcement ...   \n",
       "\n",
       "                                           paperLink  \\\n",
       "0  https://login.cs.utexas.edu/sites/default/file...   \n",
       "0  http://citeseerx.ist.psu.edu/viewdoc/summary?d...   \n",
       "0         https://dl.acm.org/citation.cfm?id=1015430   \n",
       "0           http://www.jair.org/papers/paper301.html   \n",
       "0                    https://arxiv.org/abs/1312.5602   \n",
       "0  https://www.nature.com/articles/nature14236?wm...   \n",
       "0          /citations?user=6m4wv6gAAAAJ&hl=ko&oi=sra   \n",
       "0  http://www.jmlr.org/proceedings/papers/v48/mni...   \n",
       "0  http://ai.stanford.edu/~ang/papers/icml00-irl.pdf   \n",
       "0                   https://arxiv.org/abs/1509.02971   \n",
       "0  https://www.aaai.org/ocs/index.php/AAAI/AAAI16...   \n",
       "0  http://papers.nips.cc/paper/714-feudal-reinfor...   \n",
       "0  http://new.aaai.org/Papers/AAAI/2008/AAAI08-22...   \n",
       "0  http://papers.nips.cc/paper/1713-policy-gradie...   \n",
       "0  http://papers.nips.cc/paper/1073-improving-ele...   \n",
       "0  https://link.springer.com/content/pdf/10.1007/...   \n",
       "0  https://link.springer.com/article/10.1007/BF00...   \n",
       "0  http://papers.nips.cc/paper/1384-reinforcement...   \n",
       "0  http://papers.nips.cc/paper/1109-generalizatio...   \n",
       "0  http://papers.nips.cc/paper/2552-intrinsically...   \n",
       "0  https://www.sciencedirect.com/science/article/...   \n",
       "0  https://books.google.co.kr/books?hl=ko&lr=&id=...   \n",
       "0  https://www.sciencedirect.com/science/article/...   \n",
       "0  https://science.sciencemag.org/content/306/570...   \n",
       "0  https://link.springer.com/article/10.1023/A:10...   \n",
       "0  https://www.sciencedirect.com/science/article/...   \n",
       "0  https://www.morganclaypool.com/doi/abs/10.2200...   \n",
       "0  http://citeseerx.ist.psu.edu/viewdoc/download?...   \n",
       "0  https://link.springer.com/chapter/10.1007/1155...   \n",
       "0                   https://arxiv.org/abs/1611.01578   \n",
       "\n",
       "                                          AuthorInfo  \\\n",
       "0   RS Sutton, AG Barto - 1998 - login.cs.utexas.edu   \n",
       "0                         SB Thrun - 1992 - Citeseer   \n",
       "0  P Abbeel, AY Ng - … -first international confe...   \n",
       "0  LP Kaelbling, ML Littman, AW Moore - Journal o...   \n",
       "0  V Mnih, K Kavukcuoglu, D Silver, A Graves… - a...   \n",
       "0  V Mnih, K Kavukcuoglu, D Silver, AA Rusu, J Ve...   \n",
       "0             RS Sutton, AG Barto - 2018 - MIT press   \n",
       "0  V Mnih, AP Badia, M Mirza, A Graves, T Lillicr...   \n",
       "0   AY Ng, SJ Russell - Icml, 2000 - ai.stanford.edu   \n",
       "0  TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T E...   \n",
       "0  H Van Hasselt, A Guez, D Silver - Thirtieth AA...   \n",
       "0  P Dayan, GE Hinton - Advances in neural inform...   \n",
       "0  BD Ziebart, A Maas, JA Bagnell, AK Dey - 2008 ...   \n",
       "0  RS Sutton, DA McAllester, SP Singh… - Advances...   \n",
       "0  RH Crites, AG Barto - Advances in neural infor...   \n",
       "0  M Wiering, M Van Otterlo - Adaptation, learnin...   \n",
       "0    RJ Williams - Machine learning, 1992 - Springer   \n",
       "0  R Parr, SJ Russell - Advances in neural inform...   \n",
       "0  RS Sutton - Advances in neural information pro...   \n",
       "0  N Chentanez, AG Barto, SP Singh - Advances in ...   \n",
       "0  L Baird - Machine Learning Proceedings 1995, 1...   \n",
       "0  M Tan - … the tenth international conference o...   \n",
       "0  ML Littman - Machine learning proceedings 1994...   \n",
       "0  MJ Frank, LC Seeberger, RC O'reilly - Science,...   \n",
       "0  D Ormoneit, Ś Sen - Machine learning, 2002 - S...   \n",
       "0     P Dayan, BW Balleine - Neuron, 2002 - Elsevier   \n",
       "0  C Szepesvári - … on artificial intelligence an...   \n",
       "0           J Hu, MP Wellman - ICML, 1998 - Citeseer   \n",
       "0  AY Ng, A Coates, M Diel, V Ganapathi, J Schult...   \n",
       "0  B Zoph, QV Le - arXiv preprint arXiv:1611.0157...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  “We are nearing an important milestone in the ...   \n",
       "0  Exploration plays a fundamental role in any ac...   \n",
       "0  We consider learning in a Markov decision proc...   \n",
       "0  This paper surveys the field of reinforcement ...   \n",
       "0  We present the first deep learning model to su...   \n",
       "0  The theory of reinforcement learning provides ...   \n",
       "0                                                999   \n",
       "0  We propose a conceptually simple and lightweig...   \n",
       "0  This paper addresses the problem of inverse re...   \n",
       "0  We adapt the ideas underlying the success of D...   \n",
       "0  The popular Q-learning algorithm is known to o...   \n",
       "0  One way to speed up reinforcement learning is ...   \n",
       "0  Recent research has shown the benefit of frami...   \n",
       "0  Function approximation is essential to reinfor...   \n",
       "0  This paper describes the application of reinfo...   \n",
       "0  Adaptation, Learning, and Optimization, Volume...   \n",
       "0  This article presents a general class of assoc...   \n",
       "0  We present a new approach to reinforcement lea...   \n",
       "0  On large problems, reinforcement learning syst...   \n",
       "0  Psychologists call behavior intrinsically moti...   \n",
       "0  ABSTRACT A number of reinforcement learning al...   \n",
       "0  Intelligent human agents exist in a coop-erati...   \n",
       "0  In the Markov decision process (MDP) formaliza...   \n",
       "0  To what extent do we learn from the positive v...   \n",
       "0  We present a kernel-based approach to reinforc...   \n",
       "0  There is substantial evidence that dopamine is...   \n",
       "0  Reinforcement learning is a learning paradigm ...   \n",
       "0  In this paper, we adopt general-sum stochastic...   \n",
       "0  Helicopters have highly stochastic, nonlinear,...   \n",
       "0  Neural networks are powerful and flexible mode...   \n",
       "\n",
       "                                            Citation  \n",
       "0    6358회 인용 관련 학술자료 전체 6개의 버전  FindIt @ KHU Seo...  \n",
       "0                401회 인용 관련 학술자료 전체 4개의 버전  저장된 페이지   \n",
       "0    1933회 인용 관련 학술자료 전체 32개의 버전  FindIt @ KHU Se...  \n",
       "0    7256회 인용 관련 학술자료 전체 111개의 버전 Web of Science:...  \n",
       "0              3459회 인용 관련 학술자료 전체 25개의 버전  HTML 버전   \n",
       "0    8265회 인용 관련 학술자료 전체 38개의 버전 Web of Science: ...  \n",
       "0    33585회 인용 관련 학술자료 전체 43개의 버전  FindIt @ KHU S...  \n",
       "0              2672회 인용 관련 학술자료 전체 24개의 버전  HTML 버전   \n",
       "0              1698회 인용 관련 학술자료 전체 14개의 버전  HTML 버전   \n",
       "0              2779회 인용 관련 학술자료 전체 12개의 버전  HTML 버전   \n",
       "0              1631회 인용 관련 학술자료 전체 10개의 버전  HTML 버전   \n",
       "0               528회 인용 관련 학술자료 전체 18개의 버전  HTML 버전   \n",
       "0    1193회 인용 관련 학술자료 전체 34개의 버전  FindIt @ KHU Se...  \n",
       "0              2716회 인용 관련 학술자료 전체 29개의 버전  HTML 버전   \n",
       "0               766회 인용 관련 학술자료 전체 14개의 버전  HTML 버전   \n",
       "0    489회 인용 관련 학술자료 전체 5개의 버전  FindIt @ KHU Seou...  \n",
       "0    4025회 인용 관련 학술자료 전체 20개의 버전 Web of Science: ...  \n",
       "0               730회 인용 관련 학술자료 전체 26개의 버전  HTML 버전   \n",
       "0              1382회 인용 관련 학술자료 전체 19개의 버전  HTML 버전   \n",
       "0               586회 인용 관련 학술자료 전체 28개의 버전  HTML 버전   \n",
       "0    954회 인용 관련 학술자료 전체 20개의 버전  FindIt @ KHU Seo...  \n",
       "0                      1158회 인용 관련 학술자료 전체 13개의 버전    \n",
       "0    1985회 인용 관련 학술자료 전체 30개의 버전  FindIt @ KHU Se...  \n",
       "0    1621회 인용 관련 학술자료 전체 33개의 버전 Web of Science: ...  \n",
       "0    505회 인용 관련 학술자료 전체 15개의 버전 Web of Science: 1...  \n",
       "0    829회 인용 관련 학술자료 전체 28개의 버전 Web of Science: 4...  \n",
       "0    867회 인용 관련 학술자료 전체 21개의 버전  FindIt @ KHU Seo...  \n",
       "0               905회 인용 관련 학술자료 전체 16개의 버전  HTML 버전   \n",
       "0    515회 인용 관련 학술자료 전체 26개의 버전  FindIt @ KHU Seo...  \n",
       "0              1215회 인용 관련 학술자료 전체 13개의 버전  HTML 버전   "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELENIUM version\n",
    "- [인용] 문제 발생\n",
    "- citation indexing 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import randint\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromeDir = '/Users/jiwonjang/python_tutorial/chromedriver' # driver directory\n",
    "driver = webdriver.Chrome(chromeDir)\n",
    "driver.implicitly_wait(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'reinforcement learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://scholar.google.co.kr/scholar?start='\n",
    "url2 = '&q=reinforcement+learning&hl=ko&as_sdt=0,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchPages = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetUrl = []\n",
    "for i in range(0,searchPages):\n",
    "    tmpUrl = url1+str(i*10)+url2\n",
    "    TargetUrl.append(tmpUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://scholar.google.co.kr/scholar?start=0&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=10&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=20&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=30&q=reinforcement+learning&hl=ko&as_sdt=0,5',\n",
       " 'https://scholar.google.co.kr/scholar?start=40&q=reinforcement+learning&hl=ko&as_sdt=0,5']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TargetUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(TargetUrl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = driver.find_elements_by_class_name('gs_ri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[책] Introduction to reinforcement learning'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[0].find_element_by_class_name('gs_rt').text # paper title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RS Sutton, AG Barto - 1998 - login.cs.utexas.edu'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[0].find_element_by_class_name('gs_a').text # author "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://login.cs.utexas.edu/sites/default/files/legacy_files/research/documents/1%20intro%20up%20to%20RL%3ATD.pdf'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[0].find_element_by_tag_name('a').get_attribute('href') # paper link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"“We are nearing an important milestone in the history of life on earth, the point at which we\\ncan construct machines with the potential for exhibiting an intelligence comparable to ours.”--\\nDavid Waltz, 1988 (recent president of AAAI) Should occur in≈ 2030 for≈ $1000 We don't …\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[0].find_element_by_class_name('gs_rs').text # contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6358회 인용 관련 학술자료 전체 6개의 버전'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[0].find_element_by_class_name('gs_fl').text # citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOP VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromeDir = '/Users/jiwonjang/python_tutorial/chromedriver' # driver directory\n",
    "driver = webdriver.Chrome(chromeDir)\n",
    "driver.implicitly_wait(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'reinforcement learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://scholar.google.co.kr/scholar?start='\n",
    "url2 = '&q=reinforcement+learning&hl=ko&as_sdt=0,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchPages = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetUrl = []\n",
    "for i in range(0,searchPages):\n",
    "    tmpUrl = url1+str(i*10)+url2\n",
    "    TargetUrl.append(tmpUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH\n"
     ]
    }
   ],
   "source": [
    "POST = pd.DataFrame(columns=['title','paperLink','Author','content','citation'])\n",
    "\n",
    "for url in TargetUrl:\n",
    "    driver.get(url)\n",
    "    contents = driver.find_elements_by_class_name('gs_ri')\n",
    "\n",
    "    for i in range(0, len(contents)):\n",
    "\n",
    "        paperT = contents[i].find_element_by_class_name('gs_rt').text # paper title\n",
    "        paperLink = contents[i].find_element_by_tag_name('a').get_attribute('href') # paper link\n",
    "        author = contents[i].find_element_by_class_name('gs_a').text # author\n",
    "\n",
    "        try:\n",
    "            content = contents[i].find_element_by_class_name('gs_rs').text # contents\n",
    "        except NoSuchElementException:\n",
    "            content = '999'\n",
    "\n",
    "        citation = contents[i].find_element_by_class_name('gs_fl').text # citation\n",
    "\n",
    "        tmpDict = {'title' : paperT,\n",
    "              'paperLink' : paperLink,\n",
    "              'Author' : author,\n",
    "              'content' : content,\n",
    "                   'citation' : citation}\n",
    "\n",
    "        TMP = pd.DataFrame.from_dict(tmpDict, orient='index').transpose()\n",
    "        POST = POST.append(TMP)\n",
    "    sleep(randint(1,3))\n",
    "print('FINISH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>paperLink</th>\n",
       "      <th>Author</th>\n",
       "      <th>content</th>\n",
       "      <th>citation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[책] Introduction to reinforcement learning</td>\n",
       "      <td>https://login.cs.utexas.edu/sites/default/file...</td>\n",
       "      <td>RS Sutton, AG Barto - 1998 - login.cs.utexas.edu</td>\n",
       "      <td>“We are nearing an important milestone in the ...</td>\n",
       "      <td>6358회 인용 관련 학술자료 전체 6개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficient exploration in reinforcement learning</td>\n",
       "      <td>http://citeseerx.ist.psu.edu/viewdoc/summary?d...</td>\n",
       "      <td>SB Thrun - 1992 - Citeseer</td>\n",
       "      <td>Exploration plays a fundamental role in any ac...</td>\n",
       "      <td>401회 인용 관련 학술자료 전체 4개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apprenticeship learning via inverse reinforcem...</td>\n",
       "      <td>https://dl.acm.org/citation.cfm?id=1015430</td>\n",
       "      <td>P Abbeel, AY Ng - … -first international confe...</td>\n",
       "      <td>We consider learning in a Markov decision proc...</td>\n",
       "      <td>1933회 인용 관련 학술자료 전체 32개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reinforcement learning: A survey</td>\n",
       "      <td>http://www.jair.org/papers/paper301.html</td>\n",
       "      <td>LP Kaelbling, ML Littman, AW Moore - Journal o...</td>\n",
       "      <td>This paper surveys the field of reinforcement ...</td>\n",
       "      <td>7256회 인용 관련 학술자료 전체 111개의 버전 Web of Science: 2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Playing atari with deep reinforcement learning</td>\n",
       "      <td>https://arxiv.org/abs/1312.5602</td>\n",
       "      <td>V Mnih, K Kavukcuoglu, D Silver, A Graves… - a...</td>\n",
       "      <td>We present the first deep learning model to su...</td>\n",
       "      <td>3459회 인용 관련 학술자료 전체 25개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human-level control through deep reinforcement...</td>\n",
       "      <td>https://www.nature.com/articles/nature14236?wm...</td>\n",
       "      <td>V Mnih, K Kavukcuoglu, D Silver, AA Rusu, J Ve...</td>\n",
       "      <td>The theory of reinforcement learning provides ...</td>\n",
       "      <td>8265회 인용 관련 학술자료 전체 38개의 버전 Web of Science: 2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[인용] Reinforcement learning: An introduction</td>\n",
       "      <td>https://scholar.google.co.kr/citations?user=6m...</td>\n",
       "      <td>RS Sutton, AG Barto - 2018 - MIT press</td>\n",
       "      <td>999</td>\n",
       "      <td>33585회 인용 관련 학술자료 전체 43개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Asynchronous methods for deep reinforcem...</td>\n",
       "      <td>http://www.jmlr.org/proceedings/papers/v48/mni...</td>\n",
       "      <td>V Mnih, AP Badia, M Mirza, A Graves, T Lillicr...</td>\n",
       "      <td>We propose a conceptually simple and lightweig...</td>\n",
       "      <td>2672회 인용 관련 학술자료 전체 24개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Algorithms for inverse reinforcement lea...</td>\n",
       "      <td>http://ai.stanford.edu/~ang/papers/icml00-irl.pdf</td>\n",
       "      <td>AY Ng, SJ Russell - Icml, 2000 - ai.stanford.edu</td>\n",
       "      <td>This paper addresses the problem of inverse re...</td>\n",
       "      <td>1698회 인용 관련 학술자료 전체 14개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Continuous control with deep reinforcement lea...</td>\n",
       "      <td>https://arxiv.org/abs/1509.02971</td>\n",
       "      <td>TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T E...</td>\n",
       "      <td>We adapt the ideas underlying the success of D...</td>\n",
       "      <td>2779회 인용 관련 학술자료 전체 12개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Continuous control with deep reinforcement lea...</td>\n",
       "      <td>https://arxiv.org/abs/1509.02971</td>\n",
       "      <td>TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T E...</td>\n",
       "      <td>We adapt the ideas underlying the success of D...</td>\n",
       "      <td>2779회 인용 관련 학술자료 전체 12개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Feudal reinforcement learning</td>\n",
       "      <td>http://papers.nips.cc/paper/714-feudal-reinfor...</td>\n",
       "      <td>P Dayan, GE Hinton - Advances in neural inform...</td>\n",
       "      <td>One way to speed up reinforcement learning is ...</td>\n",
       "      <td>528회 인용 관련 학술자료 전체 18개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Maximum entropy inverse reinforcement le...</td>\n",
       "      <td>http://new.aaai.org/Papers/AAAI/2008/AAAI08-22...</td>\n",
       "      <td>BD Ziebart, A Maas, JA Bagnell, AK Dey - 2008 ...</td>\n",
       "      <td>Recent research has shown the benefit of frami...</td>\n",
       "      <td>1193회 인용 관련 학술자료 전체 34개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Policy gradient methods for reinforcemen...</td>\n",
       "      <td>http://papers.nips.cc/paper/1713-policy-gradie...</td>\n",
       "      <td>RS Sutton, DA McAllester, SP Singh… - Advances...</td>\n",
       "      <td>Function approximation is essential to reinfor...</td>\n",
       "      <td>2716회 인용 관련 학술자료 전체 29개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Improving elevator performance using rei...</td>\n",
       "      <td>http://papers.nips.cc/paper/1073-improving-ele...</td>\n",
       "      <td>RH Crites, AG Barto - Advances in neural infor...</td>\n",
       "      <td>This paper describes the application of reinfo...</td>\n",
       "      <td>766회 인용 관련 학술자료 전체 14개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Reinforcement learning with hierarchies ...</td>\n",
       "      <td>http://papers.nips.cc/paper/1384-reinforcement...</td>\n",
       "      <td>R Parr, SJ Russell - Advances in neural inform...</td>\n",
       "      <td>We present a new approach to reinforcement lea...</td>\n",
       "      <td>730회 인용 관련 학술자료 전체 26개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reinforcement learning</td>\n",
       "      <td>https://link.springer.com/content/pdf/10.1007/...</td>\n",
       "      <td>M Wiering, M Van Otterlo - Adaptation, learnin...</td>\n",
       "      <td>Adaptation, Learning, and Optimization, Volume...</td>\n",
       "      <td>489회 인용 관련 학술자료 전체 5개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Residual algorithms: Reinforcement learning wi...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>L Baird - Machine Learning Proceedings 1995, 1...</td>\n",
       "      <td>ABSTRACT A number of reinforcement learning al...</td>\n",
       "      <td>954회 인용 관련 학술자료 전체 20개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Generalization in reinforcement learning...</td>\n",
       "      <td>http://papers.nips.cc/paper/1109-generalizatio...</td>\n",
       "      <td>RS Sutton - Advances in neural information pro...</td>\n",
       "      <td>On large problems, reinforcement learning syst...</td>\n",
       "      <td>1382회 인용 관련 학술자료 전체 19개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Intrinsically motivated reinforcement le...</td>\n",
       "      <td>http://papers.nips.cc/paper/2552-intrinsically...</td>\n",
       "      <td>N Chentanez, AG Barto, SP Singh - Advances in ...</td>\n",
       "      <td>Psychologists call behavior intrinsically moti...</td>\n",
       "      <td>586회 인용 관련 학술자료 전체 28개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-agent reinforcement learning: Independen...</td>\n",
       "      <td>https://books.google.co.kr/books?hl=ko&amp;lr=&amp;id=...</td>\n",
       "      <td>M Tan - … the tenth international conference o...</td>\n",
       "      <td>Intelligent human agents exist in a coop-erati...</td>\n",
       "      <td>1158회 인용 관련 학술자료 전체 13개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Markov games as a framework for multi-agent re...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ML Littman - Machine learning proceedings 1994...</td>\n",
       "      <td>In the Markov decision process (MDP) formaliza...</td>\n",
       "      <td>1985회 인용 관련 학술자료 전체 30개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural architecture search with reinforcement ...</td>\n",
       "      <td>https://arxiv.org/abs/1611.01578</td>\n",
       "      <td>B Zoph, QV Le - arXiv preprint arXiv:1611.0157...</td>\n",
       "      <td>Neural networks are powerful and flexible mode...</td>\n",
       "      <td>1215회 인용 관련 학술자료 전체 13개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By carrot or by stick: cognitive reinforcement...</td>\n",
       "      <td>https://science.sciencemag.org/content/306/570...</td>\n",
       "      <td>MJ Frank, LC Seeberger, RC O'reilly - Science,...</td>\n",
       "      <td>To what extent do we learn from the positive v...</td>\n",
       "      <td>1621회 인용 관련 학술자료 전체 33개의 버전 Web of Science: 1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algorithms for reinforcement learning</td>\n",
       "      <td>https://www.morganclaypool.com/doi/abs/10.2200...</td>\n",
       "      <td>C Szepesvári - … on artificial intelligence an...</td>\n",
       "      <td>Reinforcement learning is a learning paradigm ...</td>\n",
       "      <td>867회 인용 관련 학술자료 전체 21개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] Multiagent reinforcement learning: theor...</td>\n",
       "      <td>http://citeseerx.ist.psu.edu/viewdoc/download?...</td>\n",
       "      <td>J Hu, MP Wellman - ICML, 1998 - Citeseer</td>\n",
       "      <td>In this paper, we adopt general-sum stochastic...</td>\n",
       "      <td>905회 인용 관련 학술자료 전체 16개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous inverted helicopter flight via rein...</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/1155...</td>\n",
       "      <td>AY Ng, A Coates, M Diel, V Ganapathi, J Schult...</td>\n",
       "      <td>Helicopters have highly stochastic, nonlinear,...</td>\n",
       "      <td>515회 인용 관련 학술자료 전체 26개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[HTML] Reward, motivation, and reinforcement l...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>P Dayan, BW Balleine - Neuron, 2002 - Elsevier</td>\n",
       "      <td>There is substantial evidence that dopamine is...</td>\n",
       "      <td>829회 인용 관련 학술자료 전체 28개의 버전 Web of Science: 437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PDF] The dynamics of reinforcement learning i...</td>\n",
       "      <td>http://new.aaai.org/Papers/AAAI/1998/AAAI98-10...</td>\n",
       "      <td>C Claus, C Boutilier - AAAI/IAAI, 1998 - new.a...</td>\n",
       "      <td>Reinforcement learning can provide a robust an...</td>\n",
       "      <td>1187회 인용 관련 학술자료 전체 27개의 버전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reinforcement learning in the multi-robot domain</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/978-...</td>\n",
       "      <td>MJ Matarić - Robot colonies, 1997 - Springer</td>\n",
       "      <td>This paper describes a formulation of reinforc...</td>\n",
       "      <td>633회 인용 관련 학술자료 전체 15개의 버전 Web of Science: 196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         [책] Introduction to reinforcement learning   \n",
       "0    Efficient exploration in reinforcement learning   \n",
       "0  Apprenticeship learning via inverse reinforcem...   \n",
       "0                   Reinforcement learning: A survey   \n",
       "0     Playing atari with deep reinforcement learning   \n",
       "0  Human-level control through deep reinforcement...   \n",
       "0       [인용] Reinforcement learning: An introduction   \n",
       "0  [PDF] Asynchronous methods for deep reinforcem...   \n",
       "0  [PDF] Algorithms for inverse reinforcement lea...   \n",
       "0  Continuous control with deep reinforcement lea...   \n",
       "0  Continuous control with deep reinforcement lea...   \n",
       "0                [PDF] Feudal reinforcement learning   \n",
       "0  [PDF] Maximum entropy inverse reinforcement le...   \n",
       "0  [PDF] Policy gradient methods for reinforcemen...   \n",
       "0  [PDF] Improving elevator performance using rei...   \n",
       "0  [PDF] Reinforcement learning with hierarchies ...   \n",
       "0                             Reinforcement learning   \n",
       "0  Residual algorithms: Reinforcement learning wi...   \n",
       "0  [PDF] Generalization in reinforcement learning...   \n",
       "0  [PDF] Intrinsically motivated reinforcement le...   \n",
       "0  Multi-agent reinforcement learning: Independen...   \n",
       "0  Markov games as a framework for multi-agent re...   \n",
       "0  Neural architecture search with reinforcement ...   \n",
       "0  By carrot or by stick: cognitive reinforcement...   \n",
       "0              Algorithms for reinforcement learning   \n",
       "0  [PDF] Multiagent reinforcement learning: theor...   \n",
       "0  Autonomous inverted helicopter flight via rein...   \n",
       "0  [HTML] Reward, motivation, and reinforcement l...   \n",
       "0  [PDF] The dynamics of reinforcement learning i...   \n",
       "0   Reinforcement learning in the multi-robot domain   \n",
       "\n",
       "                                           paperLink  \\\n",
       "0  https://login.cs.utexas.edu/sites/default/file...   \n",
       "0  http://citeseerx.ist.psu.edu/viewdoc/summary?d...   \n",
       "0         https://dl.acm.org/citation.cfm?id=1015430   \n",
       "0           http://www.jair.org/papers/paper301.html   \n",
       "0                    https://arxiv.org/abs/1312.5602   \n",
       "0  https://www.nature.com/articles/nature14236?wm...   \n",
       "0  https://scholar.google.co.kr/citations?user=6m...   \n",
       "0  http://www.jmlr.org/proceedings/papers/v48/mni...   \n",
       "0  http://ai.stanford.edu/~ang/papers/icml00-irl.pdf   \n",
       "0                   https://arxiv.org/abs/1509.02971   \n",
       "0                   https://arxiv.org/abs/1509.02971   \n",
       "0  http://papers.nips.cc/paper/714-feudal-reinfor...   \n",
       "0  http://new.aaai.org/Papers/AAAI/2008/AAAI08-22...   \n",
       "0  http://papers.nips.cc/paper/1713-policy-gradie...   \n",
       "0  http://papers.nips.cc/paper/1073-improving-ele...   \n",
       "0  http://papers.nips.cc/paper/1384-reinforcement...   \n",
       "0  https://link.springer.com/content/pdf/10.1007/...   \n",
       "0  https://www.sciencedirect.com/science/article/...   \n",
       "0  http://papers.nips.cc/paper/1109-generalizatio...   \n",
       "0  http://papers.nips.cc/paper/2552-intrinsically...   \n",
       "0  https://books.google.co.kr/books?hl=ko&lr=&id=...   \n",
       "0  https://www.sciencedirect.com/science/article/...   \n",
       "0                   https://arxiv.org/abs/1611.01578   \n",
       "0  https://science.sciencemag.org/content/306/570...   \n",
       "0  https://www.morganclaypool.com/doi/abs/10.2200...   \n",
       "0  http://citeseerx.ist.psu.edu/viewdoc/download?...   \n",
       "0  https://link.springer.com/chapter/10.1007/1155...   \n",
       "0  https://www.sciencedirect.com/science/article/...   \n",
       "0  http://new.aaai.org/Papers/AAAI/1998/AAAI98-10...   \n",
       "0  https://link.springer.com/chapter/10.1007/978-...   \n",
       "\n",
       "                                              Author  \\\n",
       "0   RS Sutton, AG Barto - 1998 - login.cs.utexas.edu   \n",
       "0                         SB Thrun - 1992 - Citeseer   \n",
       "0  P Abbeel, AY Ng - … -first international confe...   \n",
       "0  LP Kaelbling, ML Littman, AW Moore - Journal o...   \n",
       "0  V Mnih, K Kavukcuoglu, D Silver, A Graves… - a...   \n",
       "0  V Mnih, K Kavukcuoglu, D Silver, AA Rusu, J Ve...   \n",
       "0             RS Sutton, AG Barto - 2018 - MIT press   \n",
       "0  V Mnih, AP Badia, M Mirza, A Graves, T Lillicr...   \n",
       "0   AY Ng, SJ Russell - Icml, 2000 - ai.stanford.edu   \n",
       "0  TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T E...   \n",
       "0  TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T E...   \n",
       "0  P Dayan, GE Hinton - Advances in neural inform...   \n",
       "0  BD Ziebart, A Maas, JA Bagnell, AK Dey - 2008 ...   \n",
       "0  RS Sutton, DA McAllester, SP Singh… - Advances...   \n",
       "0  RH Crites, AG Barto - Advances in neural infor...   \n",
       "0  R Parr, SJ Russell - Advances in neural inform...   \n",
       "0  M Wiering, M Van Otterlo - Adaptation, learnin...   \n",
       "0  L Baird - Machine Learning Proceedings 1995, 1...   \n",
       "0  RS Sutton - Advances in neural information pro...   \n",
       "0  N Chentanez, AG Barto, SP Singh - Advances in ...   \n",
       "0  M Tan - … the tenth international conference o...   \n",
       "0  ML Littman - Machine learning proceedings 1994...   \n",
       "0  B Zoph, QV Le - arXiv preprint arXiv:1611.0157...   \n",
       "0  MJ Frank, LC Seeberger, RC O'reilly - Science,...   \n",
       "0  C Szepesvári - … on artificial intelligence an...   \n",
       "0           J Hu, MP Wellman - ICML, 1998 - Citeseer   \n",
       "0  AY Ng, A Coates, M Diel, V Ganapathi, J Schult...   \n",
       "0     P Dayan, BW Balleine - Neuron, 2002 - Elsevier   \n",
       "0  C Claus, C Boutilier - AAAI/IAAI, 1998 - new.a...   \n",
       "0       MJ Matarić - Robot colonies, 1997 - Springer   \n",
       "\n",
       "                                             content  \\\n",
       "0  “We are nearing an important milestone in the ...   \n",
       "0  Exploration plays a fundamental role in any ac...   \n",
       "0  We consider learning in a Markov decision proc...   \n",
       "0  This paper surveys the field of reinforcement ...   \n",
       "0  We present the first deep learning model to su...   \n",
       "0  The theory of reinforcement learning provides ...   \n",
       "0                                                999   \n",
       "0  We propose a conceptually simple and lightweig...   \n",
       "0  This paper addresses the problem of inverse re...   \n",
       "0  We adapt the ideas underlying the success of D...   \n",
       "0  We adapt the ideas underlying the success of D...   \n",
       "0  One way to speed up reinforcement learning is ...   \n",
       "0  Recent research has shown the benefit of frami...   \n",
       "0  Function approximation is essential to reinfor...   \n",
       "0  This paper describes the application of reinfo...   \n",
       "0  We present a new approach to reinforcement lea...   \n",
       "0  Adaptation, Learning, and Optimization, Volume...   \n",
       "0  ABSTRACT A number of reinforcement learning al...   \n",
       "0  On large problems, reinforcement learning syst...   \n",
       "0  Psychologists call behavior intrinsically moti...   \n",
       "0  Intelligent human agents exist in a coop-erati...   \n",
       "0  In the Markov decision process (MDP) formaliza...   \n",
       "0  Neural networks are powerful and flexible mode...   \n",
       "0  To what extent do we learn from the positive v...   \n",
       "0  Reinforcement learning is a learning paradigm ...   \n",
       "0  In this paper, we adopt general-sum stochastic...   \n",
       "0  Helicopters have highly stochastic, nonlinear,...   \n",
       "0  There is substantial evidence that dopamine is...   \n",
       "0  Reinforcement learning can provide a robust an...   \n",
       "0  This paper describes a formulation of reinforc...   \n",
       "\n",
       "                                            citation  \n",
       "0                         6358회 인용 관련 학술자료 전체 6개의 버전  \n",
       "0                          401회 인용 관련 학술자료 전체 4개의 버전  \n",
       "0                        1933회 인용 관련 학술자료 전체 32개의 버전  \n",
       "0  7256회 인용 관련 학술자료 전체 111개의 버전 Web of Science: 2305  \n",
       "0                        3459회 인용 관련 학술자료 전체 25개의 버전  \n",
       "0   8265회 인용 관련 학술자료 전체 38개의 버전 Web of Science: 2408  \n",
       "0                       33585회 인용 관련 학술자료 전체 43개의 버전  \n",
       "0                        2672회 인용 관련 학술자료 전체 24개의 버전  \n",
       "0                        1698회 인용 관련 학술자료 전체 14개의 버전  \n",
       "0                        2779회 인용 관련 학술자료 전체 12개의 버전  \n",
       "0                        2779회 인용 관련 학술자료 전체 12개의 버전  \n",
       "0                         528회 인용 관련 학술자료 전체 18개의 버전  \n",
       "0                        1193회 인용 관련 학술자료 전체 34개의 버전  \n",
       "0                        2716회 인용 관련 학술자료 전체 29개의 버전  \n",
       "0                         766회 인용 관련 학술자료 전체 14개의 버전  \n",
       "0                         730회 인용 관련 학술자료 전체 26개의 버전  \n",
       "0                          489회 인용 관련 학술자료 전체 5개의 버전  \n",
       "0                         954회 인용 관련 학술자료 전체 20개의 버전  \n",
       "0                        1382회 인용 관련 학술자료 전체 19개의 버전  \n",
       "0                         586회 인용 관련 학술자료 전체 28개의 버전  \n",
       "0                        1158회 인용 관련 학술자료 전체 13개의 버전  \n",
       "0                        1985회 인용 관련 학술자료 전체 30개의 버전  \n",
       "0                        1215회 인용 관련 학술자료 전체 13개의 버전  \n",
       "0   1621회 인용 관련 학술자료 전체 33개의 버전 Web of Science: 1071  \n",
       "0                         867회 인용 관련 학술자료 전체 21개의 버전  \n",
       "0                         905회 인용 관련 학술자료 전체 16개의 버전  \n",
       "0                         515회 인용 관련 학술자료 전체 26개의 버전  \n",
       "0     829회 인용 관련 학술자료 전체 28개의 버전 Web of Science: 437  \n",
       "0                        1187회 인용 관련 학술자료 전체 27개의 버전  \n",
       "0     633회 인용 관련 학술자료 전체 15개의 버전 Web of Science: 196  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
